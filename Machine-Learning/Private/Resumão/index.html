<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Vi√©s e Vari√¢ncia  O que √© vies? O que √© variancia Relaciones vi√©s com vari√¢ncia Quais s√£o as principais formas de se controlar vi√©s?"><meta property="og:title" content><meta property="og:description" content="Vi√©s e Vari√¢ncia  O que √© vies? O que √© variancia Relaciones vi√©s com vari√¢ncia Quais s√£o as principais formas de se controlar vi√©s?"><meta property="og:type" content="website"><meta property="og:image" content="https://henriqueld.github.io/quartz/icon.png"><meta property="og:url" content="https://henriqueld.github.io/quartz/Machine-Learning/Private/Resum%C3%A3o/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="Vi√©s e Vari√¢ncia  O que √© vies? O que √© variancia Relaciones vi√©s com vari√¢ncia Quais s√£o as principais formas de se controlar vi√©s?"><meta name=twitter:image content="https://henriqueld.github.io/quartz/icon.png"><meta name=twitter:site content="_jzhao"><title>ü™¥ Quartz 3.3</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://henriqueld.github.io/quartz//icon.png><link href=https://henriqueld.github.io/quartz/styles.19109a40042e9f0e72e952fda4442a34.min.css rel=stylesheet><link href=https://henriqueld.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://henriqueld.github.io/quartz/js/darkmode.ea03503ca359b66bfbe4d5557fb73029.min.js></script>
<script src=https://henriqueld.github.io/quartz/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://henriqueld.github.io/quartz/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://henriqueld.github.io/quartz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://henriqueld.github.io/quartz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://henriqueld.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://henriqueld.github.io/quartz/",fetchData=Promise.all([fetch("https://henriqueld.github.io/quartz/indices/linkIndex.5663591302e11b76bdc6ea0d3a733758.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://henriqueld.github.io/quartz/indices/contentIndex.c4a097a63cfac011b45c0d1a6146d8e1.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://henriqueld.github.io/quartz",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://henriqueld.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'‚Äô':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/henriqueld.github.io\/quartz\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=henriqueld.github.io/quartz src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://henriqueld.github.io/quartz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://henriqueld.github.io/quartz/>ü™¥ Quartz 3.3</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/Machine%20Learning/Private/Resum%c3%a3o.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><ol><li><a href=#vi√©s-e-vari√¢ncia>Vi√©s e Vari√¢ncia</a></li><li><a href=#√°rvores>√Årvores</a></li><li><a href=#ensembles>Ensembles</a></li><li><a href=#outros-modelos>Outros Modelos</a></li><li><a href=#m√©tricas-de-avalia√ß√£o>M√©tricas de avalia√ß√£o</a></li></ol></li></ol></nav></details></aside><a href=#vi√©s-e-vari√¢ncia><h3 id=vi√©s-e-vari√¢ncia><span class=hanchor arialabel=Anchor># </span>Vi√©s e Vari√¢ncia</h3></a><ul><li>O que √© vies?</li><li>O que √© variancia</li><li>Relaciones vi√©s com vari√¢ncia</li><li>Quais s√£o as principais formas de se controlar vi√©s?</li><li>Quais s√£o as principais formas de se controlar vari√¢ncia?</li></ul><p>Vi√©s e vari√¢ncia s√£o dois dos conceitos gerais de erros em modelagem, <mark style=background:#adccffa6>vi√©s √© o tipo de erro que ocorre quando o modelo assume suposi√ß√µes incorreta dos dados a partir do conjunto de treino. Um modelo com alto vi√©s est√° relacionado ao underfit, quando um modelo aprende muito pouco com os dados de treino.</mark></p><p>Por outro lado, <mark style=background:#ff5582a6>a vari√¢ncia reflete o qu√£o sens√≠vel o modelo √© em rela√ß√£o √† varia√ß√µes dos dados de conjunto de treino. Dizemos que um modelo muito sens√≠vel possui alta vari√¢ncia e est√° relacionado ao problema de overfit, quando o modelo n√£o generaliza bem para novos dados (teste)</mark>.</p><p>A rela√ß√£o entre os dois √© o famoso trade-off vi√©s e vari√¢ncia, normalmente na modelagem existe uma balan√ßa entre reduzir o vi√©s e a vari√¢ncia. Ao passo que um modelo muito simples inicialmente come√ßam a ganhar complexidade e flexibilidade (ao comportamento dos dados), ele tem uma redu√ß√£o no vi√©s por√©m pode apresentar aumento na vari√¢ncia, indicando perda de performance para novos dados n√£o observados, <mark style=background:#adccffa6>o objetivo do trade-off √© encontrar o ponto de equil√≠brio entre a redu√ß√£o do vi√©s e da vari√¢ncia</mark></p><p>Vi√©s alto pode ser controlado usando modelos mais complexos e flex√≠veis, usando mais features (principalmente se elas apresentarem poder preditivo) e para alguns algoritmos, reduzir a penaliza√ß√£o aplicada. Para alta vari√¢ncia, podemos usar modelos mais simples/com menos par√¢metros, aumentar a quantidade de dados no treino, utilizar regularizadores (lasso e ridge) e tamb√©m √© poss√≠vel utilizar t√©cnicas de boosting</p><a href=#√°rvores><h3 id=√°rvores><span class=hanchor arialabel=Anchor># </span>√Årvores</h3></a><ul><li>Qual o crit√©rio de quebra?</li><li>Como a sa√≠da √© calculada?</li><li>Quais s√£o os pontos fortes do algoritmo?</li><li>Quais s√£o os crit√©rios principais de parada?</li><li>Quais s√£o os principais problemas encontrados no algoritmo?</li><li>Qual a forma de regulariza√ß√£o de uma √°rvore?</li></ul><p>√Årvores de decis√£o podem ser utilizadas tanto para problemas de regress√£o quanto pra de classifica√ß√£o e funcionam de maneira minimamente diferentes para cada tipo. √â chamada de √°rvore pois as condi√ß√µes de decis√£o do modelo s√£o feitas por ramifica√ß√µes criando &ldquo;visualmente&rdquo; algo muito parecido com uma raiz de uma √°rvore.</p><p>No geral a ramifica√ß√£o da √°rvore √© feita de maneira que os dados que sobram em cada grupo ap√≥s a separa√ß√£o sejam mais homog√™neos do que antes da quebra, nas √°rvores de regress√£o verificamos a &ldquo;homogeneidade&rdquo; com m√©tricas como <a class="internal-link broken">MSE</a> e <a class="internal-link broken">MAE</a>, e para as √°rvores de classifica√ß√£o utilizamos <a class="internal-link broken">Gini</a> ou <a class="internal-link broken">Entropia</a> para validar as quebras.</p><p>Ap√≥s serem feitas todas as quebras, n√≥s temos folhas no n√≠vel mais baixo de cada ramifica√ß√£o que representa a sa√≠da do modelo, para regress√£o utilizamos a m√©dia da target dos dados que pertencem a folha e para classifica√ß√£o n√≥s utilizamos a classe mais frequente dentro da folha (caso ela n√£o seja pura).</p><p>Pessoal gosta muito da interpretabilidade que as √°rvores de decis√£o oferecem e a capacidade de lidar com os dados sem a necessidade de padroniza√ß√£o ou tratamentos. Por√©m se n√£o tomar cuidado com os par√¢metros da √°rvore √© bem f√°cil de acontecer overfitting e o algoritmo tem a tend√™ncia de gerar √°rvores diferentes se os dados de treino forem alterados.</p><p>Uma maneira de evitar o overfitting √© definir bem os crit√©rios de parada da √°rvore, que s√£o a profundidade m√°xima da √°rvore, o tanto que voc√™ quer que ela se ramifique, n√∫mero m√≠nimo de observa√ß√µes dentro de um n√≥ para que seja poss√≠vel continuar dividindo e o n√∫mero m√≠nimo de observa√ß√µes dentro de uma folha do modelo.</p><p>Regularizadores de √°rvore de decis√£o s√£o basicamente os crit√©rios de parada</p><a href=#ensembles><h3 id=ensembles><span class=hanchor arialabel=Anchor># </span>Ensembles</h3></a><ul><li>Quais as principais formas de ensemble?</li><li>Cite um algoritmo de bagging e outro de boosting</li><li>Qual problema o bagging se prop√µe a resolver?</li><li>Qual problema o boosting se prop√µe a resolver?</li><li>Quais s√£o os principais par√¢metros de uma random forest e quais s√£o seus efeitos?</li><li>Quais s√£o os principais par√¢metros de um gradient boosting e quais s√£o seus efeitos?</li><li>Relacione bagging a vi√©s e vari√¢ncia</li><li>Relacione boosting a vi√©s e vari√¢ncia</li><li>Cite duas implementa√ß√µes de boosting e explique suas diferen√ßas</li></ul><p>Ensemble s√£o t√©cnicas que v√°rios modelos treinados para resolver um mesmo problema, combinados para ter um melhor poder preditivo. Os principais m√©todos de ensembles s√£o o bagging e o boosting.</p><p>Bagging utiliza v√°rias inst√¢ncias do &ldquo;mesmo modelo&rdquo; para diferentes subconjuntos dos dados originais (realizado por bootstrap) que no fim s√£o combinados por voto da maioria (classifica√ß√£o) e m√©dia/mediana das predi√ß√µes (regress√£o). No geral bagging tenta tratar o problema de modelos que tendem a ter alta vari√¢ncia com sua combina√ß√£o, e um exemplo de bagging √© a Random Forest (agrega√ß√£o de √°rvores de decis√µes)</p><p>Boosting busca resolver o problema underfit de modelos fracos &ldquo;melhorando&rdquo; o modelo de forma sequencial, em cada itera√ß√£o o modelo √© treinado em um conjunto de dados &ldquo;ajustado&rdquo; dando mais import√¢ncia para os erros passado, ou predizendo o erro gerado pelo modelo anterior. Exemplos de boosting s√£o Gradient Boosting e XGBoost</p><p>Principais par√¢metros da Random Forest:</p><ul><li><mark style=background:#adccffa6>numero de √°rvores</mark></li><li><mark style=background:#adccffa6>tamanho do subconjunto de features pra ser utilizado em cada √°rvore</mark></li><li><mark style=background:#adccffa6>metodo de reamostragem das observa√ß√µes para cada √°rvore</mark></li><li>profundidade m√°xima das √°rvores</li><li>n√∫mero minimo de amostras (folha/n√≥s)</li></ul><p>Principais par√¢metros do Gradient Boosting:</p><ul><li><mark style=background:#adccffa6>numero de √°rvores</mark></li><li><mark style=background:#adccffa6>tamanho do subconjunto de features pra ser utilizado em cada √°rvore</mark></li><li><mark style=background:#adccffa6>learning rate</mark></li><li>profundidade m√°xima das arvores</li><li>numero m√≠nimo de amostras (folha/n√≥s)</li></ul><p>Tanto Gradient Boosting quanto XGBoost s√£o t√©cnicas de boosting que buscam melhorar um modelo weak learner predizendo os res√≠duos por√©m possuem algumas diferen√ßas: O XGBoost possui termos regularizadores, como o gamma e o lambda para diminuir o impacto que observa√ß√µes individuais possuem nas previs√µes e melhorar a generaliza√ß√£o do modelo, al√©m de tamb√©m possuir um sistema de poda dinamica que n√£o depende de completar a execu√ß√£o da arvore antes de realizar</p><a href=#outros-modelos><h3 id=outros-modelos><span class=hanchor arialabel=Anchor># </span>Outros Modelos</h3></a><p>Falar de naive bayes</p><a href=#m√©tricas-de-avalia√ß√£o><h3 id=m√©tricas-de-avalia√ß√£o><span class=hanchor arialabel=Anchor># </span>M√©tricas de avalia√ß√£o</h3></a><ul><li>Principais m√©tricas para avaliar um classificador</li><li>Funcionamento / caso de uso / restri√ß√µes</li><li>Diferenciar m√©tricas de poder e calibra√ß√£o</li><li>T√©cnicas multiclasse/multilabel</li><li>Principais m√©tricas para avaliar um regressor</li><li>Funcionamento/ caso de uso / restri√ß√µes</li></ul><a href=#as-m√©tricas-mais-comuns-pra-avaliar-classificadores-s√£o><h4 id=as-m√©tricas-mais-comuns-pra-avaliar-classificadores-s√£o><span class=hanchor arialabel=Anchor># </span>As m√©tricas mais comuns pra avaliar classificadores s√£o:</h4></a><a href=#m√©tricas-de-poder><h5 id=m√©tricas-de-poder><span class=hanchor arialabel=Anchor># </span>M√©tricas de poder:</h5></a><ul><li>Acuracia: Reflete o percentual de classes que seu modelo acerta, √∫til pra ter uma ideia inicial do modelo mas p√©ssima quando os dados s√£o muito desbalanceados</li><li>Precis√£o: Mede a propor√ß√£o de observa√ß√µes corretamente classificadas como positivas, bom quando queremos controlar os falsos positivos, <mark style=background:#adccffa6>importante para problemas de recomenda√ß√£o</mark></li><li>Recall/Sensibilidade: Mede a propor√ß√£o de observa√ß√µes positivas classificadas corretamente, √∫til em problemas de sa√∫de/medicina <mark style=background:#adccffa6>onde n√£o queremos de maneira alguma deixar de classificar um cliente doente corretamente</mark></li><li>F1-Score: M√©dia harm√¥nica de precis√£o e recall, penaliza mais os valores extremos, √∫til quando ambas o custo dos dois erros s√£o semelhantes.</li><li>ROC-AUC: Gr√°fico entre TPR e FPR, mede qu√£o bem o classificador separa duas classes (quando o valor se aproxima de 1) para v√°rios pontos de corte, boa m√©trica para avaliar a classifica√ß√£o de um modelo no geral para problemas de classes desbalanceadas</li></ul><a href=#m√©tricas-de-calibra√ß√£o><h5 id=m√©tricas-de-calibra√ß√£o><span class=hanchor arialabel=Anchor># </span>M√©tricas de calibra√ß√£o:</h5></a><ul><li>Log-Loss: Mede a discrep√¢ncia entre a probabilidade observada pelo modelo e as classes reais atrav√©s da log-verossimilhan√ßa</li></ul><a href=#para-avaliar-problemas-multiclass><h4 id=para-avaliar-problemas-multiclass><span class=hanchor arialabel=Anchor># </span>Para avaliar problemas multiclass:</h4></a><ul><li><strong>Macro Average</strong> das m√©tricas acima: M√©dia simples da soma das m√©tricas dividas pelo n√∫mero de classes, ex: precis√£o
$$Macro Avg = \frac{Precis√£o_{c1}+Precis√£o_{c2}+Precis√£o_{c3}}{3}$$</li><li><strong>Micro Average</strong> das m√©tricas acima: M√©dia considerando toda a soma individual de TP, TN, FP e FN de todas as classes do conjunto de dados, ex: precisao
$$Micro Avg = \frac{\sum_{1,2,3}TruePositive}{\sum_{1,2,3}TruePositive+\sum_{1,2,3}FalsePositive}$$</li><li><strong>Weighted Average</strong> das m√©tricas acima: M√©dia com pesos atribu√≠dos pela frequ√™ncia de cada classe no conjunto de dados, ex: precis√£o
$$Weighted Avg = \frac{Precis√£o_{c1}*10+Precis√£o_{c2}*20+Precis√£o_{c3}*50}{10+20+50}$$</li></ul><a href=#para-problemas-de-m√∫ltiplos-r√≥tulos-pra-mesma-observa√ß√£o><h4 id=para-problemas-de-m√∫ltiplos-r√≥tulos-pra-mesma-observa√ß√£o><span class=hanchor arialabel=Anchor># </span>Para problemas de m√∫ltiplos r√≥tulos pra mesma observa√ß√£o:</h4></a><ul><li><strong>Jaccard Score</strong> mede a interse√ß√£o das classifica√ß√µes sobre a uni√£o de todas as classifica√ß√µes, <mark style=background:#adccffa6>para problemas bin√°rios √© id√™ntico √† acur√°cia, mas tamb√©m podemos entender o uso para problemas multiclasse e de multirotulo</mark></li></ul><a href=#as-m√©tricas-mais-comuns-pra-avaliar-regressores-s√£o><h4 id=as-m√©tricas-mais-comuns-pra-avaliar-regressores-s√£o><span class=hanchor arialabel=Anchor># </span>As m√©tricas mais comuns pra avaliar regressores s√£o:</h4></a><ul><li><strong>MSE</strong> representa a m√©dia do quadrado dos res√≠duos, penaliza de maneira mais forte erros maiores por√©m √© sens√≠vel a outliers, como √© uma fun√ß√£o deriv√°vel, √© muito √∫til como fun√ß√£o de custo</li><li><strong>RMSE</strong> representa a raiz quadrada do MSE, tem as mesmas vantagens com o adicional de manter o erro na escala original dos dados, aumentando interpretabilidade.</li><li><strong>MAE</strong> m√©dia dos erros absolutos, penaliza de acordo com a magnitude dos erros por√©m √© menos sens√≠vel a outliers, como n√£o √© deriv√°vel possui limita√ß√µes como fun√ß√£o de custo, o ponto positivo √© que facilita a interpretabilidade pois mantem a escala original dos dados.</li><li><strong>R¬≤</strong> representa a porcentagem de ganho de predi√ß√£o ao usar o modelo em compara√ß√£o √† m√©dia da feature (diferen√ßa entre SSR da m√©dia e SSR do ajuste), desvantagem √© n√£o levar em conta a quantidade de features, que pode influenciar negativamente a m√©trica</li><li><strong>R¬≤ Ajustado</strong> √© uma adapta√ß√£o do R¬≤ com uma penaliza√ß√£o pelo n√∫mero de features, ou seja, leva em conta a quantidade de explica√ß√£o fornecida pelas vari√°veis preditoras, √∫til para comparar modelos com diferentes n√∫mero de par√¢metros</li><li></li><li>Quais s√£o as principais categorias de algoritmos de clusteriza√ß√£o</li><li>Cite um algoritmo de cada categoria?</li><li>Explique rapidamente os algoritmos citado</li></ul><a href=#clusteriza√ß√£o-hier√°rquica><h4 id=clusteriza√ß√£o-hier√°rquica><span class=hanchor arialabel=Anchor># </span>Clusteriza√ß√£o Hier√°rquica</h4></a><p>Constroi dendogramas para representar os clusters em uma hierarquia, onde em certo ponto de corte todos os pontos podem fazer parte de um mesmo cluster, ou cada ponto ser seu pr√≥prio cluster</p><a href=#aglomera√ß√£o><h5 id=aglomera√ß√£o><span class=hanchor arialabel=Anchor># </span>Aglomera√ß√£o</h5></a><p>Na inicializa√ß√£o cada ponto √© seu pr√≥prio e a cada itera√ß√£o os dois clusters mais pr√≥ximos se unem para formar um novo cluster, esse processo se repete at√© existir apenas 1 cluster s√≥, contendo todo o dataset</p><a href=#divis√£o><h5 id=divis√£o><span class=hanchor arialabel=Anchor># </span>Divis√£o</h5></a><p>O algoritmo come√ßa considerando todos os pontos em um √∫nico cluster e a cada passo as observa√ß√µes com maior dissimilaridade √© realocado em um cluster separado, processo se repete at√© existir um cluster para cada observa√ß√£o</p><p>As medidas utilizadas podem ser <strong>vizinho mais proximo</strong>, <strong>vizinho mais distante</strong> ou <strong>media das distancias</strong></p><a href=#clusteriza√ß√£o-particionais><h4 id=clusteriza√ß√£o-particionais><span class=hanchor arialabel=Anchor># </span>Clusteriza√ß√£o Particionais</h4></a><p>T√©cnicas de agrupamento que divide os dados em um n√∫mero pre definido de clusters e assim como na hier√°rquica, no fim do processo cada ponto pertence a apenas um cluster, o objetivo √© encontrar a divis√£o do hiperplano que otimiza a m√©trica de dist√¢ncia intra-cluster e inter-cluster</p><a href=#k-means><h5 id=k-means><span class=hanchor arialabel=Anchor># </span>K-means</h5></a><p>estima o centroides do cluster com a media dos pontos - indicado usar distancia euclidiana</p><a href=#k-medoids><h5 id=k-medoids><span class=hanchor arialabel=Anchor># </span>K-Medoids</h5></a><p>estima centroide do cluster com a mediana - indicado usar com distancia de manhattan</p><a href=#clusteriza√ß√£o-baseado-em-densidade---dbscan><h4 id=clusteriza√ß√£o-baseado-em-densidade---dbscan><span class=hanchor arialabel=Anchor># </span>Clusteriza√ß√£o baseado em densidade - DBSCAN</h4></a><p>Algoritmo de agrupamento que considera pontos muito pr√≥ximos em mesmo cluster por densidade, teoricamente consegue identificar qualquer formato na distribui√ß√£o dos dados olhando a proximidade entre pontos</p><p>funciona com os par√¢metros de <strong>pontos minimos</strong> e <strong>tamanho do raio</strong> para classificar os pontos do dataset e depois atribuir em algum cluster</p><a href=#clusteriza√ß√£o-baseado-em-mistura-de-modelos><h4 id=clusteriza√ß√£o-baseado-em-mistura-de-modelos><span class=hanchor arialabel=Anchor># </span>Clusteriza√ß√£o baseado em mistura de modelos</h4></a><p>Cluster definido em uma abordagem probabil√≠stica, cada modelo representa um cluster e √© ajustado aos dados usando expectation-maximization, permitindo medir a incerteza dos agrupamentos gerados.</p><a href=#gmm><h5 id=gmm><span class=hanchor arialabel=Anchor># </span>GMM</h5></a></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://henriqueld.github.io/quartz/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, ¬© 2023</p><ul><li><a href=https://henriqueld.github.io/quartz/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>GitHub</a></li></ul></footer></div></div></body></html>