{"/Machine-Learning/":{"title":"Guia de estudos de Machine Learning","content":"\nMinhas notas de estudo sobre machine learning :)\n\n1. [[Machine Learning/Machine Learning|Machine Learning]]\n\n\n","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/%C3%81rvores-de-decis%C3%A3o-Classifica%C3%A7%C3%A3o":{"title":"Árvores de decisão - Classificação","content":"Árvores de decisão são algoritmos supervisionados não paramétricos que realizam classificação por meio da construção de uma estrutura em forma de árvore. Cada nó interno da árvore representa uma condição sobre uma ou mais características, enquanto **as folhas** representam as classes finais preditas.\n\nA árvore começa com um **nó raiz**, onde a seleção do atribute é feita com base em algum critério, geralmente **[[Entropia]]** ou **[[Gini]]**. O intuito das separações é obter o máximo de homogeneidade possível nas folhas.\n\n![[Pasted image 20230716175205.png | center]]\n\nCom base no atributo selecionado, os dados de treinamento são divididos em subconjuntos em **nós**, de acordo com os diferentes valores/resposta do atributo selecionado onde cada **nó** representa uma ramificação da árvore.\n\nO processo de seleção de feature e ponto de corte se repete, criando uma estrutura de árvore, até que uma **condição de parada** seja atingida. A condição de parada geralmente reflete um determinado **índice de pureza das folhas** da árvore ou ocorre quando um **limite máximo de profundidade** é atingido, esses termos podem ser definidos nos hiperparâmetros \n\n![[Pasted image 20230716180257.png | center]]\n\nApós a construção da árvore, uma nova observação é classificada percorrendo **as condições de cada nó até chegar uma folha**, que contém a classe predita pelo modelo.\n\n## **Exemplo**: \nClassificador se uma pessoa gosta ou não gosta do filme Troll 2. partindo dos dados de treino a seguir:\n![[Pasted image 20230716185613.png | center]]\n\nPara decidir a raiz da árvore, vamos calcular o **índice de GINI** para de cada uma das duas variáveis categóricas:\n![[Pasted image 20230716191329.png | center]]\n\nPara a variável contínua **Age**, devemos ordenar (já está no exemplo), tirar a média entre cada linha e calcular o **índice de GINI** considerando **cada uma dás médias como condição de ramificação no nó** e pegar a condição que retorna o melhor índice:\n![[Pasted image 20230716191834.png | center]]\n\nLogo a nossa raiz será a condição **Loves Soda com GINI = 0.214**, devemos seguir com as demais variáveis, em qualquer nó que ainda apresentar impureza, para determinar o resto da ramificação da árvore repetindo o mesmo processo **(Lembrando que o nó resultando da resposta \"no\" já está puro e não precisamos alterar)**\n\n![[Pasted image 20230716192751.png]]\n\nCom essa nova quebra, utilizando a condição **Age \u003c 12.5 com Gini = 0**, conseguimos ter uma árvore onde todas as folhas são 100% puras, e assim não temos mais pra que continuar ramificando, chegando a seguinte árvore de decisão:\n\n![[Pasted image 20230716193136.png | center]]\n\n## Problema de Overfitting\nPor ser um algoritmo de partição recursivo, a árvore estende a sua profundidade até o ponto de classificar perfeitamente os elementos do conjunto de treino, **podendo até mesmo zerar o número de erros**. Desta forma o modelo pode não generalizar para dados não vistos.\nUma forma de reduzir o overfitting é realizando a **poda** da árvore, que pode ser utilizada de duas formas: para o crescimento da árvore mais cedo ou após a árvore já estar completa, geralmente tunando os hiperparâmetros\n\n### Vantagens\n- Não é necessário normalizar/padronizar os dados\n- Fácil interpretabilidade e de fácil visualização\n- Bom para problemas binários ou multiclasses\n- Útil para saber descobrir a *feature importance* (seleção de variáveis)\n- Features com baixa significância não afetam a predição (porém aumenta o custo computacional)\n\n### Desvantagem\n- Fácil de acontecer *overfitting* se não cuidar dos hiperparâmetros\n- Sensível aos dados: variação nas amostras podem gerar árvores bem diferentes\n#classificação ","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/%C3%81rvores-de-decis%C3%A3o-Regress%C3%A3o":{"title":"Árvores de decisão - Regressão","content":"Árvores de decisão são algoritmos supervisionados não paramétricos que realizam a regressão por meio da construção de uma estrutura em forma de árvore. Cada nó interno da árvore representa uma condição sobre uma ou mais características, enquanto **as folhas** representam as classes finais preditas.\n\nA árvore começa com um **nó raiz**, onde a seleção do atribute é feita com base em algum critério, como o [[Mean Squared Error (MSE)|MSE]] ou [[Mean Absolute Error (MAE)|MAE]]. O atributo selecionado é aquele que melhor divide os dados e resulta na maior redução do erro de regressão.\n\nAs árvores de regressão tendem a fazer uma boa predição porque cada **folha** se torna um cluster de dados no gráfico e a **predição se torna a média dos pontos que então dentro da folha**:\n\n![[Pasted image 20230719215921.png|center]]\n\nOs pontos de ramificação são definidos testando todas as médias de dois pontos e verificando qual corte reduz com mais eficiência o SSR:\n\n![[Pasted image 20230719221622.png|center]]\nNo nosso exemplo, Dose \u003c 14.5 foi o ponto escolhido, no nó à esquerda sobraram apenas 6 pontos, na teoria seria possível dividir ainda mais esses dados, \u003cmark style=\"background: #FF5582A6;\"\u003eporém seguir com um número tão baixo de pontos faz com que seja muito provável que ocorra overfitting do modelo\u003c/mark\u003e.\n\nUma maneira simples de evitar esse problema é definir um valor mínimo necessário na folha para continuar a ramificação, 20 geralmente é um valor razoável, porém \u003cmark style=\"background: #ADCCFFA6;\"\u003eno exemplo usaremos 7 observações como valor mínimo.\u003c/mark\u003e\n\nSeguindo o mesmo processo e considerando o critério mínimo de observações definido acima, chegaremos à seguinte árvore:\n\n![[Pasted image 20230719222315.png|center]]\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eOs ensembles como Random Forest e XGBoost também podem ser utilizados em problemas de regressão\u003c/mark\u003e\n\n### Vantagens\n- Não é necessário normalizar/padronizar os dados\n- Fácil interpretabilidade e de fácil visualização\n- Útil para saber descobrir a *feature importance* (seleção de variáveis)\n- Features com baixa significância não afetam a predição (porém aumenta o custo computacional)\n\n### Desvantagem\n- Fácil de acontecer *overfitting* se não cuidar dos hiperparâmetros\n- Sensível aos dados: variação nas amostras podem gerar árvores bem diferentes\n- Difícil captura de relações complexas nos dados\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/Acur%C3%A1cia":{"title":"Acurácia","content":"Representa a proporção de classificações corretas **(independente da classe)** em relação ao total de amostras observadas\n$$ Acurácia = \\frac{TP+TN}{TP+TN+FP+FN} $$\n**Desvantagens**\n- Pode ser ilusório para classificações de problemas com **desbalanceamento de classes** (acurácia elevada mesmo com performance ruim do classificador)\n- Atribui o mesmo peso para ambos os erros, (alguns problemas tem maior ganho ao minimizar FP ou FN)\n\n**Vantagens**\n- Métrica altamente interpretável\n- Pode ser utilizada para comparar dois modelos\n- Medida útil para problemas de **classes balanceadas** onde a importância de cada classificação é semelhante (TP, TN)\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Aglomera%C3%A7%C3%A3o-Bottom-Up":{"title":"Aglomeração (Bottom Up)","content":"O algoritmo se inicia com cada observação sendo seu próprio cluster (n clusters). Os dois clusters mais próximos se unem para formar um novo cluster, os seguintes clusters que estão mais próximos se unem para formar um novo e esse processo continua até existir apenas 1 cluster no fim, contendo todos o dataset.\n\n\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Boruta":{"title":"Boruta","content":"Boruta é um algoritmo de feature selection desenvolvido em 2010 e desenhado para fazer uma seleção automática de features em um banco de dados. Surgiu originalmente como um módulo no R, porém foi feita uma implantação em Python com mais flexibilidade nos parâmetros.\n\nResumidamente, o Boruta permuta as features existentes nos bancos de dados (chamadas de **shadow features**) e compara sua importância com as features originais, em teoria **qualquer feature significante** para a solução do problema tende a ser **mais importante do que a melhor shadow feature**.\n\n## Exemplo\nA seguir vamos exemplificar o funcionamento do método com um dataset simples, onde queremos **inferir a renda** de uma pessoa a partir da sua **idade**, **altura** e **peso**:\n\n![[Pasted image 20230719225255.png|center]]\n\n### Shadow Features\nNo Boruta, as features não competem entre si, em vez disso elas são comparadas com uma versão randomizada delas mesmas, as denominadas **shadow features**. No nosso exemplo, será criada a coluna **shadow_age** que representa a permutação das observações de **age**, e analogamente **shadow_height** e **shadow_weight**.\n\nEssas shadow features são agrupadas ao dataset original de features, obtendo agora um novo dataframe *\"X_Boruta\"*:\n![[Pasted image 20230719230722.png|center]]\n\nPróximo passo é ajustar uma [[Random Forest - Classificação|Random Forest]] utilizando **X_Boruta** para predizer **income**.\n\n### Avaliando as features importances\nAgora que temos as shadow features e o modelo ajustado, vamos calcular as features importances de cada uma das features no dataset *X_Boruta* e **identificar a maior feature importance obtida entre as shadow features**.\n\nQuando a importance de uma feature é maior do que esse threshold, consideramos um \"acerto\". A ideia é que **uma feature só é importante se for capaz de explicar melhor a target do que a melhor shadow feature**.\n![[Pasted image 20230719231703.png|center]]\nAqui o threshold é 14%, logo apenas 2 features atingiram a expectativa e foram consideradas úteis, **age** e **height**, enquanto **weight** não performou bem. Aparentemente deveríamos desconsiderar a última feature, porém \u003cmark style=\"background: #ADCCFFA6;\"\u003edevemos acreditar em apenas uma estimativa?\u003c/mark\u003e\n\n### Distribuição Binomial\nComo em outros diversos métodos em machine learning, a iteração é uma ferramenta útil e que nos trás muitos benefícios, principalmente para validarmos a feature importance utilizando Boruta.\n\nSe realizarmos o processo de ajuste de modelo e contagem de \"acertos\" em 20 iterações, obtemos os seguintes resultados:\n![[Pasted image 20230719232402.png|center]]\n\nAgora como podemos definir um **critério de decisão?** Vamos partir do pressuposto que não temos a menor ideia se uma feature é significante ou não, qual a probabilidade que devemos mantê-la? **O nível máximo de incerteza é 50%, como jogar uma moeda para tomar essa decisão**. \n\nComo cada iteração nos retorna um resultado binário (acerto ou não), \u003cmark style=\"background: #ADCCFFA6;\"\u003euma série de n iterações segue uma distribuição binomial\u003c/mark\u003e e vamos utilizar essa distribuição para tomar a decisão:\n\n![[Pasted image 20230719233226.png|center]]\n\nAqui não teremos um critério 100% objetivo para manter ou remover a feature, em vez disso usaremos áreas de aceitação:\n**Área de recusa**: representada de \u003cmark style=\"background: #FF5582A6;\"\u003evermelho\u003c/mark\u003e, se a distribuição dos acertos de uma feature caírem aqui, consideramos ela não significante e removemos do dataset.\n**Área de dúvida**: representada de \u003cmark style=\"background: #ADCCFFA6;\"\u003eazul\u003c/mark\u003e é a área onde o método é indeciso se devemos manter ou remover a variável, e portanto, *temos a liberdade para tomar a decisão*.\n**Área de aceitação:** representada de \u003cmark style=\"background: #BBFABBA6;\"\u003everde\u003c/mark\u003e, área onde caem as features consideradas significantemente preditivas para o problema em questão, e devem sempre ser mantidas.\n\nAs regiões são definidas selecionando as duas caudas mais extremas da distribuição binomial, onde cada cauda corresponde a aproximadamente 0.5% da distribuição.\n\nEm resumo, após 20 iterações nós podemos tomar decisões com base em estatísticas bem definidas:\n1. Para o problema de inferir o **income**, devemos manter **age** como variável preditiva e remover a variável de **weight**\n2. O método de Boruta foi indeciso com relação a variável **height** e a escolha fica na nossa mão se devemos ou não manter (se não houver extrema necessidade de redução de custo operacional, é recomendável manter as variáveis na zona de dúvida)\n\nApós a definição das variáveis importante, \u003cmark style=\"background: #FF5582A6;\"\u003enão devemos esquecer de desconsiderar completamente as shadow features para o modelo final\u003c/mark\u003e.\n\n### Conclusão\nBoruta é um método que realiza feature selection de maneira estatisticamente robusta, removendo o processo subjetivo de definir o threshold de corte que é necessário em várias outras técnicas de feature selection.","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Brier-Score":{"title":"Brier Score","content":"Métrica de avaliação utilizada para pedir a acurácia e a precisão de modelos de regressão probabilística ou até mesmo para problemas de classificação que possuem o output como probabilidade. É equivalente ao erro quadrático médio ([[Mean Squared Error (MSE)|MSE]]) aplicado às probabilidades previstas.\n\nO Brier Score é calculado como a média dos quadrados das diferenças entre as probabilidades previstas pelo modelo e as probabilidades reais.\n\nSeja **y** o valor real e **p** o valor previsto pelo modelo, o Brier Score é dado por:\n$$Brier Score = (p-y)^2$$\n\nO Brier Score varia entre 0 e 1, onde 0 representa uma previsão perfeita, e 1 representa a pior previsão possível.\n\nDe forma geral, deve ser menor que 0.25\n\n\u003cmark style=\"background: #FF5582A6;\"\u003eDeve ser sempre aplicada à regressões probabilísticas\u003c/mark\u003e\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Classifica%C3%A7%C3%A3o":{"title":"Classificação","content":"Os modelos de classificação \u003cmark style=\"background: #ADCCFFA6;\"\u003eanalisam os dados de entrada e os padrões existentes para fazer previsões ou tomar decisões\u003c/mark\u003e\nUtilizado quando temos o objetivo de atribuir uma categoria ou rótulo a uma entrada com base em características conhecidas. Por exemplo, é possível utilizar algoritmos de classificação para identificar se um e-mail é spam ou não bom base no conteúdo e nas palavras utilizadas.\n\n[[Técnicas de modelagem - Classificação]]\n\n[[Métricas de avaliação - Classificação]]\n\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Clustering":{"title":"Clustering","content":"Um modelo de clustering é uma técnica de machine learning não supervisionada usada para agrupar dados em subgrupos ou clusters com base em suas similaridades. O objetivo é encontrar padrões e estruturas nos dados, agrupando exemplos sem a necessidade de rótulos ou categorias pré-definidas.\n\n[[Técnicas de modelagem - Clustering]]\n\n[[Métricas de avaliação - Clustering]]\n#clustering\n","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Cross-Validation":{"title":"Cross Validation","content":"Técnica utilizada em aprendizado de máquina e estatística para avaliar o desempenho de um modelo de forma mais confiável e evitar problemas de *overfitting*.\n\nPara evitar problemas de selecionarmos um subconjunto dos dados para treinamento que podem acabar gerando um modelo que sofra de *underfit* ou *overfit*, o **Cross Validation** nos oferece a possibilidade de utilizar \u003cmark style=\"background: #FF5582A6;\"\u003etodos\u003c/mark\u003e os dados para treinamento de maneira iterativa e \u003cmark style=\"background: #ADCCFFA6;\"\u003eavaliar a performance média do modelo.\u003c/mark\u003e\n\n\u003cmark style=\"background: #FF5582A6;\"\u003eObs: Cuidado para não reutilizar os dados para treinamento e teste na mesma iteração para não acontecer Data Leakage.\u003c/mark\u003e\n\nNa Cross Validation executamos o processo de modelagem em diferentes subconjuntos dos dados para obtermos várias avaliações de desempenho do modelo.\n\n## Benefícios\nCross-validation nos ajuda a obter uma validação mais assertiva da qualidade do modelo, porém devemos nos \u003cmark style=\"background: #ADCCFFA6;\"\u003eperguntar se o ganho gerado com essa técnica compensa o incremento no custo computacional gerado pelo uso de cross-validation\u003c/mark\u003e.\n\nEm datasets menores, o processamento adicional de executar cross-validation não será significativo, poucos dados também é a situação onde utilizar apenas a separação de train-test não é muito eficiente, \u003cmark style=\"background: #ADCCFFA6;\"\u003eEm resumo quando temos poucos dados, o uso de cross-validation é mais indicado.\u003c/mark\u003e\n\nPara datasets maiores o custo computacional extra é mais expressivo, mas no geral se o modelo não demorar muito para realizar o treinamento utilizar o cross-validation é recomendado pois tende a trazer ganhos de modelagem.\n\n### Hold-Out\nForma mais simples de separar os dados. Define-se um percentual para cada conjunto de dados (treino, validação e teste) e cria-se as amostras. Geralmente utilizado quando há bastante dado, suficiente para que as amostram tenham significância estatística para representar a população.\n![[image3_11zon_3898fc87c8.jpg|center]]\n\n### K-Fold\nNa técnica de K-fold, nós separamos o dataset original em K partes iguais e realizamos cada iteração de experimento em um subconjunto diferentes de folds.\n![[1fXzJ.png|center]]\n\nNo exemplo, realizamos o treinamento no Experimento 1 usando o primeiro fold para teste e todos os outros para treinamento, então realizamos o segundo treinamento no Experimento 2 analogamente. Repetimos esse processo até que cada fold seja utilizada uma vez como teste, garantindo que usamos 100% dos dados como conjunto de teste em algum momento.\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eAo final das K iterações, calcula-se o valor média para a métrica de avaliação, obtendo-se assim uma medida mais confiável sobre a capacidade de predição do modelo\u003c/mark\u003e, além disso, podemos realizar uma divisão em k-fold estratificada. \n\n\n### Leave-one-out\nCaso especifico do **K-Fold, sendo K igual ao número total de dados** N. Nesta abordagem são realizados N cálculos de erro, um para cada dado.\n![[image2_11zon_cac3fb4270.jpg|center]]\n\nApesar de apresentar uma investigação completa sobre a variação do modelo, possui um alto custo computacional, sendo indicado para situações com poucos dados disponíveis.\n\n### Out-of-sample e Out-of-time\n**Out-of-sample** são dados não vistos pelo modelo, não foram utilizados no treino e serão utilizados apenas para a previsão\n\n**Out-of-time** é um out-of-time com dados obtidos posteriormente de quando o modelo foi treinado. São amostras de dados de diferentes períodos de tempo\n\n### Times Series Cross-Validation\nPara modelos de series temporais, podemos considerar uma técnica de cross-validation que utiliza o tempo de captura dos dados para avaliar diferentes períodos de tempo e no entanto, a generalização do modelo para tempo futuro.\n\nComo a ordem dos dados é de extrema importância para series temporais, o corte entre conjunto de treino e teste deve ser definido conforme a cronologia dos dados:\n![[image6_11zon_1664949880.jpg|center]]","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/DBSCAN":{"title":"DBSCAN","content":"O algoritmo de clusterização não hierárquico que considera os clusters como regiões de maior/menor densidade, muito útil para distribuições de dados que não seguem um padrão esférico/convexo.\n\nEsse algoritmo consegue identificar qualquer formato na distribuição dos dados, verificando primariamente a similaridade entre os pontos.\n\nNão exige que o número de clusters seja definido previamente e pode ser utilizado para detectar quais pontos apresentam características de ruído/outliers. \n\nFunciona identificando pontos que estão em regiões densas:\n**Core**: São os pontos que tiverem pelo menos um número específico de pontos (argumento *MinPts*) dentro do raio (argumento *Eps*). **São pontos localizados no interior de um cluster**.\n**Border**: São considerados pontos de fronteiras aqueles que tem um número menos do que o definido pelo MinPts em seu raio, mas está na vizinhança de pelo menos 1 ponto **core**.\n**Noise:** São os pontos que não foram classificados como **core** ou **border**.\n\n![[Pasted image 20230722160043.png|center]]\n\n**Passo a passo:**\n1. Percorre e marca os pontos como **core**, **border** ou **noise**\n2. Desconsiderar os pontos marcados como **noise**\n3. Inserir uma aresta entre cada par de objetos de **core** vizinhos\n4. Cada componente conectado forma uma cluster\n5. Cada border é atribuído ao cluster de um de seus **core** associados\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Divis%C3%A3o-Top-Down":{"title":"Divisão (Top Down)","content":"O algoritmo se inicia com um único cluster, contendo todo o dataset. A observação com maior dissimilaridade (mais distante do cluster a partir de uma determina métrica) é realocado no seu próprio cluster, as observações no cluster antigo que estiverem próximas deste novo cluster serão realocadas nele.\n\nEsse processo se repete até que cada observação se encontre em seu próprio cluster.\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Ensemble":{"title":"Ensemble","content":"Técnica utilizada em que múltiplos modelos (normalmente chamados de **modelos fracos**) são treinados para resolver o mesmo problema e são combinados posteriormente para gerar resultados melhores.\n\nOs modelos fracos (ou aprendizes fracos/modelos base) são aqueles utilizados como blocos para a construção de modelo mais complexos. Na maioria dos casos estes modelos não performam tão bem sozinhos pois podem ter um alto viés e/ou alta variância. \n\nLogo a ideia de **Ensemble** é reduzir viés e/ou variância dos modelos fracos, combinando vários deles com o objetivo de criar um único modelo preditivo forte que atinge melhores performances.\n\nDe forma geral, podemos dizer que **Bagging** irá focar principalmente em obter um modelo de ensemble com menos variância do que seus modelos base, enquanto **Boosting** e **Stacking** principalmente irão tentar produzir modelos fortes com menos viés dos que seus modelos base.\n\n## Bagging\nTambém conhecido como **Bootstrap Aggregating**, essa técnica se baseia na ideia de combinar o resultado de diferentes modelos do mesmo algoritmo que foram ajustados a amostras diferentes do conjunto de dados original. \u003cmark style=\"background: #ADCCFFA6;\"\u003eTal combinação normalmente é feita de forma uniforme, ou seja, o voto de cada modelo possui o mesmo peso.\u003c/mark\u003e\n\nEssa técnica funciona por reduzir a variabilidade aleatória e considerar o voto majoritário, especialmente em modelos instáveis como as de arvore de decisão.\n\nNo *bagging* \u003cmark style=\"background: #ADCCFFA6;\"\u003evárias instâncias do mesmo modelo base são treinadas em paralelo (de forma independente) em diferentes amostragens dos dados\u003c/mark\u003e e depois são \u003cmark style=\"background: #ADCCFFA6;\"\u003eagregados em um processo \"médio\"\u003c/mark\u003e. Como o objetivo é obter um \u003cmark style=\"background: #FF5582A6;\"\u003emodelo com menor variância\u003c/mark\u003e, é por esse motivo que o \u003cmark style=\"background: #FF5582A6;\"\u003emodelo base escolhido deve ter baixo viés e alta variância\u003c/mark\u003e\n\n![[Pasted image 20230717222349.png | center]]\n\n[[Random Forest - Classificação |Random Forest]] é um caso especial de *bagging* com árvore de decisão. Além de cada árvore fazer uma amostragem nos dados, também faz uma amostragem nas variáveis explicativas a serem utilizadas. Dessa forma o modelo dá liberdade para destacar a importância de features diferentes, que em um bagging simples não apareceriam\n\n## Boosting\nEnsemble que reamostra os casos com base no erro do modelo. Ao identificar quais exemplos de treinamento um modelo do conjunto ensemble errou, na próxima reamostragem as observações previstas de forma errada terão mais importância, desta forma os erros serão corrigidos em cada iteração. \n\nExistem vários algoritmos de Boosting, sendo os mais famosos: [[AdaBoost]], [[Gradient Boost]], [[XGBoost]], [[LightGBM]], [[CatBoost]]\n\nAo contrária do *bagging* que tem como objetivo reduzir a variância, Boosting é uma técnica que \u003cmark style=\"background: #ADCCFFA6;\"\u003econsiste em ajustar de forma sequencial vários modelos fraco\u003c/mark\u003es, de forma que uma importância maior é dada para as observações no dataset que tiveram maior erro no modelo anterior da sequência. De forma intuitiva, cada novo modelo irá focar nas observações mais difíceis, dessa forma \u003cmark style=\"background: #ADCCFFA6;\"\u003eobtemos no final do processo um modelo forte com menor viés (mesmo assim é possível perceber que o boosting também pode ter o efeito de reduzir a variância)\u003c/mark\u003e.\n\n![[Pasted image 20230717223104.png | center]]\n\n## Stacking\nGeralmente considera diferentes tipos de modelos fracos (algoritmos diferentes), aprende eles de forma paralela e os combina através do treino de um \"meta-modelo\", para ter uma predição final baseada na predição dos modelos fracos.\n\nNeste métodos os modelos fracos são ajustados de forma independente e o meta-modelo é treinado em cima das predições obtidas dos modelos fracos.\n\nAssumindo que queremos ajustar um *stacking* composto de \"L\" modelos fracos, então devemos:\n- Dividir a base de treino em duas partes\n- Escolher os \"L\" modelos fracos e ajusta-los em uma das  partes divididas (1ª parte)\n- Para cada modelo fraco devemos fazer a predição para as observações contidas na outra parte do dataset (2ª parte)\n- Ajuste o meta-modelo na 2ª parte do dataset dividido, usando as predições obtidas pelos modelos fracos como input\n![[Pasted image 20230717223749.png | center]]\n![[Pasted image 20230717223808.png | center]]\n\n","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Entropia":{"title":"Entropia","content":"Entropia pode ser definida como o grau de impureza de um conjunto. Se a amostra for completamente **homogênea** com relação as classes de um problema, **a entropia é zero**. Se a amostra for **igualmente dividida entre as classes, tem entropia igual a 1**. \n\n$$Entropia = -\\sum_i P_i * log_2P_i$$\nA escolha do atributo para um nó é dada pelo **ganho de informação**, que é definido como a redução na entropia esperada dado cada categoria do atributo.\n\n$$Ganho(A) = Entropia(S) - \\sum^{k}_{i=1}P_i*Entropia(A_i)$$\n$$\n\\begin{aligned}\n  \u0026Entropia(S): \\text{Entropia da amostra no nó pai} \\\\\n  \u0026Entropia(A_i): \\text{Entropia na categoria \"i\" do atributo \"A\"} \\\\\n  \u0026P_i: \\text{Proporção dos dados na categoria \"i\" do atributo \"A\" (comparado com o total de amostras)}\n\\end{aligned}\n$$\n\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/F1-Score":{"title":"F1-Score","content":"Média harmônica entre Precisão e Sensibilidade. Uma boa métrica para ser utilizada em conjunto de dados com classes desbalanceadas.\n$$ F1 = 2 *\\frac{Precisão *Recall}{Precisão + Recall} $$\nSe a precisão ou recall forem baixos, o F1 também será baixo. Ou seja, um modelo com alto F1 é capaz de acertar suas predições (precisão alta) e também recuperar os exemplos da classe de interesse (recall alto).\n\n**Desvantagens**\n- Não indicado para problemas onde uma das métricas utilizadas é de maior interesse (precisão ou recall), pois **assume a mesma importância para ambas**\n- Não considera as classificações dos TN\n\n**Vantagens**\n- Métrica adequada para problemas com **classes balanceadas**\n- Combina precisão e recall em uma métrica única\n- Pode ser utilizado para comparar modelos classificadores\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Feature-Selection":{"title":"Feature Selection","content":"Feature selection é uma técnica usada no campo de aprendizado de máquina e mineração de dados para selecionar um subconjunto relevante e informativo de características (atributos) a partir de um conjunto de dados original. O objetivo da feature selection é reduzir a dimensionalidade dos dados, mantendo apenas as características mais importantes para o problema em questão.\n\nSelecionando as features mais relevantes, a *feature selection* busca:\n- **Reduzir a complexidade**: Diminuir o número de características pode levar a modelos mais simples, rápidos e fáceis de interpretar\n- **Melhorar o desempenho**: Como teremos features mais significantes, os modelos podem obter uma melhor generalização e desempenho em dados não vistos\n- **Evitar overfitting**: Eliminar características irrelevantes ou redundantes pode ajudar a evitar o overfitting, onde o modelo se ajusta muito bem aos dados de treinamento, mas tem baixa capacidade de generalização\n\nVamos conhecer alguns métodos de feature selection\n\n### [[Boruta]]","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Gaussian-Mixture-Models-GMM":{"title":"Gaussian Mixture Models (GMM)","content":"Algoritmos de clusterização como o K-Means apesar de simples entendimento e fácil explicação, possuem limitações como a falta de flexibilidade no formato dos clusters (considera formatos circulares) e a falta de uma medida probabilística de atribuição, ou seja, um elemento é atribuído apenas a um cluster e não se tem ideia da probabilidade dele pertencer a um outro cluster.\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eCom o GMM é possível medir a incerteza na atribuição do cluster,\u003c/mark\u003e incorporando as distância de cada ponto a todos os centroides, e a \u003cmark style=\"background: #ADCCFFA6;\"\u003eforma dos clusters passam a ser elipses\u003c/mark\u003e, podendo se ajustar melhor aos dados.\n\nO modelo GMM tenta encontrar uma mistura de distribuições gaussianas de probabilidades multidimensionais que melhor modelem um conjunto de dados de entrada. Como ele trabalha com probabilidades, é possível saber qual a probabilidade de um elemento pertencer a cada cluster.\n\n![[Pasted image 20230722161112.png|center]]\n\nCada uma das K gaussianas possuem os seguintes parâmetros:\n- Uma **média** que define seu centro.\n- Uma **matriz de covariância** que define sua largura.\n- Uma função de probabilidade que define quão grande a gaussiana será.\n![[Pasted image 20230722161411.png|center]]\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Gini":{"title":"Gini","content":"Indica o poder discriminatório do modelo, está relacionado com a curva ROC-AUC\n$$Gini = 2*AUC-1$$\n![[Pasted image 20230712202438.png]]\nEle varia de 0 a 1, onde 0 representa igualdade perfeita (ou seja, todas as observações têm o mesmo valor) e 1 representa desigualdade máxima (ou seja, uma única observação detém todo o valor)\n\n### Gini como métrica de ganho de informação (Árvore)\nMede o grau de heterogeneidade dos dados, logo pode ser usado para medir a impureza de um **nó**\n$$Gini = 1 - \\sum^{c}_{i=1}P_{i}^{2}$$\n$$\\text{onde, } P_{i}^{2}: \\text{Frequência relativa de cada classe(c) em cada nó (em probabilidade)}$$\nQuando o índice é igual a **zero, indica que o nó é puro**. Por outro lado, quanto mais se aproxima de 1 mais evidências temos de que o nó é **impuro (existem diversas classes dentro da mesma folha)**\n\nEm classificações binárias, utilizar Gini tende a isolar num ramo os registros que representam a classe mais frequente.\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Gradient-Boost":{"title":"Gradient Boost","content":"","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Gradiente-Descendente":{"title":"Gradiente Descendente","content":"Gradiente descendente é um algoritmo de otimização utilizado para encontrar os mínimos de uma função, especialmente para problemas de machine learning e ajuste de modelos paramétricos.\n\nO gradiente indica em qual direção o valor de uma função cresce/decresce com maior velocidade.\n\nConsidere a equação de regressão linear:\n$$Y = \\beta_0+\\beta_1x+\\epsilon$$\nO método do gradiente descendente tem como objetivo minimizar o erro quadrático médio ([[Mean Squared Error (MSE)|MSE]] - função de custo) de forma iterativa (atualizando todos os parâmetros ao mesmo tempo) e consequentemente, encontrar os melhores valores para os coeficientes da equação (nesse exemplo **B0** e **B1**).\n\nO vetor gradiente tem uma direção e uma magnitude, a cada iteração um novo ponto é definido. Os algoritmos de gradiente descendente multiplicam o gradiente por um escalar conhecido como **taxa de aprendizado** para determinar o próximo ponto.\nO valor da taxa de aprendizado é importante, se for muito pequeno pode fazer o algoritmo demorar muito para aprender e se for muito grande pode fazer o algoritmo não convergir.\n![[Pasted image 20230721172614.png|center]]\n\nDe forma geral, taxas de aprendizados menores requerem um número maior de iterações, dado que pequenas variações são feitas a cada passo.","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Means":{"title":"K-Means","content":"Método de agrupamento não hierárquico que utiliza a \u003cmark style=\"background: #ADCCFFA6;\"\u003edistância euclidiana\u003c/mark\u003e entre os pontos para o cálculo do centróide:\n$$d = \\sqrt{\\sum^{n}_{i=1}(x_i - y_i)^{2}}$$\n\nAjusta os centroides dos clusters com base nos valores médios, e \u003cmark style=\"background: #FF5582A6;\"\u003epor utilizar a média é mais sensível a outliers\u003c/mark\u003e.\n\nOs centroides finais podem não ser pontos verdadeiras presentes na base, apenas o valor médios dos pontos presentes no cluster.\n\nObs: A distância de Minkowski é uma generalização da distância euclidiana e da de Manhattan:\n$$d = (\\sum^{n}_{i=1}(x_i - y_i)^{p})^{\\frac{1}{p}}$$\n**Quando P=1** a distância é de Manhattan\n**Quando P=2** a distância é a Euclidiana\n\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Medians":{"title":"K-Medians","content":"Método de agrupamento não hierárquico que utiliza a \u003cmark style=\"background: #ADCCFFA6;\"\u003edistância de Manhattan\u003c/mark\u003e entre os pontos para o cálculo dos centroides:\n$$d=\\sum^{n}_{i=1}(x_i-y_i)$$\nAjusta os centroides com base nos valores medianos de cada dimensão das instâncias atribuídas ao cluster e por considerar a \u003cmark style=\"background: #ADCCFFA6;\"\u003emediana, é menos sensível a outliers\u003c/mark\u003e\n\n\n#clustering","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Medoids":{"title":"K-Medoids","content":"A ideia desse algoritmo é fazer com que os centroides finais sejam pontos verdadeiros, ou seja, dados que de fato estão presentes no dataset. O principal objetivo é tornar os centroides interpretáveis, assim aumentando a interpretabilidade do cluster.\n\nO passo a passo se difere na atualização dos centroides: \u003cmark style=\"background: #ADCCFFA6;\"\u003eao invés de usar a média/mediana de todos os pontos do cluster, é escolhido o ponto com menor valor de custo (objeto que se encontra mais próximo do centro de gravidade do cluster)\u003c/mark\u003e\n\n#clustering","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Modes":{"title":"K-Modes","content":"Método de agrupamento não hierárquico utilizado para agrupar dados categóricos, já que os anteriores funcionam de maneira eficiente apenas para dataset com valores numéricos.\n\nK-Modes define os clusters com base no número de categorias coincidentes entre os dados (número de atributos categóricos comuns que são compartilhados por dois pontos).\n\nSe baseia no algoritmo do K-means com as seguintes alterações:\n1. Utiliza uma medida de dissimilaridade simples para dados categóricos\n2. Substitui a média dos clusters pela moda\n3. Utiliza método de frequência para atualizar os valores das moda\n\nObs: Apesar de trabalhar com variáveis categóricas, as mesmas devem estar no formato numérico para entrar no modelo.\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Prototypes":{"title":"K-Prototypes","content":"É uma modificação do K-Means com K-Modes para trabalhar com datasets que possuem tanto variáveis numéricas quanto categóricas.\n\nEle mede a distância entre as variáveis usando a distância euclidiana e mede a distância entre as variáveis categóricas usando o número de categorias coincidentes.\n\n#clustering","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Log-Loss":{"title":"Log-Loss","content":"![[1 rdBw0E-My8Gu3f_BOB6GMA.webp]]\n\n- Métrica de classificação baseada nas probabilidades. Esta métrica pune previsões incorretas muito confiantes (alta probabilidade), por exemplo, prever uma classe com uma probabilidade de 95% e na realidade a correta ser a outra\n- É uma medição suave de acurácia que incorpora a ideia de confiança probabilística. De forma geral ==não é bom ser utilizada em datasets com classes desbalanceadas==\n- É uma métrica boa para comparação de modelos, para qualquer tipo de problema, quanto menor o valor do log-loss significa melhor predição\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/M%C3%A9tricas-de-avalia%C3%A7%C3%A3o-Classifica%C3%A7%C3%A3o":{"title":"Métricas de avaliação - Classificação","content":"## Introdução\nAs seguintes métricas servem para quantificar o desempenho e a qualidade das previsões feitas por modelos classificadores. Em resumo são usadas para avaliar quão bem um modelo está solucionando o problema em questão, comparar diferentes modelos e selecionar o mais apropriado para a tarefa\n\n### [[Matriz de confusão]]\nResume a volumetria todos os possíveis resultados de predição modelo de classificação\n\n### [[Acurácia]]\nProporção de classificações corretamente classificadas pelo modelo de classificação\n\n### [[Precision]]\nAKA: Precisão\nProporção de observações ==corretamente classificadas como positivas==\n\n### [[Recall]]\nAKA: Sensibilidade\nProporção de ==observações positivas classificadas corretamente==\n\n### [[F1-Score]]\nCombinação de [[Precision]] e [[Recall]], penalizando sempre pela métrica de menor valor\n\n### [[Specificity]]\nAKA: Especificidade\nProporção de ==observações negativas classificadas corretamente==\n\n### [[ROC-AUC]]\nCurva criada a partir da TPR([[Recall]]) e FPR(1-[[Specificity]])\n\n### [[Gini]]\nMedida de dissimilaridade variando de 0 a 1, onde 1 representa dissimilaridade máxima\n\n### [[Log-Loss]]\nMede a discrepância entre as probabilidades previstas pelo modelo de classificação e as classes reais\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/M%C3%A9tricas-de-avalia%C3%A7%C3%A3o-Clustering":{"title":"Métricas de avaliação - Clustering","content":"Como as técnicas de clustering não são supervisionadas, não há resposta para o cálculo do **erro**, porém existem 3 tipos de critérios que podemos considerar para avaliar os agrupamentos gerados:\n\n## Externos\nAvaliam o grau de correspondência entre a estrutura dos grupos (partição ou hierarquia) \u003cmark style=\"background: #ADCCFFA6;\"\u003esob avaliação e informação a priori\u003c/mark\u003e na forma de uma solução de agrupamento esperada ou conhecida.\n\n#### Resultado previamente conhecido:\n- Reconhecimento visual dos clusters naturais (bases em duas ou três dimensões)\n- Opinião de um especialista de domínio\n- Bases geradas sinteticamente com distribuições conhecidas (benchmark)\n- Bases de classificação sob hipótese que classes são clusters\n\n#### Rand Index\nMede a similaridade entre dois clusters (comparação de pares de objetos).\n$$RI = \\frac{a+d}{a+b+c+d}$$\n**a**: Número de pares que pertencem à mesma classe e ao mesmo cluster\n**b**: Número de pares que pertencem à mesma classe e a clusters distintos\n**c**: Número de pares que pertencem à classes distintas e mesmo cluster\n**d**: Número de pares que pertencem à classes e clusters distintos\n**Classes:** Grupos da partição de referência\n**Clusters:** Grupos da partição sob avaliação\n\nO Rand Index pode ser interpretado como a porcentagem de decisões corretas feitas pelo algoritmo. Varia de 0 a 1, onde 0 indica que os clusters não se assemelham em nenhum par de pontos e 1 indica que os clusters são idênticos.\n\n#### Limitações\nViés de favorecer a comparação de partições com níveis mais elevados de granularidade (valores mais elevados ao comparar partições com mais grupos), há mesmo peso para objetos agregados (a) e separados (d), sendo que **d** tende a dominar o índice (quanto mais grupos, mais pares pertencem a grupos distintos)\n\n## Internos\nAvaliam o grau de compatibilidade enrtre a estrutura de grupos sob avaliação e os dados, usando apenas os próprios dados. \n\nComo o **WCSS** utilizado no método de cotovelo.\n\n## Relativos\nAvaliam qual dentre duas ou mais estruturas de grupos é melhor sob algum aspecto. Tipicamente são critérios internos capazes de quantificar a qualidade relativa. \n\nComo o critério da largura de Silhueta (**SWC**)\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/M%C3%A9tricas-de-avalia%C3%A7%C3%A3o-Regress%C3%A3o":{"title":"Métricas de avaliação - Regressão","content":"### Introdução\nAs métricas de avaliação para modelos de regressão são medidas usadas para quantificar o desempenho e a qualidade das previsões feitas por esses modelos. Elas são usadas para avaliar o quão bem o modelo de regressão está ajustando-se aos dados e para comparar diferentes modelos.\n\n### [[Mean Squared Error (MSE)]]\n\n### [[Root Mean Squared Error (RMSE)]]\n\n### [[Mean Absolute Error (MAE)]]\n\n### [[Mean Absolute Percentual Error (MAPE)]]\n\n### [[R²]]\n\n### [[Brier Score]]\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Machine-Learning":{"title":"Machine Learning","content":"Machine learning é um campo da inteligência artificial que se concentra no desenvolvimento de algoritmos e modelos capazes de aprender padrões e tomar decisões com base em dados, sem a necessidade de serem explicitamente programados para cada tarefa especifica. \n\nEssa abordagem ==tende a melhores resultados à medida que temos mais dados== disponíveis para nos auxiliar nas resoluções de problemas.\n\nExistem diferentes tipos de problemas que podem ser abordados com Machine Learning, e eles podem ser agrupados em três grandes grupos: Regressão, Classificação e Agrupamento\n\n## [[Classificação]]\nOs modelos de classificação ==analisam os dados de entrada e os padrões existentes para fazer previsões ou tomar decisões.==\nUtilizado quando temos o objetivo de atribuir uma categoria ou rótulo a uma entrada com base em características conhecidas. Por exemplo, é possível utilizar algoritmos de classificação para identificar se um e-mail é spam ou não bom base no conteúdo e nas palavras utilizadas.\n\n## [[Regressão]]\nOs modelos de regressão buscam ==identificar relações e tendências nos dados para realizar previsões numéricas==.\nUtilizado quando o objetivo é prever um valor contínuo com base em variáveis de entrada. Por exemplo, é possível utilizar algoritmos de regressão para prever o preço de uma casa com base em recursos como tamanho, número de quartos, localização, entre outros.\n\n## [[Clustering]]\nOs modelos de agrupamento buscam identificar estruturas e relacionamentos ocultos nos dados sem a necessidade de rótulos categorias pré-definidas.\nUtilizado quando o objetivo é ==identificar grupos ou clusters naturais nos dados==, onde as observações são semelhantes umas às outras dentro de um mesmo grupo, mas diferentes de observações em outros grupos. Por exemplo, é possível utilizar algoritmos de agrupamento para segmentar clientes com base em seus padrões de compra ou agrupar documentos por tópicos similares.\n\n\n","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Matriz-de-confus%C3%A3o":{"title":"Matriz de confusão","content":"Representa a frequência com que cada classe do modelo é classificada corretamente ou incorretamente. Sua diagonal principal representa as classificações corretas, enquanto as demais células mostram as classificações incorretas.\n![[Untitled.png]]\nA partir de suas informações pode-se calcular diversos outros indicadores de qualidade de classificação\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Mean-Absolute-Error-MAE":{"title":"Mean Absolute Error (MAE)","content":"Representa a média do erro absoluto do modelo de regressão, **penaliza mais os erros com maiores magnitudes**, dando menos importância para os erros pequenos.\n\n$$MAE = \\frac{1}{n}\\sum^{n}_{i=1}|y-\\hat{y}|$$\n### Vantagens\n- Métrica de fácil interpretação, medida sai na mesma escala original dos dados de interesse\n- Pouco sensível à outliers\n\n### Desvantagens\n- Função da métrica não é diferenciável, não pode ser utilizada como função de custo\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Mean-Absolute-Percentual-Error-MAPE":{"title":"Mean Absolute Percentual Error (MAPE)","content":"Transformação do [[Mean Absolute Error (MAE)|MAE]] que representa a média do erro percentual absoluto do modelo de regressão, **penalizando mais os erros com maiores magnitudes**, dando menos importância para os erros pequenos.\n\n$$MAPE = \\frac{100}{n}\\sum^{n}_{i=1}\\frac{|y-\\hat{y}|}{y}$$\n### Vantagens\n- Métrica de fácil interpretação, pois representa o percentual de erro que o modelo nos retorna\n- Pouco sensível à outliers\n\n### Desvantagens\n- Função da métrica não é diferenciável, não pode ser utilizada como função de custo\n#regressão ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Mean-Squared-Error-MSE":{"title":"Mean Squared Error (MSE)","content":"Representa a média dos erros (resíduos) elevado ao quadrado, **penaliza mais os erros com maior diferença**, dando menos importância para os erros pequenos.\n\n$$MSE = \\frac{1}{n}\\sum^{n}_{i=1}(y - \\hat{y})^2 = \\frac{SSR}{n}$$\n### Vantagens\n- Função derivável, pode ser utilizada como função de custo\n\n### Desvantagens\n- Muito sensível a outliers\n- Dificulta a interpretação da métrica pelo resultado ser o quadrado da magnitude real da variável de interesse\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Naive-Bayes":{"title":"Naive Bayes","content":"É um algoritmo de e classificação baseado no Teorema de Bayes e na suposição de independência condicional entre as variáveis explicativas, costumando ter alto viés e baixa variância. **Considerado ingênuo (naive) porque assume total independência entre as variáveis**, mesmo que não seja necessariamente verdade nos dados reais.\n\n*Durante a descrição será utilizado um exemplo de classificação de e-mail como \"\u003cmark style=\"background: #ADCCFFA6;\"\u003eNormal\u003c/mark\u003e\" ou \"\u003cmark style=\"background: #FF5582A6;\"\u003eSpam\u003c/mark\u003e\"*\nO primeiro passo é calcular as probabilidades a priori de cada classe com base na frequência que cada classe ocorre nos dados de treinamento:\n![[Pasted image 20230716151827.png]]\nTambém calculamos as probabilidades condicionais de cada valor de cada característica para cada classe, no nosso exemplo são palavras presentes nos e-mail de treino:\n![[Pasted image 20230716152356.png]]\n\nQuando uma nova observação surge e temos que fazer a predição com Naive Bayes, o algoritmo utiliza as probabilidades calculadas para calcular a probabilidade posterior de cada classe para aquela observação (gera um Score). A classe com maior Score é selecionada como a classe predita para a informação\n\nVamos supor que receber um novo e-mail contendo **\"Dear friend\"** e desejamos utilizar o modelo para classifica-lo como Normal ou Spam, vamos calcular os Scores para cada classe:\n\n$$P(N)*P(Dear|N)*P(Friend|N) = 0.67*0.47*0.29 = 0.09$$\n$$P(S)*P(Dear|S)*P(Friend|S) = 0.33*0.29*0.25 = 0.01$$\nComo a classe predita é derivada da classe com maior Score calculado, definimos esse novo e-mail como \u003cmark style=\"background: #ADCCFFA6;\"\u003eNormal\u003c/mark\u003e\n\nO exemplo **\"Dear friend\"** funciona porque existe, em ambas as classes, observações que apareceram durante os e-mails de treinamento, porém dados discretos faltantes podem se tornar um grande problema bem rápido para o Naive Bayes.\n\nUm exemplo problemático seria classificar um novo e-mail **\"Lunch Money Money Money Money\"** dados que a probabilidade a priori de observar \"Lunch\" no Spam é zero:\n\n$$P(N)*P(Lunch|N)*P(Money|N)^4 = 0.67*0.18*0.06^4 = 0.000002$$\n$$P(S)*P(Lunch|S)*P(Money|S)^4 = 0.33*0.00*0.57^4 = 0$$\n## Como Naive Bayes trata dados faltantes\nNormalmente, o algoritmo de Naive Bayes elimina o problema de dados faltantes realizando uma \"pseudo contagem\" de cada palavra. Não é nada mais do que adicionar uma contagem para **cada palavra em todas as classes**.\n\nAssim podemos recalcular as **probabilidades condicionais** de cada palavra e não corremos o risco de alguma ser zero e impactar o cálculo de qualquer combinação presente no e-mail:\n![[Pasted image 20230716155700.png]]\n\n$$P(N)*P(Lunch|N)*P(Money|N)^4 = 0.67*0.19*0.10^4 = 0.00001$$\n$$P(S)*P(Lunch|S)*P(Money|S)^4 = 0.33*0.09*0.45^4 = 0.00121$$\nAssim classificando o e-mail corretamente como \u003cmark style=\"background: #FF5582A6;\"\u003eSpam\u003c/mark\u003e\n\n## Utilizando dados contínuos\nQuando existe a necessidade de utilizar dados contínuos dentro do Naive Bayes utilizamos na formula  em vez da probabilidade condicional, a verossimilhança da variável considerando as distribuições para cada uma das classes.\n\n*Obs: Probabilidade e Verossimilhança representam informações diferentes em estatística, consultar:[[Probabilidade vs Verossimilhança]]*\n\nVamos seguir com o exemplo de classificar se uma pessoa vai \u003cmark style=\"background: #ADCCFFA6;\"\u003egostar\u003c/mark\u003e ou \u003cmark style=\"background: #FF5582A6;\"\u003enão gostar\u003c/mark\u003e do filme Troll 2:\n![[Pasted image 20230716161544.png]]\n$$P(Gostar) = \\frac{4}{7}=0.57$$\n$$P(N Gostar) = \\frac{3}{7}=0.42$$\nSurge uma nova observação para predizer, com os seguintes dados: Popcorn = 20g, Soda= 500ml e Candy = 100g\n\n$$(1):P(G)*L(Popcorn=20|G)*L(Soda=500|G)*L(Candy=100|G) = 0.57*0.06*0.004*0.000000001$$\n==Para evitar problemas de *Underfloat* quando multiplicamos números muito próximos de zero, uma alternativa é utilizar log natural para transformar toda a fórmula e tornar a multiplicação em adição:==\n\n$$(1):log(0.57*0.06*0.004*0.000000001)$$\n$$log(0.57)+log(0.06)+log(0.004)+log(0.000000001) = -124$$\n$$(2): P(NG)*L(Popcorn=20|NG)*L(Soda=500|NG)*L(Candy=100|NG)$$\n$$log(0.4)*log(0.000000001)*log(0.00008)*log(0.02) = -48$$\nLogo classificamos a nova observação como \u003cmark style=\"background: #FF5582A6;\"\u003eNão Gosta de Troll 2\u003c/mark\u003e\n\n### Vantagens\n- Algoritmo de baixa complexidade computacional e pode ser usado em *\"real time\"*\n- Escalável para datasets grandes (performa bem em base com alta dimensionalidade)\n- Pouco sensível para features não significantes\n- Eficaz em problemas de multiclasses\n- Útil para classificar textos, análise de sentimentos, detecção de spam e sistemas de recomendação\n\n### Desvantagem\n- Supõe que as variáveis são independentes, o que não é verdade na maioria das vezes\n- Mau estimador em probabilidade, suas probabilidades (*predict_proba*) não são tão assertivas\n- Os dados de treino devem representar muito bem a população (preenchimento de variável/público todo capturado na base de treino)\n#classificação ","lastmodified":"2023-08-07T23:34:18.666980198Z","tags":[]},"/Machine-Learning/Machine-Learning/Precision":{"title":"Precision","content":"Métrica que dá ênfase para erros por FP (casos incorretamente classificados como positivos). Responde a pergunta: **Dos exemplos classificados como positivos, quantos são realmente positivos?**\n$$ Precisão = \\frac{TP}{TP+FP} $$\n\n**Desvantagens**\n- Ignora completamente os erros de classificar uma amostra positiva como negativa (falso negativo)\n\n**Vantagens**\n- Métrica adequada para problemas onde existe **grave consequência para falsos positivos**\n- Ao ser utilizado junto à ==Sensibilidade==, traz um insight valioso quando a **classificação positiva é mais relevante**\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Probabilidade-vs-Verossimilhan%C3%A7a":{"title":"Probabilidade vs Verossimilhança","content":"Probabilidade e Verossimilhança são termos comumente intercalados durante conversas sobre Machine Learning. Porém no contexto de estatística cada um tem um papel e descreve informações completamente diferentes.\n\n### Probabilidade\nProbabilidade é uma medida numérica que quantifica a chance de um evento ocorrer e é derivada a partir de uma distribuição, calculando a **área abaixo da curva entre dois pontos**:\n![[Pasted image 20230715180903.png]]\nPor exemplo: dada a distribuição de altura de uma população que segue um Normal com média = 155.7 e desvio padrão = 6.6, podemos calcular a **probabilidade de realizar uma medição e observar um valor entre 142.5 e 155.7cm**. \nA área abaixo da curva no exemplo anterior é igual a 0.48, logo a probabilidade de medirmos alguém que possua o altura no intervalo descrito é de 48%.\n\nAnalogamente é fácil notar que em **qualquer distribuição contínua** ==a probabilidade de observar um valor especifico é sempre **ZERO**==, pois não conseguimos calcular área de um figura com comprimento 0.\n\n### Likelihood\nLikelihood ou Verossimilhança é uma medida estatística que quantifica a plausibilidade de quão bem os parâmetros de um modelo se ajustam aos dados.\n\nSeguindo o exemplo anterior, a verossimilhança é usada para calcular o quão provável é os parâmetros do modelo gerarem exatamente as observações que temos.\n![[Pasted image 20230715182357.png]]\n\nEm resumo, a principal diferença entre probabilidade e likelihood é a direção do raciocínio estatístico. A probabilidade é usada para calcular a chance de eventos futuros com base em um modelo conhecido, enquanto a verossimilhança é usada para estimar os parâmetros do modelo com base em dados observados\n\n#conceitos","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/R":{"title":"R²","content":"Representa a porcentagem de ganho de predição por usar o modelo, quando comparado apenas a média dos dados.\n\n$$R^2=\\frac{SSR(mean)-SSR(fit)}{SSR(mean)}$$\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eO R² também pode ser calculado com o MSE no lugar do SSR\u003c/mark\u003e.\n\nQuanto mais perto o R² se aproximar de 1, melhor o modelo de ajusta ao dados de treinamento em comparação com a média dos valores.\n\nPara verificar o cálculo, vamos seguir com um exemplo que prediz altura com base no peso de uma pessoa:\n\nComeçamos calculando a soma do resíduos ao quadrado da média:\n![[Pasted image 20230718225252.png|center]]\n$$SSR(mean) = (1.2-1.9)^2 +(2.2-1.9)^2 +(1.4-1.9)^2 +(2.7-1.9)^2 +(2.3-1.9)^2 =1.6$$\nEm seguida, calculamos a soma dos resíduos ao quadrado do modelo ajustado:\n![[Pasted image 20230718225552.png|center]]\n$$SSR(fit) = (1.2-1.1)^2 +(2.2-1.8)^2 +(1.4-1.9)^2 +(2.7-2.4)^2 +(2.3-2.5)^2 =0.5$$\nAgora temos todos os componentes necessários para o cálculo da métrica:\n$$R^2=\\frac{SSR(mean)-SSR(fit)}{SSR(mean)}=\\frac{1.6-0.5}{1.6}=0.7$$\nO R² ser 0.7 indica que tivemos uma **redução de 70% no tamanho dos resíduos** por usar a reta ajustada pelo modelo.\n\n### Relação com Correlação de Pearson\nA correlação de Pearson pode ser calculada a partir do R² com a seguinte relação:\n$$R^2 = r^2 =\\rho^2$$\n### R² ajustado\n\n\n\n#todo \nR² ajustado\nrelacionar R² com p-valor\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/ROC-AUC":{"title":"ROC-AUC","content":"Avalia a performance de um classificador para diferentes limiares de classificação, relacionando a Taxa de Falso Positivo (FPR) e a Taxa de Verdadeiro Positivo (TPR)\n$$TPR = \\frac{TP}{TP+FN}; FPR = \\frac{FP}{FP+TN}$$\n![[Pasted image 20230712201216.png]]\n-  Quanto mais próxima a curva estiver do canto superior esquerdo melhor é a predição do modelo, uma vez que sua TPR = 100% com FPR = 0%\n-  Linha tracejada indica qual seria a curva que atribui as classes aleatoriamente\n-  Área sob a curva (AUC) pode ser usada como métrica do modelo\n-  ==Métrica pouco sensível a problemas de classes desbalanceadas==\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Random-Forest-Classifica%C3%A7%C3%A3o":{"title":"Random Forest - Classificação","content":"Random Forest é um algoritmo que realiza o [[Ensemble]] de várias [[Árvores de decisão - Classificação|Árvores de decisão]] para realizar classificação em problemas complexos. Ele utiliza um conjunto de árvores de decisão aleatórias e faz **predição com base em uma votação majoritária das árvores individuais**\n\nUtilizando **Bagging** para criar diferentes conjuntos de treinamento a partir do conjunto de dados original. Cada conjunto de treinamento é obtido através de uma amostragem aleatória com reposição, o que permite que exemplos se repitam ou sejam omitidos em cada conjunto.\n\nPara cada conjunto de treinamento é construída uma [[Árvores de decisão - Classificação|Árvore de decisão]]. Durante a construção o algoritmo seleciona um subconjunto aleatório de features a partir do conjunto total de características. Isso ajuda a reduzir a correção entre as árvores e aumentar a diversidade do conjunto de árvores.\n\nApós a construção de todas árvores, a Random Forest faz a classificação de um exemplo de teste através de uma votação majoritária. Cada árvore dá o seu voto e a classe mais votada é considerada a classe final predita.\n\nTambém pode ser utilizada para fornecer uma medida de importância de cada feature, calculando a **redução média do índice Gini** ou do **ganho de informação** ao usar cada característica para dividir os nós das árvores, ajudando a identificar quais são as features mais importantes para o problema\n\nEm resumo Random Forest é muito utilizado por sua capacidade de lidar com dados complexos, grande quantidade de features e tendência de *overfitting*. Ele combina as previsões de várias árvores de decisão (modelos fracos) para **reduzir a variância** e **melhorar a precisão geral** do modelo.\n\n### Vantagens\n- Erro reduzido (em comparação a uma árvore de decisão)\n- Boa performance em datasets desbalanceados\n- Pode trabalhar com conjunto de dados muito grandes\n- Lida bem com valores nulos\n- Não tem problema tão grande de *overfitting*, pela utilização de várias árvores aleatórias\n- Não sensível a outliers\n- Útil para extrair o feature importance\n\n### Desvantagem\n- Features precisam ter importância para predição, se não pode prejudicar o algoritmo\n- Predições das árvores não devem estar correlacionadas\n- Abre mão da interpretabilidade/processo de tomada de decisão pela performance\n\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Recall":{"title":"Recall","content":"Também conhecida como taxa de verdadeiro positivo (TPR), dá maior ênfase para erros por FN (casos incorretamente classificados como negativos).\n\nResponde a pergunta: Dos exemplo positivos, quantos foram classificados corretamente?\n$$ Sensibilidade = \\frac{TP}{TP+FN} $$\n**Desvantagens**\n- Não considera erros ao classificar amostras negativas como positivas (falso positivo)\n\n**Vantagens**\n- Métrica adequada para problemas onde existe **grave consequência para falsos negativos**\n- Ao ser utilizado junto à Precisão, traz um insight valioso quando a **classificação positiva é mais relevante**\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Rede-Neural":{"title":"Rede Neural","content":"","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Regress%C3%A3o":{"title":"Regressão","content":"Um modelo de regressão é uma técnica estatística usada para modelar a relação entre uma variável dependente contínua e uma ou mais variáveis independente. \n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eO objetivo é encontrar uma função matemática que descreva essa relação e permita fazer previsões ou inferências sobre os valores da variável dependente com base nas variáveis independentes.\u003c/mark\u003e\n\n[[Técnicas de modelagem - Regressão]]\n\n[[Métricas de avaliação - Regressão]]\n\n#regressão\n","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Regress%C3%A3o-Linear":{"title":"Regressão Linear","content":"Tipo de regressão em que os coeficientes podem ser expressos por uma combinação linear de elementos (b0, b1, b2, ...), os quais são justamente os valores que não sabemos.\n\n### Simples\nSó temos uma variável independente:\n$$Y = \\beta_0+\\beta_1X$$\n### Múltipla\nTemos mais de 1 variável independentes para explicar Y\n$$Y = \\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_nX_n$$\n### Polinomial\nFormada por uma equação polinomial \n$$Y = \\beta_0+\\beta_1X+\\beta_2X^2+...+\\beta_nX^n$$\n## Hipóteses consideradas\n- **Variáveis Explicativas**:\n\t- **Linearidade**: a variável resposta y deve estar linearmente correlacionada com as variáveis explicativas \"x\"\n\t- **Falta de multicolinearidade**: A multicolinearidade deixa os coeficientes instáveis, modelo não consegue atribuir bons valores para coeficientes de variáveis altamente correlacionadas\n\n- **Erros**:\n\t* **Normalidade Multivariada**: os erros devem ter uma distribuição normal\n\t* **Independentes e identicamente distribuídos (iid)**: depois de treinar o modelo, os erros do modelo devem ser variáveis aleatórias independentes (não ter interseção) e devem ser identicamente distribuídas (ter a mesma função de distribuição acumulada). Por definição, uma variável aleatória é uma variável \"iid\" \n\t* **Homocedasticidade**: Os erros devem ter uma variância constante, ou seja, não podem ter um padrão em relação ao eixo x\n![[Pasted image 20230717220328.png | center]]\n### Principais causas de heterocedasticidade nos resíduos\n- Natureza das variáveis: alguns relacionamentos apresentam tendência à heterocedasticidade\n- Outliers: um valor extremo na amostra pode inflacionar a variabilidade me um determinado ponto do ajuste\n- Falhas na especificação do modelo: omissão de variáveis importantes, explicativas\n- Transformação dos dados: utilização de transformações (como proporções, log, etc) pode reduzir a heterocedasticidade\n- Em resumo, os erros (resíduos) não devem ser correlacionadas, ter a média zero, variância constante e ter distribuição normal\n\nObs: para verificar se uma variável possui distribuição normal em uma amostra, podemos fazer o teste de **Shapiro Wilk**\n\n#todo \ncompletar após ver statquest\n\n#regressão","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Regress%C3%A3o-Logistica":{"title":"Regressão Logistica","content":"A regressão logística é uma técnica de [[Classificação]] que nos ajuda a estimar uma curva para predizer a probabilidade (entre 0 e 1) de features discretas utilizando variáveis contínuas e/ou discretas, por exemplo se um cliente está insatisfeito ou satisfeito.\n\nO eixo y na regressão logística representa a probabilidade de uma observação pertencer a alguma classe do problema, e a curva de ajuste do modelo(roxo) nos dá a probabilidade predita da pessoa pertencer a uma determinada classificação.\n\nOs parâmetros são estimados **maximizando a função de log verossimilhança** do modelo a partir dos dados de treino. Uma vez que temos os parâmetros definidos determinamos se uma observação faz parte de determinada classe realizando com o auxilio de um corte no valor da probabilidade (geralmente 0.5).\n![[Pasted image 20230714175014.png]]\n\n==Existe a possibilidade de ajustar o ponto de corte de probabilidade para melhor adequar a predição ao problema em questão, é um método muito utilizado quando utilizamos a [[ROC-AUC]] como métrica de avaliação==\n\nNo exemplo abaixo, temos um modelo que infere se uma pessoa gosta do filme Troll 2, com a linha no ponto de corte de 50% de probabilidade.\n![[Pasted image 20230715175805.png]]\n*Normalmente é utilizado a log verossimilhança para evitarmos problemas de erro computacional (Underflow), para em vez de multiplicarmos números muito pequenos, somamos*\n\nSimilar à [[Regressão Linear]] também é possível avaliar o desempenho da predição com um **\"pseudo\" R²** (McFadden's R²) e calculando o **p-valor**, além das métricas usuais para classificação\n\n### Vantagens\n- Implementação simples\n- Score de probabilidade para as observações (pode ser utilizado no auxílio do problema)\n- Fácil interpretabilidade de como a saída do modela foi calculada\n- Não é necessário realizar *feature scaling*\n- Não é necessário realizar tunning de hiperparâmetros\n\n### Desvantagem\n- Baixo desempenho com dados não lineares\n- Baixo desempenho com variáveis de baixo poder preditivo (pouca significância) \n- Algoritmo não tão poderoso, normalmente superado por técnicas mais recentes e robustas\n* A regressão logística sempre assume podemos atribuir uma curva em \"forma de S\" para predizer os dados, quando temos correlação com a resposta que oscila durante a distribuição das variáveis descritivas a condição para uso de regressão logística não é satisfeita:\n\t![[Pasted image 20230715193458.png]]\n\tPara problemas que os dados tem relação mais complexas (não linearidade), podemos seguir com as técnicas de [[SVM]], [[Árvores de decisão - Classificação]] ou [[Rede Neural]] \n* Sensível a outlier nos dados de treinamento, principalmente na determinação dos coeficientes\n\n#todo \n- [ ] entender como funciona a generalização one-vs-rest\n\n#classificação","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Regulariza%C3%A7%C3%A3o":{"title":"Regularização","content":"Técnicas utilizadas para evitar *overfitting* e ajudar na seleção de variáveis de **Modelos Lineares Generalizados (GLM)**\n\n## Lasso (L1)\nO lasso adiciona uma **penalidade igual ao valor absoluto da magnitude dos coeficientes multiplicados por um lambda**\n$$L1 =\\sum^{n}_{i=1}(y_i - \\sum^{p}_{j=1}X_{ij}\\beta_j)^2 + \\lambda\\sum^{p}_{j=1}|B_j|$$ ou simplificando os termos:\n$$L1 = SSR - \\lambda*|\\text{slope}|$$\n![[Pasted image 20230718215505.png | center]] \n**Obs:**\n- Se **lambda = 0**, temos a função de custo padrão\n- Se **lambda tende a 0**, temos uma aproximação do modelo sem regularizador (pode não tratar o overfitting)\n- Se **lambda tende a infinito**, temos uma aproximação de um modelo que despreza qualquer efeito das features, tende ao *underfitting* pois os **coeficientes tenderão a zero**\n\n- Pelo fato de usar o módulo no termo de penalidade, e não elevar ao quadrado, **pode zerar os coeficientes** de variáveis pouco importantes e por conta disso **pode ser utilizado para seleção de variáveis**.\n- O lasso adiciona um penalidade aos coeficientes que o modelo enfatiza demais, isso reduz o grau de *overfitting* do modelo.\n- Lasso tende a se sair bem quando há poucas features significativas e a magnitude das demais features for próxima de zero.\n- \u003cmark style=\"background: #FF5582A6;\"\u003eLasso não lida bem com multicolinearidade\u003c/mark\u003e, pois pode eliminar de forma aleatória variáveis correlacionadas, podendo eliminar alguma que seja relevante para o modelo.\n\n## Ridge (L2)\nAdiciona uma **penalidade igual ao quadrado da magnitude dos coeficientes multiplicado por um lambda.**\nComo no lasso, adiciona uma penalidade aos coeficientes que o modelo enfatiza demais, porém, por elevar ao quadrado **não tem a capacidade de zerar coeficientes e auxiliar no feature selection**\n\n$$L2 =\\sum^{n}_{i=1}(y_i - \\sum^{p}_{j=1}X_{ij}\\beta_j)^2 + \\lambda\\sum^{p}_{j=1}B^2_j$$\nou simplificando os termos:\n$$L2 = SSR - \\lambda*\\text{slope}^2$$\n![[Pasted image 20230718215644.png | center]]\n- Interessante para ser usada quando há multicolinearidade e não se pode descartar nenhuma variável\n- Quando duas features são correlacionadas e seus coeficientes estão muito desproporcionais, a Ridge faz com que as features correlacionadas tenham coeficientes parecidos.\n- Funciona bem se há varias features minimamente importantes.\n- Por não eliminar features não importantes, pode ser ruim ao utilizar em bases com muitas features.\n![[Pasted image 20230718214432.png | center]]\n\n## Elastic Net\nElastic Net combina as características da Lasso e Ridge. **Ela reduz o impacto de diferentes features ao mesmo tempo que não elimina todas as features.**\n\n$$\\text{Elastic Net} =\\sum^{n}_{i=1}(y_i - \\sum^{p}_{j=1}X_{ij}\\beta_j)^2 + \\lambda_1\\sum^{p}_{j=1}|B_j| + \\lambda_2\\sum^{p}_{j=1}B^2_j$$\nComo funciona sendo a combinação de L1 e L2, é necessário o ajuste de 2 hiperparâmetros, porém oferece um melhor equilíbrio geral no requisito de regularizador.","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Root-Mean-Squared-Error-RMSE":{"title":"Root Mean Squared Error (RMSE)","content":"Representa a raiz quadrada da média dos erros (resíduos) elevado ao quadrado (raiz do [[Mean Squared Error (MSE)|MSE]]), **penaliza mais os erros com maior diferença**, dando menos importância para os erros pequeno.\n$$RMSE = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}(y - \\hat{y})^2}$$\n### Vantagens\n- Função derivável, pode ser utilizada como função de custo\n- Métrica de fácil interpretação, medida sai na mesma escala original dos dados de interesse\n### Desvantagens\n- Muito sensível a outliers\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/SVM":{"title":"SVM","content":"Support Vector Machine tem o objetivo de encontrar a **fronteira de decisão** que consiga separar o conjunto de dados em classes. **O SVM busca a linha ou hiperplano que melhor separa os dados**, maximizando a distância entre os pontos e a fronteira.\n\nPara encontrar esse hiperplano o SVM usa um processo de minimização para encontrar os pontos que servirão de suporte para criar o vetor delimitante de fronteira, tais pontos são encontrados de forma a maximizar a distância entre eles e a fronteira.\n\nO SVM em sua formulação original apenas será capaz de modelar problemas de classificação binária, porém técnicas podem ser aplicadas para fazer expansão para problemas multiclasses, além de problemas regressivos. \u003cmark style=\"background: #ADCCFFA6;\"\u003eEm sua forma original, é um classificador linear, porém pode ser utilizados em problemas não lineares utilizando o \"Kernel Trick\"\u003c/mark\u003e.\n\n## Soft Margin\n\nQualquer variação na posição dos pontos próximos à fronteira pode influenciar de maneira forte a posição do hiperplano. Dessa forma, o **soft margin** tem como objetivo permitir que o SVM cometa uma certa quantidade de erros e mantenha a margem o mais larga possível, para que outros pontos ainda possam ser classificados corretamente **(Pode ser interpretado como um trade-off entre viés e variância)**.\n- Ajuda a reduzir o problema de *overfitting*, uma vez que com uma margem mais larga é possível generalizar melhor dados não vistos.\n- É feito utilizando o hiperparâmetro \"C\": decide o trade-off entre maximizar a margem e minimizar os erros. Quando \"C\" é pequeno, os erros de classificação recebem menos importância e o foco maior é em maximizar a margem, todavia quando \"C\" é grande, o foco é mais em evitar erros de classificação ao custo de manter a margem mais estreita\n\n## Kernel Trick\n\nQuando os dados não são linearmente separáveis a solução é aumentar a dimensionalidade, de forma que em uma nova projeção os dados sejam linearmente separáveis. O aumento de dimensionalidade é feito utilizando uma função **(kernel)**, a qual mapeia os dados em outro espaço.\n\nO \u003cmark style=\"background: #ADCCFFA6;\"\u003eKernel Trick\u003c/mark\u003e se refere ao fato do SVM, a partir dos kernels, ser capaz de calcular a relação entre os dados em dimensionalidade aumentada sem que de fato os dados sejam transformados para uma maior dimensão. Fator que torna possível utilizar o Kernel RBF que funciona com dimensionalidade infinita e que as relações sejam calculadas.\n![[Pasted image 20230716214419.png | center]]\n- Os **Kernels** mais utilizados são:\n\t- RBF (Radial Basis Function), sendo a principal a Gaussiana\n\t- Polinomial\n\t- Sigmoide\n![[Pasted image 20230716214548.png | center]]\n![[Pasted image 20230716214601.png | center]]\n\n### Vantagens\n- Boa performance em problemas com alta dimensionalidade (muitas features)\n- Ótimo algoritmo quando as classes são separáveis\n- Pouco sensível a outliers\n- Mais adequado para classificações binárias\n\n### Desvantagem\n- Custo computacional elevado para datasets muito grandes (requer bastante processamento para alterar a dimensionalidade)\n- Todas as features devem ser numéricas\n- Não performa bem quando as classes estão muito sobrepostas\n- Requer cuidado para selecionar de forma apropriada os hiperparâmetros (C, Kernel, etc)\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/Specificity":{"title":"Specificity","content":"Representa o oposto do Recall, demonstra a taxa de acerto na classe negativa obtida pelo classificador.\nResponde a pergunta: De todos os casos negativos, quantos foram classificados corretamente?\n$$ Especificidade = \\frac{TN}{TN+FP} $$\n$$ FPR = 1 - especificidade $$\n**Desvantagens**\n- Não mede o desempenho completo do modelo\n- Pode ser ilusório em problemas com **desbalanceamento de classes**\n\n**Vantagens**\n- Medida direta da capacidade do classificador **evitar falsos positivos**\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.698980978Z","tags":[]},"/Machine-Learning/Machine-Learning/T%C3%A9cnicas-de-modelagem-Classifica%C3%A7%C3%A3o":{"title":"Técnicas de modelagem - Classificação","content":"\n[[Árvores de decisão - Classificação]]\n\n[[Random Forest - Classificação]]\n\n[[XGBClassifier]]\n\n[[Naive Bayes]]\n\n[[Regressão Logistica]]\n\n[[SVM]]\n\n[[KNN]]\n\n[[Rede Neural]]\n\n\n#classificação ","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/T%C3%A9cnicas-de-modelagem-Clustering":{"title":"Técnicas de modelagem - Clustering","content":"\n## Agrupamento Não Hierárquico\nTécnica de aprendizado não supervisionado em que o objetivo é encontrar nos dados uma estrutura de agrupamento natural, agrupando indivíduos com base na similaridade ou distâncias (dissimilaridades).\n- **Partição rígida**: Todos os pontos do dataset possuem um cluster, sendo que nenhum cluster fica vazio e não existe intersecção entre eles.\n- **Objetivo:** \u003cmark style=\"background: #ADCCFFA6;\"\u003eMinimizar distância intra-cluster\u003c/mark\u003e (pontos dentro de um mesmo cluster estão pertos um dos outros) e \u003cmark style=\"background: #ADCCFFA6;\"\u003emaximizar a distância inter-cluster\u003c/mark\u003e (pontos em diferentes cluster estão distantes)\n\n#### Passo a passo geral:\n1. Escolher o número **k** de clusters\n\t1. Pode ser utilizado métodos como cotovelo, silhueta, etc\n2. Selecionar os centroides iniciais (não necessariamente pontos presentes no dataset)\n\t\tA inicialização pode gerar clusters diferentes (\u003cmark style=\"background: #FF5582A6;\"\u003eproblema de sensibilidade da inicialização\u003c/mark\u003e). Maneira de lidar com esse problema são:\n\t\t**Repetição:** Repetir o algoritmo e a inicialização diversas vezes e escolher a clusterização que tiver menor distância intra-cluster e maior distância inter-cluster\n\t\t**K++ (K-means ++, K-medians ++, etc):** Técnica inteligente para inicialização dos centroides em que o 1º é escolhido de forma aleatória a partir dos dados e os demais centroides são escolhidos a partir dos pontos restantes com probabilidade proporcional à distância ao quadrado do centroide mais próximo\n3. Atribuir para cada ponto o cluster do centroide mais próximo\n4. Avaliar e recalcular a nova posição dos centroides de cada cluster\n5. Repetir os passos 3 e 4 até atingir a convergência (elementos não trocam mais de grupos após recalculo de centroides)\n\n##### [[K-Means]]\n\n##### [[K-Medians]]\n\n##### [[K-Modes]]\n\n##### [[K-Medoids]]\n\n##### [[K-Prototypes]]\n\n#### Definição do número K de clusters\n\n##### Método do cotovelo\nConsiste em traçar uma curva do WCSS (Within-Cluster Sum of Square ou soma do quadrado das distâncias intra-cluster) e o número de clusters. O valor de k a ser escolhido será aquele em que a variação do WCSS torna-se menos discrepante:\n![[Pasted image 20230721235857.png|center]]\n**Passo a passo:**\n1. Realizar a clusterização para diferentes valores de K (ex: 1 até 10)\n2. Para cada K, calcular a soma total dos quadrados das distâncias intra-cluster (inercia)\n3. Plotar a curva de WCSS contra K\n4. O local do **cotovelo** no gráfico indicará o número apropriado de clusters\n![[Pasted image 20230722000449.png|center]]\n\n##### Método da Silhueta\nConsiste em plotar o valor médio do coeficiente de silhueta para diferentes valores de K. O número ótimo de clusters será aquele que tiver o valor máximo da silhueta:\n![[Pasted image 20230722000349.png|center]]\nO coeficiente de silhueta mede a qualidade da clusterização, ou seja, ele determina quão bem cada ponto está dentro do seu cluster. Um valor alto indica uma boa clusterização.\n![[Pasted image 20230722000506.png|center]]\n\nO coeficiente nos diz se os pontos estão corretamente atribuídos aos seus clusters:\n**S(i) próximo de 0:** o ponto encontra-se entre dois clusters\n**S(i) próximo de -1:** o ponto teria sido melhor classificado em outro cluster\n**S(i) próximo de 1:** o ponto foi agrupado corretamente\n\n## Agrupamento por Densidade\n#### [[DBSCAN]]\nO algoritmo de clusterização não hierárquico que considera os clusters como regiões de maior/menor densidade, muito útil para distribuições de dados que não seguem um padrão esférico/convexo.\n\n## Agrupamento Hierárquico\nTécnica de clusterização que baseia-se no tamanho e distância (medida de dissimilaridade/similaridade) dos dados em um conjunto. \n\nPara realizar a clusterização é necessário definir a métrica de distância a ser utilizada (euclidiana, manhattan, etc) e um critério de ligação. Essa técnica produz de 1 a N clusters, sendo N o número de observações presentes no dataset, ocorrendo por processo de **aglomeração (bottom up)** ou por **divisão (top down)**.\n\n**Vantagens:** Fácil implementação, produz um dendograma (facilita no entendimento de como a clusterização foi realizada), técnica menos sensível a outliers\n**Desvantagens:** As vezes pode ser difícil identificar um número ideal de clusters, mesmo com a ajuda do dendograma. Geralmente requer um maior tempo para o algoritmo terminar de rodar.\n\n##### [[Aglomeração (Bottom Up)]]\n\n##### [[Divisão (Top Down)]]\n\n![[Pasted image 20230722154126.png|center]]\n\n### Critérios de ligação\n![[Pasted image 20230722154335.png|center]]\n\n##### Single Linkage\nTécnica de **vizinho mais próximo**, é a menor distância entre dois pontos dentro de dois clusters. As vezes pode produzir clusters onde as observações em diferentes clusters estão mais próximas do que as observações dentro de seu próprio cluster.\n\nEsses clusters podem aparecer de forma espalha e no \u003cmark style=\"background: #FF5582A6;\"\u003egeral são sensíveis a outliers\u003c/mark\u003e.\n\n##### Complete Linkage\nTécnica de **vizinho mais distante**, é a maior distância entre dois pontos em dois clusters. Geralmente produz clusters mais compactos do que o método de **single linkage**, mas esses clusters podem acabar ficando muito próximos.\n\nUma das métricas mais populares e são \u003cmark style=\"background: #FFB86CA6;\"\u003emenos sensíveis a outliers\u003c/mark\u003e.\n\n##### Average Linkage\nA distância entre cada par de pontos em cada cluster é somada e dividida pelo número de pares para ser obter uma distância média. \n\nTão popular quanto **complete linkage** porém \u003cmark style=\"background: #BBFABBA6;\"\u003emuito menos sensível a outliers\u003c/mark\u003e.\n\n![[Pasted image 20230722154935.png|center]]\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eDependendo de como os dados estão distribuidos, o critério de ligação escolhido pode alterar muito a agrupamento gerado.\u003c/mark\u003e\n\n## Agrupamento por Distribuição Probabilística\n#### [[Gaussian Mixture Models (GMM)]]\nAlgoritmo de clusterização que é mais flexível no formato dos clusters e nos fornece uma medida probabilística de atribuição a um determinado cluster\n\n\n\n#todo \nestudar inicialização K++\n\n#clustering ","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/T%C3%A9cnicas-de-modelagem-Regress%C3%A3o":{"title":"Técnicas de modelagem - Regressão","content":"\n[[Regressão Linear]]\n\n[[Árvores de decisão - Regressão]]\n\n\n#regressão ","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/Todo":{"title":"Todo","content":"#todo\n- [x] Viés e Variância  \n- [x] Boruta\n- [x] Árvore de Decisão/Regressão  \n- [x] Ensemble Methods  \n- [x] Bagging  \n- [x] Random Forest  \n- [x] Boosting  \n- [x] Overfit e Underfit  \n- [x] Cross Validation \n- [x] Regularização (L1 e L2)  \n- [x] Métricas de Avaliação (Classificação, Regressão e Clustering)  \n\t- [x] Classificação\n\t- [x] Regressão\n\t- [x] Clustering\n- [x] Clustering  \n\n  \n- [x] Gradient Boosting  \n- [ ] XGBoost  \n\t- [x] XGBClassifier\n\t- [ ] XGBRegressor\n- [ ] Calibragem \n- [x] Regressão Logística  \n- [x] Regressão Linear  \n- [ ] Tunagem de Hiperparametros (Hyperopt, optuna, Grid Search, Random Search)  \n- [x] K-Means  \n- [x] Hierárquico  \n- [x] DBSCAN  \n- [ ] Tipos de aprendizado - supervisionado/nao supervisionado/semi supervisionado\n\n- [x] Hard Clustering / Soft Clustering\n- [ ] Complexidade Computacional\n- [ ] Rede Neurais\n\t- [x] basico\n\t- [ ] convolucao +\n  \n- [x] Xtrees  \n- [ ] Light GBM  \n- [ ] CatBoost  \n- [ ] Data Augmentation  \n- [x] Naive Bayes  \n- [ ] KNN  \n- [x] SVM  \n- [ ] PCA  \n \n- [ ] AdaBoost  \n- [ ] GLM  \n- [x] K-Medoides / K-Prototypes  \n- [x] GMM\n\n- Linear Regression\n- [ ] [A BEGINNERS GUIDE TO REGRESSION TECHNIQUES](https://analyticsindiamag.com/a-beginners-guide-to-regression-techniques/)\n- [ ] [Linear Regression Algorithm | Linear Regression in Python | Machine Learning Algorithm | Edureka - YouTube](https://www.youtube.com/watch?v=E5RjzSK0fvY)\n- [ ] [In Depth: Linear Regression | Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html)\n- [ ] [Linear Models - YouTube](https://www.youtube.com/playlist?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU)\n- [ ] [Statistics 101: Linear Regression, The Very Basics - YouTube](https://www.youtube.com/watch?v=ZkjP5RJLQF4\u0026list=PLIeGtxpvyG-LoKUpV0fSY8BGKIMIdmfCi\u0026index=1)\n- [ ] [How to Implement Linear Regression From Scratch in Python](https://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/)\n- [ ] [Linear Regression using Python - Towards Data Science](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2)\n- [ ] [Mathematical explanation for Linear Regression working - GeeksforGeeks](https://www.geeksforgeeks.org/mathematical-explanation-for-linear-regression-working/)\n- [ ] [Gradient Descent in Linear Regression - GeeksforGeeks](https://www.geeksforgeeks.org/gradient-descent-in-linear-regression/)\n- [ ] [ML | Normal Equation in Linear Regression - GeeksforGeeks](https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/)\n- [ ] [Univariate Linear Regression in Python - GeeksforGeeks](https://www.geeksforgeeks.org/univariate-linear-regression-in-python/)\n- [ ] [How to do Linear Regression and Logistic Regression in Machine Learning?](https://mlfromscratch.com/machine-learning-introduction-8-linear-regression-and-logistic-regression/#/)\n- [ ] [Linear Regression (Python Implementation) - GeeksforGeeks](https://www.geeksforgeeks.org/linear-regression-python-implementation/)\n- [ ] [ML | Multiple Linear Regression using Python - GeeksforGeeks](https://www.geeksforgeeks.org/ml-multiple-linear-regression-using-python/)\n- [ ] [Python | Implementation of Polynomial Regression - GeeksforGeeks](https://www.geeksforgeeks.org/python-implementation-of-polynomial-regression/)\n- [ ] [Simple Linear Regression From Scratch in Numpy - Towards Data Science](https://towardsdatascience.com/simple-linear-regression-from-scratch-in-numpy-871335e14b7a)\n- [ ] [A Complete Tutorial on Ridge and Lasso Regression in Python](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n- [ ] [Python/linear_regression.py at master · TheAlgorithms/Python](https://github.com/TheAlgorithms/Python/blob/master/machine_learning/linear_regression.py)\n- [ ] [Python | Linear Regression using sklearn - GeeksforGeeks](https://www.geeksforgeeks.org/python-linear-regression-using-sklearn/)\n- [ ] [ML | Locally weighted Linear Regression - GeeksforGeeks](https://www.geeksforgeeks.org/ml-locally-weighted-linear-regression/)\n- [ ] [Statistics PL15 - Multiple Regression - YouTube](https://www.youtube.com/playlist?list=PLIeGtxpvyG-IqjoU8IiF0Yu1WtxNq_4z-)\n- [ ] [Statistics PL18 - Nonlinear Regression - YouTube](https://www.youtube.com/playlist?list=PLIeGtxpvyG-KE0M1r5cjbC_7Q_dVlKVq4)\n- [ ] [Isotonic Regression is THE Coolest Machine-Learning Model You Might Not Have Heard Of](https://towardsdatascience.com/isotonic-regression-is-the-coolest-machine-learning-model-you-might-not-have-heard-of-3ce14afc6d1e)\n- Logistic Regression\n- [ ] [Logistic Regression - YouTube](https://www.youtube.com/playlist?list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe)\n- [ ] [TLM | Logistic Regression](https://www.thelearningmachine.ai/logistic)\n- [ ] [Logistic regression - Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression)\n- [ ] [Maximum likelihood and gradient descent demonstration – Zlatan Kremonic](https://zlatankr.github.io/posts/2017/03/06/mle-gradient-descent)\n- [ ] [An Introduction to Logistic Regression - Towards Data Science](https://towardsdatascience.com/an-introduction-to-logistic-regression-8136ad65da2e)\n- [ ] [A Gentle Introduction to Logistic Regression With Maximum Likelihood Estimation](https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/)\n- [ ] [Logistic model - Maximum likelihood](https://www.statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood)\n- SVD\n- [ ] [Gilbert strang - SVD](https://www.youtube.com/watch?v=rYz83XPxiZo)\n- [ ] [You Don’t Know SVD (Singular Value Decomposition)](https://towardsdatascience.com/svd-8c2f72e264f)\n- [ ] [(114) A geometrical interpretation of the SVD - YouTube](https://www.youtube.com/watch?v=NsNNI_-JPUY)\n- [ ] [SVD playlist](https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv)\n- [ ] [Gilbert strang - Computing Eigenvalues and Singular Values](https://www.youtube.com/watch?v=d32WV1rKoVk)\n- [ ] [Gilbert strang - Singular Value Decomposition](https://www.youtube.com/watch?v=mBcLRGuAFUk)\n- [ ] [Computing the SVD](https://www.youtube.com/watch?v=cOUTpqlX-Xs\u0026t=22s)\n- [ ] [Lecture 47 — Singular Value Decomposition | Stanford University](https://www.youtube.com/watch?v=P5mlg91as1c)\n- [ ] [How to Calculate the Singular-Value Decomposition (SVD) from Scratch with Python](https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/)\n- [ ] [What is an intuitive explanation of singular value decomposition (SVD)? - Quora](https://www.quora.com/What-is-an-intuitive-explanation-of-singular-value-decomposition-SVD)\n- [ ] [What is the meaning behind the singular value in Singular Value Decomposition? - Quora](https://www.quora.com/What-is-the-meaning-behind-the-singular-value-in-Singular-Value-Decomposition)\n- [ ] [What is the best way of introducing singular value decomposition (SVD) on a linear algebra course? Why is it so important? Are there any applications which have a real impact? - Quora](https://www.quora.com/What-is-the-best-way-of-introducing-singular-value-decomposition-SVD-on-a-linear-algebra-course-Why-is-it-so-important-Are-there-any-applications-which-have-a-real-impact)\n- [ ] [What's the difference between SVD and SVD++? - Quora](https://www.quora.com/Whats-the-difference-between-SVD-and-SVD++)\n- [ ] [What is the purpose of Singular Value Decomposition? - Quora](https://www.quora.com/What-is-the-purpose-of-Singular-Value-Decomposition)\n- Covariance\n- [ ] [Baffled by Covariance and Correlation??? Get the Math and the Application in Analytics for both the terms..](https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22)\n- [ ] [Covariance and Correlation Part 1: Covariance - YouTube](https://www.youtube.com/watch?v=qtaqvPAeEJY)\n- [ ] [The Covariance Matrix : Data Science Basics](https://www.youtube.com/watch?v=152tSYtiQbw)\n- [ ] [Statistics 101: The Covariance Matrix](https://www.youtube.com/watch?v=locZabK4Als\u0026t=1s)\n- PCA\n- [ ] [Implementing a Principal Component Analysis (PCA)– in Python, step by step](https://sebastianraschka.com/Articles/2014_pca_step_by_step.html#4-computing-eigenvectors-and-corresponding-eigenvalues)\n- [ ] [The Mathematics Behind Principal Component Analysis](https://towardsdatascience.com/the-mathematics-behind-principal-component-analysis-fff2d7f4b643)\n- [ ] [A tutorial on Principal Components Analysis](http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf)\n- [ ] [Principal Component Analysis - Youtube](https://www.youtube.com/playlist?list=PLBv09BD7ez_5_yapAg86Od6JeeypkS4YM)\n- [ ] [Dimensionality Reduction For Dummies — Part 1: Intuition](https://towardsdatascience.com/https-medium-com-abdullatif-h-dimensionality-reduction-for-dummies-part-1-a8c9ec7b7e79)\n- [ ] [Data Analysis 6: Principal Component Analysis (PCA) - Computerphile](https://www.youtube.com/watch?v=TJdH6rPA-TI)\n- [ ] [Visual Explanation of Principal Component Analysis, Covariance, SVD](https://www.youtube.com/watch?v=5HNr_j6LmPc)\n- [ ] [luis serrano pca](https://www.youtube.com/watch?v=g-Hb26agBFg)\n- [ ] [StatQuest: Principal Component Analysis (PCA), Step-by-Step - YouTube](https://www.youtube.com/watch?v=FgakZw6K1QQ)\n- [ ] [StatQuest: PCA in Python - YouTube](https://www.youtube.com/watch?v=Lsue2gEM9D0)\n- [ ] [StatQuest: PCA - Practical Tips](https://www.youtube.com/watch?v=oRvgq966yZg\u0026list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\u0026index=24)\n- [ ] [Dimensionality reduction and PCA](https://www.youtube.com/playlist?list=PLBv09BD7ez_4InDh85LM_43Bsw0cFDHdN)\n- [ ] [Principal Component Analysis (PCA) and Singular Value Decomposition (SVD)](https://mlfromscratch.com/principal-component-analysis-pca-svd/#/)\n- [ ] [Visualizing Classifier Boundaries Using Kernel PCA](https://www.kaggle.com/jsultan/visualizing-classifier-boundaries-using-kernel-pca)\n- [ ] [Understanding Principal Component Analysis Once And For All](https://medium.com/bluekiri/understanding-principal-component-analysis-once-and-for-all-9f75e7b33635)\n- [ ] [How to Calculate Principal Component Analysis (PCA) from Scratch in Python](https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/)\n- [ ] [Implementing a Principal Component Analysis (PCA)](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html)\n- [ ] [What is an intuitive explanation for PCA? - Quora](https://www.quora.com/What-is-an-intuitive-explanation-for-PCA)\n- [ ] [What is an intuitive explanation of the relation between PCA and SVD? - Quora](https://www.quora.com/What-is-an-intuitive-explanation-of-the-relation-between-PCA-and-SVD)\n- [ ] [Why don't people use SVD in PCA rather than eigen value decomposition? - Quora](https://www.quora.com/Why-dont-people-use-SVD-in-PCA-rather-than-eigen-value-decomposition)\n- [ ] [(19) Statistics PL03 - Descriptive Statistics II - YouTube](https://www.youtube.com/playlist?list=PLIeGtxpvyG-JMH5fGDWhtniyET88Mexcw)\n- [ ] [Dimensionality Reduction and Principal Component Analysis (PCA) Explained](http://abhijitannaldas.com/ml/dimensionality-reduction-and-principal-component-analysis-pca-explained.html)\n- [ ] [In Depth: Principal Component Analysis](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html)\n- LDA\n- [ ] [Linear Discriminant Analysis – Bit by Bit](http://sebastianraschka.com/Articles/2014_python_lda.html)\n- [ ] [Linear Discriminant Analysis](http://www.saedsayad.com/lda.htm)\n- [ ] [Linear Discriminant Analysis](https://sebastianraschka.com/Articles/2014_python_lda.html)\n- [ ] [A Geometric Intuition for Linear Discriminant Analysis](https://omarshehata.github.io/lda-explorable/)\n- [ ] [Machine Learning with Python: Linear Discriminant Analysis in Python](https://www.python-course.eu/linear_discriminant_analysis.php)\n- [ ] [Using Linear Discriminant Analysis (LDA) for data Explore: Step by Step. | Blog](https://www.apsl.net/blog/2017/07/18/using-linear-discriminant-analysis-lda-data-explore-step-step/)\n- [ ] [Linear Discriminant Analysis (LDA) Numerical Example](https://people.revoledu.com/kardi/tutorial/LDA/Numerical%20Example.html)\n- [ ] [Classification — Linear Discriminant Analysis](https://towardsdatascience.com/classification-part-2-linear-discriminant-analysis-ea60c45b9ee5)\n- [ ] [Linear Discriminant Analysis](https://medium.com/@srishtisawla/linear-discriminant-analysis-d38decf48105)\n- [ ] [Feature Reduction using — PCA \u0026 LDA](https://medium.com/@adityaraj_64455/feature-reduction-using-pca-lda-338b9fe64f59)\n- [ ] [Machine Learning: In-Depth LDA (Linear Discriminant Analysis) Python Example On The Iris Dataset. - YouTube](https://www.youtube.com/watch?v=S8YSqrzqERI)\n- [ ] [How to implement Linear Discriminant Analysis python | +91-7307399944 for query - YouTube](https://www.youtube.com/watch?v=qiq4Y0ZkAwU)\n- [ ] [Linear Discriminant Analysis In Python - Towards Data Science](https://towardsdatascience.com/linear-discriminant-analysis-in-python-76b8b17817c2)\n- [ ] [Implementing LDA in Python with Scikit-Learn](https://stackabuse.com/implementing-lda-in-python-with-scikit-learn/)\n- [ ] [Machine Learning with Python: Linear Discriminant Analysis in Python](https://www.python-course.eu/linear_discriminant_analysis.php)\n- [ ] [(Linear Discriminant Analysis) using Python - Journey 2 Artificial Intelligence - Medium](https://medium.com/journey-2-artificial-intelligence/lda-linear-discriminant-analysis-using-python-2155cf5b6398)\n- SVM\n- [ ] [Please explain Support Vector Machines (SVM) like I am a 5 year old. : MachineLearning](https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/)\n- [ ] [Statquest - Support Vector Machines, Clearly Explained!!!](https://www.youtube.com/watch?v=efR1C6CvhmE)\n- [ ] [Coursera Support vector machine](https://www.coursera.org/learn/machine-learning/lecture/sKQoJ/using-an-svm)\n- [ ] [Intuition for the Support Vector Machine (primal form)](https://www.youtube.com/watch?v=ptwn9wg_s48)\n- [ ] [Chapter 2 : SVM (Support Vector Machine) Theory - Machine Learning 101 - Medium](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72)\n- [ ] [Understanding Support Vector Machines algorithm (along with code)]([https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/?)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/?))\n- [ ] [Support Vector Machines in Scikit-learn (article) - DataCamp](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python)\n- [ ] [Implementing SVM and Kernel SVM with Python Scikit-Learn](https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/)\n- [ ] [Support Vector Machines for Machine Learning](https://machinelearningmastery.com/support-vector-machines-for-machine-learning/)\n- [ ] [cs229-notes3.dvi](http://cs229.stanford.edu/notes/cs229-notes3.pdf)\n- [ ] [Classifying data using Support Vector Machines(SVMs) in Python - GeeksforGeeks](https://www.geeksforgeeks.org/classifying-data-using-support-vector-machinessvms-in-python/)\n- [ ] [Support Vector Machine (SVM) - Fun and Easy Machine Learning](https://www.youtube.com/watch?v=Y6RRHw9uN9o)\n- [ ] https://www.youtube.com/watch?v=iEQ0e-WLgkQ\n- [ ] [In-Depth: Support Vector Machines | Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n- [ ] [Sentdex - Support Vector Machine Intro and Application - YouTube](https://www.youtube.com/watch?v=mA5nwGoRAOo\u0026t=1s)\n- [ ] [Support Vector Machine — Introduction to Machine Learning Algorithms](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)\n- [ ] [Classification From Scratch, Part 7 of 8: SVM - DZone Big Data](https://dzone.com/articles/classification-from-scratch-svm-78)\n- [ ] [Chapter 3.1 : SVM from Scratch in Python. - Deep Math Machine learning.ai - Medium](https://medium.com/deep-math-machine-learning-ai/chapter-3-1-svm-from-scratch-in-python-86f93f853dc)\n- [ ] [adityajn105/SVM-From-Scratch: An Implementation of SVM - Support Vector Machines using Linear Kernel](https://github.com/adityajn105/SVM-From-Scratch)\n- [ ] [SVM-From-Scratch/Support Vector Machine From Scratch.ipynb at master · adityajn105/SVM-From-Scratch](https://github.com/adityajn105/SVM-From-Scratch/blob/master/Support%20Vector%20Machine%20From%20Scratch.ipynb)\n- Decision Trees\n- [ ] [StatQuest: Decision Trees](https://www.youtube.com/watch?v=7VeUPuFGJHk\u0026list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\u0026index=34)\n- [ ] [Decision Tree Algorithm | Decision Tree in Python | Machine Learning Algorithms | Edureka](https://www.youtube.com/watch?v=qDcl-FRnwSU)\n- [ ] [Classification And Regression Trees for Machine Learning](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/)\n- [ ] [How To Implement The Decision Tree Algorithm From Scratch In Python](https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/)\n- [ ] [Clas - 5 Data Science Training | Decision Tree Classifier Explained | Edureka](https://www.youtube.com/watch?v=v3tsrs1wpi4)\n- [ ] [Understanding Decision Trees for Classification in Python](https://www.kdnuggets.com/2019/08/understanding-decision-trees-classification-python.html)\n- [ ] [A Simple Explanation of Information Gain and Entropy](https://victorzhou.com/blog/information-gain/)\n- [ ] [A Simple Explanation of Gini Impurity](https://victorzhou.com/blog/gini-impurity/)\n- [ ] [In-Depth: Decision Trees and Random Forests](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html)\n- [ ] [The Simple Math behind 3 Decision Tree Splitting criterions](https://towardsdatascience.com/the-simple-math-behind-3-decision-tree-splitting-criterions-85d4de2a75fe)\n    Entropy sum\n\n    - [ ] [Decision tree Learning example | ID3 |](https://www.youtube.com/watch?v=UzpwBb3qAbs)\n    - [ ] [(137) Decision Tree Classification Algorithm – Solved Numerical Question 2 in Hindi - YouTube](https://www.youtube.com/watch?v=JsbaJp6VaaU)\n    - [ ] [ID3](https://www.cise.ufl.edu/~ddd/cap6635/Fall-97/Short-papers/2.htm)\n    - [ ] [Decision Trees for Classification: A Machine Learning Algorithm | Xoriant Blog](https://www.xoriant.com/blog/product-engineering/decision-trees-machine-learning-algorithm.html)\n    \n    GINI sum\n    \n    - [ ] [(137) Decision Tree Solved Example Using CART Model in Hindi | Data mining | Machine Learning | AI - YouTube](https://www.youtube.com/watch?v=9K0M2KCyNYo)\n    - [ ] [Gini Index For Decision Trees](https://blog.quantinsti.com/gini-index/)\n- Feature Selection\n    \n    - [ ] [How do I select features for Machine Learning? - YouTube](https://www.youtube.com/watch?v=YaKMeAlHgqQ)\n    - [ ] [Feature Selection in Machine Learning using Python - YouTube](https://www.youtube.com/playlist?list=PLc2rvfiptPSQYzmDIFuq2PqN2n28ZjxDH)\n    - [ ] [Hands-on with Feature Selection Techniques: An Introduction](https://heartbeat.fritz.ai/hands-on-with-feature-selection-techniques-an-introduction-1d8dc6d86c16)\n    - [ ] [How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)\n    - [ ] [Feature Selection For Machine Learning in Python](https://machinelearningmastery.com/feature-selection-machine-learning-python/)\n    - [ ] [FEATURE SELECTION Techniques for Classification Models](https://medium.com/@shiwanigupta3005/feature-selection-techniques-for-classification-models-832ebfc6564d)\n    - [ ] [1.13. Feature selection — scikit-learn 0.22.2 documentation](https://scikit-learn.org/stable/modules/feature_selection.html)\n    - [ ] [anujdutt9/Feature-Selection-for-Machine-Learning: Methods with examples for Feature Selection during Pre-processing in Machine Learning.](https://github.com/anujdutt9/Feature-Selection-for-Machine-Learning)\n- Evaluation metrics\n    \n    - [ ] [MLM- A Gentle Introduction to Model Selection for Machine Learning](https://machinelearningmastery.com/a-gentle-introduction-to-model-selection-for-machine-learning/)\n    - [ ] [Data Preprocessing : Concepts](https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825)\n    - [ ] [About Feature Scaling and Normalization](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html)\n    - [ ] [Measuring Search Effectiveness](https://www.creighton.edu/fileadmin/user/HSL/docs/ref/Searching_-_Recall_Precision.pdf)\n    - [ ] [Classifier evaluation with imbalanced datasets](https://classeval.wordpress.com/introduction/basic-evaluation-measures/)\n    - [ ] [ROC](https://stats.stackexchange.com/questions/370918/must-roc-curve-be-concave)\n    - [ ] [ROC curve 101](https://stats.stackexchange.com/questions/66837/why-does-my-roc-curve-look-like-this-is-it-correct/66844#66844)\n    - [ ] [A Pirate's Guide to Accuracy, Precision, Recall, and Other Scores](https://blog.floydhub.com/a-pirates-guide-to-accuracy-precision-recall-and-other-scores/)\n    - [ ] [Multi-Class Metrics Made Simple, Part II: the F1-score](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1)\n    - [ ] [Feature Scaling with scikit-learn](http://benalexkeen.com/feature-scaling-with-scikit-learn/)\n- Bagging and boosting\n    \n    - [ ] [Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)\n    - [ ] [UDACITY: Bootstrap aggregating bagging](https://www.youtube.com/watch?v=2Mg8QD0F1dQ)\n    - [ ] [Bagging, boosting and stacking in machine learning](https://stats.stackexchange.com/questions/18891/bagging-boosting-and-stacking-in-machine-learning)\n    - [ ] [A Gentle Introduction to the Bootstrap Method](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)\n    - [ ] [Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)\n    - [ ] [Basics of Ensemble Learning Explained in Simple English](https://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning)\n    - [ ] [A Comprehensive Guide to Ensemble Learning (with Python codes)](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/)\n    - [ ] [StatQuest: Random Forests Part 1 - Building, Using and Evaluating](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ\u0026t=2s)\n    - [ ] [Random Forests for Complete Beginners](https://victorzhou.com/blog/intro-to-random-forests/)\n    - [ ] [Random Forest(Bootstrap Aggregation) Easily Explained](https://www.youtube.com/watch?v=iajaNLLCOF4)\n    - [ ] [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n    - [ ] [Effect of Irrelevant Features](https://bookdown.org/max/FES/feature-selection-simulation.html)\n    - [ ] [TheAlgorithms-random_forest_classification](https://github.com/TheAlgorithms/Python/tree/master/machine_learning/random_forest_classification)\n    - [ ] [UDACITY: Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)\n    - [ ] [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)\n    - [ ] [Boosting and AdaBoost for Machine Learning](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/)\n    - [ ] [A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)\n    - [ ] [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n    - [ ] [Gradient Boost Part 1: Regression Main Ideas](https://www.youtube.com/watch?v=3CC4N4z3GJc)\n    - [ ] [Gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting)\n    - [ ] [Gradient Boosting for Linear Regression - why does it not work?](https://stats.stackexchange.com/questions/186966/gradient-boosting-for-linear-regression-why-does-it-not-work)\n    - [ ] [Boosting Machine Learning Tutorial | Adaptive Boosting, Gradient Boosting, XGBoost | Edureka](https://www.youtube.com/watch?v=kho6oANGu_A)\n    - [ ] [Xgboost (Boosting) Intuition Easily Explained](https://www.youtube.com/watch?v=YABWwCLPfZs)\n    - [ ] [An End-to-End Guide to Understand the Math behind XGBoost](https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/)\n    - [ ] [How to Develop Your First XGBoost Model in Python with scikit-learn](https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/)\n    - [ ] [Why is the boosting algorithm robust to overfitting?](https://www.quora.com/Why-is-the-boosting-algorithm-robust-to-overfitting)\n    - [ ] [30 Questions to test a data scientist on Tree Based Models](https://www.analyticsvidhya.com/blog/2017/09/30-questions-test-tree-based-models/)\n    - [ ] [45 questions to test Data Scientists on Tree Based Algorithms (Decision tree, Random Forests, XGBoost)](https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/)\n    - [ ] [40 Questions to ask a Data Scientist on Ensemble Modeling Techniques (Skilltest Solution)](https://www.analyticsvidhya.com/blog/2017/02/40-questions-to-ask-a-data-scientist-on-ensemble-modeling-techniques-skilltest-solution/)\n- Graphical Models, Bayesian networks\n    \n    - [ ] [A Sober Look at Bayesian Neural Networks](https://jacobbuckman.com/2020-01-17-a-sober-look-at-bayesian-neural-networks/)\n    - [ ] [A Gentle Introduction to Bayesian Belief Networks](https://machinelearningmastery.com/introduction-to-bayesian-belief-networks/)\n    - [ ] [Graphical Models](http://www.cs.cmu.edu/~16831-f12/notes/F12/16831_lecture06_astamble.pdf)\n    - [ ] [Directed Graphical Models](https://personal.utdallas.edu/~nrr150130/gmbook/bayes.html)\n    - [ ] [Introduction to Bayesian Networks](https://towardsdatascience.com/introduction-to-bayesian-networks-81031eeed94e)\n    - [ ] [Probabilistic Graphical Models](https://frnsys.com/ai_notes/foundations/probabilistic_graphical_models.html)\n    - [ ] [Introduction to Bayesian Networks | Implement Bayesian Networks In Python | Edureka](https://www.youtube.com/watch?v=SkC8S3wuIfg\u0026t=81s)\n    - [ ] [Bayesian Networks - YouTube](https://www.youtube.com/watch?v=TuGDMj43ehw)\n    - [ ] [(24) Lecture 13.2 — Belief Nets [Neural Networks for Machine Learning] - YouTube](https://www.youtube.com/watch?v=6yxJeySclIc)\n    - [ ] [A friendly introduction to Bayes Theorem and Hidden Markov Models - YouTube](https://www.youtube.com/watch?v=kqSzLo9fenk)[(24) belief network - YouTube](https://www.youtube.com/results?search_query=belief+network)\n    - [ ] [(24) Bayesian Belief Network Explained with Solved Example in Hindi - YouTube](https://www.youtube.com/watch?v=ccivrsjMsXw)\n    - [ ] [(24) BayesianNetworks - YouTube](https://www.youtube.com/watch?v=5s7XdGacztw)\n- Clustering\n    \n    - [ ] [The Most Comprehensive Guide to K-Means Clustering You’ll Ever Need](https://towardsdatascience.com/mish-8283934a72df)\n    - [ ] [Beginner’s Guide To K-Means Clustering](https://www.analyticsindiamag.com/beginners-guide-to-k-means-clustering/)\n    - [ ] [K-means Clustering Algorithm: Know How It Works](https://www.edureka.co/blog/k-means-clustering-algorithm/)\n    - [ ] [In Depth: k-Means Clustering](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)\n    - [ ] [TheAlgorithms - k_means_clust](https://github.com/TheAlgorithms/Python/blob/master/machine_learning/k_means_clust.py)\n    - [ ] [K means Clustering – Introduction](https://www.geeksforgeeks.org/k-means-clustering-introduction/)\n    - [ ] [Image compression using K-means clustering](https://www.geeksforgeeks.org/image-compression-using-k-means-clustering/)\n    - [ ] [Introduction to Image Segmentation with K-Means clustering](https://www.kdnuggets.com/2019/08/introduction-image-segmentation-k-means-clustering.html)\n    - [ ] [ML | Mini Batch K-means clustering algorithm](https://www.geeksforgeeks.org/ml-mini-batch-k-means-clustering-algorithm/)\n    - [ ] [Clustering in Machine Learning](https://www.geeksforgeeks.org/clustering-in-machine-learning/)\n    - [ ] [Different Types of Clustering Algorithm](https://www.geeksforgeeks.org/different-types-clustering-algorithm/)\n    - [ ] [In Depth: Gaussian Mixture Models](https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html)\n    - [ ] [In-Depth: Kernel Density Estimation](https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html)\n    - [ ] [A Beginner’s Guide to Hierarchical Clustering and how to Perform it in Python](https://www.analyticsvidhya.com/blog/2019/05/beginners-guide-hierarchical-clustering/)\n    - [ ] [ML | Hierarchical clustering (Agglomerative and Divisive clustering)](https://www.geeksforgeeks.org/ml-hierarchical-clustering-agglomerative-and-divisive-clustering/)\n    - [ ] [Hierarchical Clustering / Dendrogram: Simple Definition, Examples](https://www.statisticshowto.datasciencecentral.com/hierarchical-clustering/)\n    - [ ] [Hierarchical Clustering / Dendrograms](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Hierarchical_Clustering-Dendrograms.pdf)\n    - [ ] [ML | Mean-Shift Clustering](https://www.geeksforgeeks.org/ml-mean-shift-clustering/)\n    - [ ] [ML | Spectral Clustering](https://www.geeksforgeeks.org/ml-spectral-clustering/)\n    - [ ] [ML | Fuzzy Clustering](https://www.geeksforgeeks.org/ml-fuzzy-clustering/)\n    - [ ] [DBSCAN Clustering in ML | Density based clustering](https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/)\n    - [ ] [How DBSCAN works and why should we use it?](https://towardsdatascience.com/how-dbscan-works-and-why-should-i-use-it-443b4a191c80)\n    - [ ] [What is the Jaccard Index?](https://www.statisticshowto.datasciencecentral.com/jaccard-index/)\n    - [ ] [K-Means Clustering Implementation in Python | Kaggle](https://www.kaggle.com/andyxie/k-means-clustering-implementation-in-python)\n    - [ ] [Python Programming Tutorials](https://pythonprogramming.net/k-means-from-scratch-machine-learning-tutorial/)\n    - [ ] [Machine Learning Workflows in Python from Scratch Part 2: k-means Clustering](https://www.kdnuggets.com/2017/06/machine-learning-workflows-python-scratch-part-2.html)\n    - [ ] [K-Means Clustering in Python - Blog by Mubaris NK](https://mubaris.com/posts/kmeans-clustering/)\n    - [ ] [Implementing K Means Clustering from Scratch - in Python - The Nadig Blog](http://madhugnadig.com/articles/machine-learning/2017/03/04/implementing-k-means-clustering-from-scratch-in-python.html)\n    - [ ] [Machine Learning Workflows in Python from Scratch Part 1: Data Preparation](https://www.kdnuggets.com/2017/05/machine-learning-workflows-python-scratch-part-1.html)\n    - [ ] [Wikipedia - Single linkage Clustering](https://en.wikipedia.org/wiki/Single-linkage_clustering)\n    - [ ] [Pyclustering](https://github.com/annoviko/pyclustering/tree/master/pyclustering/cluster)\n- Naive bayes\n    \n    - [ ] [Luis Serrano - Naive Bayes classifier: A friendly approach](https://www.youtube.com/watch?v=Q8l0Vip5YUw)\n    - [ ] [Andrew Ng Naive Bayes Generative Learning Algorithms](https://www.youtube.com/watch?v=z5UQyCESW64)\n    - [ ] [Andrew Ng Naive Bayes Text Clasification](https://www.youtube.com/watch?v=NFd0ZQk5bR4)\n    - [ ] [3blue1brown- Bayes theorem, and making probability intuitive](https://www.youtube.com/watch?v=HZGCoVF3YvM)\n    - [ ] [3blue1brown- The quick proof of Bayes' theorem](https://www.youtube.com/watch?v=U_85TaXbeIo)\n    - [ ] [Brandon Rohrer - How Bayes Theorem works](https://www.youtube.com/watch?v=5NMxiOGL39M)\n    - [ ] [Naive Bayes - Georgia Tech - Machine Learning](https://www.youtube.com/watch?v=M59h7CFUwPU)\n    - [ ] [The Bayesian Trap](https://www.youtube.com/watch?v=R13BD8qKeTg\u0026list=RDQMQfbssw7R-TQ\u0026index=24)\n    - [ ] [In Depth: Naive Bayes Classification](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)\n    - [ ] [Naive Bayes Classifier in Python | Naive Bayes Algorithm | Machine Learning Algorithm | Edureka](https://www.youtube.com/watch?v=vz_xuxYS2PM\u0026t=11s)\n    - [ ] [How to Develop a Naive Bayes Classifier from Scratch in Python](https://machinelearningmastery.com/classification-as-conditional-probability-and-the-naive-bayes-algorithm//)\n    - [ ] [Naive Bayes Classifier From Scratch](https://chrisalbon.com/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/)\n    - [ ] [kaggle - Naive Bayes Classifier¶](https://www.kaggle.com/pranavpandey2511/naive-bayes-classifier-from-scratch)\n    - [ ] [Naive Bayes Classifiers](https://www.geeksforgeeks.org/naive-bayes-classifiers)\n    - [ ] [Understanding Naive Bayes Classifier from scratch : Python code](https://appliedmachinelearning.blog/2017/05/23/understanding-naive-bayes-classifier-from-scratch-python-code/)\n    - [ ] [kDnuggets - Naive Bayes from Scratch using Python only – No Fancy Frameworks](https://www.kdnuggets.com/2018/10/naive-bayes-from-scratch-python.html)\n    - [ ] [Naïve Bayes for Machine Learning – From Zero to Hero](https://blog.floydhub.com/naive-bayes-for-machine-learning/)\n    - [ ] [How Bayes’ Theorem is Applied in Machine Learning](https://www.kdnuggets.com/2019/10/bayes-theorem-applied-machine-learning.html)\n- MLE, MAP, Mixture models, expectation maximization\n    \n    - [ ] [The Only Theorem Data Scientists Need To Know](https://towardsdatascience.com/the-only-theorem-data-scientists-need-to-know-a50a263d013)\n    - [ ] [Pieter abeel Maximum Likelihood Examples](https://www.youtube.com/watch?v=BFHGIE-nwME)\\\n    - [ ] [Gaussians.pdf](https://ttic.uchicago.edu/~dmcallester/ttic101-07/lectures/Gaussians/Gaussians.pdf)\n    - [ ] [normal distribution - Maximum Likelihood Estimators - Multivariate Gaussian - Cross Validated](https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian?noredirect=1\u0026lq=1)\n    - [ ] [(9) Maximum Likelihood estimation - an introduction part 1 - YouTube](https://www.youtube.com/watch?v=I_dhPETvll8)\n    - [ ] [Maximum Likelihood Estimation Explained - Normal Distribution](https://towardsdatascience.com/maximum-likelihood-estimation-explained-normal-distribution-6207b322e47f)\n    - [ ] [Probability concepts explained: Maximum likelihood estimation](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)\n    - [ ] [Maximum likelihood estimation of normal distribution - Daijiang Li](https://daijiang.name/en/2014/10/08/mle-normal-distribution/?source=post_page-----791153818030----------------------)\n    - [ ] [cs229-notes2.pdf](https://see.stanford.edu/materials/aimlcs229/cs229-notes2.pdf)\n    - [ ] [An Introductory Guide to Maximum Likelihood Estimation (with a case study in R)](https://www.analyticsvidhya.com/blog/2018/07/introductory-guide-maximum-likelihood-estimation-case-study-r/)\n    - [ ] [YOUTUBE - MLE](https://www.youtube.com/watch?index=23\u0026list=PLD0F06AA0D2E8FFBA\u0026t=0s\u0026v=aHwsEXCk4HA\u0026app=desktop)\n    - [ ] [Gaussian Mixture Model - GeeksforGeeks](https://www.geeksforgeeks.org/gaussian-mixture-model/)\n    - [ ] [5.pdf](https://www.cse.wustl.edu/~garnett/cse515t/fall_2019/files/lecture_notes/5.pdf)\n    - [ ] [Gaussian Mixture Models Clustering Algorithm Explained](https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e)\n    - [ ] [analytics vidya GMM](https://www.analyticsvidhya.com/blog/2019/10/gaussian-mixture-models-clustering/)\n    - [ ] [Hidden markov model-GMM-tf2](https://gitlab.com/kesmarag/hmm-gmm-tf2)\n    - [ ] [MLM-A Gentle Introduction to Maximum a Posteriori (MAP) for Machine Learning](https://machinelearningmastery.com/maximum-a-posteriori-estimation/)\n    - [ ] [MLM-A Gentle Introduction to Monte Carlo Sampling for Probability](https://machinelearningmastery.com/monte-carlo-sampling-for-probability/)\n    - [ ] [Gaussian Mixture Model clustering: how to select the number of components (clusters)](https://towardsdatascience.com/gaussian-mixture-model-clusterization-how-to-select-the-number-of-components-clusters-553bef45f6e4)\n    - [ ] [A Novel Ship Detector Based on Gaussian Mixture Model and K-Means Algorithm | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-319-98776-7_72)\n    - [ ] [Probability concepts explained: Bayesian inference for parameter estimation.](https://towardsdatascience.com/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348)\n- EXPECTATION MAXIMIZATION\n    \n    - [ ] [MLM-A Gentle Introduction to Expectation-Maximization (EM Algorithm)](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)\n    - [ ] [Edureka expectation maximization](https://www.youtube.com/watch?v=DIADjJXrgps)\n    - [ ] [YOUTUBE - EXPECTATION MAXIMIZATION](https://www.youtube.com/watch?v=AnbiNaVp3eQ\u0026list=PLD0F06AA0D2E8FFBA\u0026index=116)\n    - [ ] [YOUTUBE-EM](https://www.youtube.com/playlist?list=PLBv09BD7ez_7beI0_fuE96lSbsr_8K8YD)\n    - [ ] [Gaussian Mixture Model - GeeksforGeeks](https://www.geeksforgeeks.org/gaussian-mixture-model/)\n    - [ ] [Gaussian Mixture Models Clustering Algorithm Explained](https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e)\n    - [ ] [What are Gaussian Mixture Models? A Powerful Clustering Algorithm](https://www.analyticsvidhya.com/blog/2019/10/gaussian-mixture-models-clustering/)\n    - [ ] [A Gentle Introduction to Expectation-Maximization (EM Algorithm)](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)\n    - [ ] [EM Algorithm In Machine Learning | Expectation-Maximization | Machine Learning Tutorial | Edureka - YouTube](https://www.youtube.com/watch?v=DIADjJXrgps)\n    - [ ] [(ML 16.3) Expectation-Maximization (EM) algorithm - YouTube](https://www.youtube.com/watch?v=AnbiNaVp3eQ\u0026list=PLD0F06AA0D2E8FFBA\u0026index=116)\n    - [ ] [Mixture Models - YouTube](https://www.youtube.com/playlist?list=PLBv09BD7ez_4e9LtmK626Evn1ion6ynrt)\n    - [ ] [Expectation Maximization Algorithm - YouTube](https://www.youtube.com/playlist?list=PLBv09BD7ez_7beI0_fuE96lSbsr_8K8YD)\n    - [ ] [Clustering - YouTube](https://www.youtube.com/watch?v=vNdyhLI02bs)\n    - [ ] [Clustering (4): Gaussian Mixture Models and EM - YouTube](https://www.youtube.com/watch?v=qMTuMa86NzU\u0026t=8s)\n    - [ ] [Expectation Maximization with an Example – Stokastik](http://www.stokastik.in/em/)\n    - [ ] [ML | Expectation-Maximization Algorithm - GeeksforGeeks](https://www.geeksforgeeks.org/ml-expectation-maximization-algorithm/)\n    - [ ] [EM Algorithm (Expectation-maximization): Simple Definition - Statistics How To](https://www.statisticshowto.datasciencecentral.com/em-algorithm-expectation-maximization/)\n    - [ ] [A Tutorial on the Expectation Maximization (EM) Algorithm](https://www.kdnuggets.com/2016/08/tutorial-expectation-maximization-algorithm.html)","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/Trade-off-Vi%C3%A9s-Vari%C3%A2ncia":{"title":"Trade-off Viés-Variância","content":"Quando treinamos um modelo de Machine Learning, sempre teremos um erro de generalização: erro que informa o \u003cmark style=\"background: #ADCCFFA6;\"\u003equão bem o modelo generaliza para dados que não foram usados no treinamento\u003c/mark\u003e (dados novos), e esse erro pode ser decomposto em 3 termos:\n\n### Viés\nErro ou diferença entre o previsto e observado (suposições erradas assumidas pelo modelo)\n\n### Variância\nErro devido a sensibilidade excessiva do modelo à pequenas variações nos dados, ou seja, um modelo com alta variância captura ruído aleatório nos dados disponíveis, ao invés dos outputs pretendidos (terá performance ruim para dados não vistos)\n\n### Erro irredutível\nErro devido ao ruídos dos dados, considerados irredutíveis dado a aleatoriedade natural na distribuição \"geradora\"\n\nA partir desses erros, surgem dois fenômenos no aprendizado de máquina se o modelo se ajusta aos dados de treinamento de maneira inadequada:\n\n## Underfitting\n*Underfitting* acontece quando o modelo se ajusta de maneira insuficiente ao dados de treino, ou seja, o modelo não é capaz de aprender os padrões presentes nos dados e/ou **não consegue replicar o comportamento** dos dados pela técnica de escolha (ex: utilizar [[Regressão Linear]] para dados que seguem uma parábola).\n\nComo resultado, o modelo não consegue aprender com precisão as relações entre as variáveis e as classes, resultando em um **desempenho ruim tanto nos dados de treinamento quando nos dados de teste**\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003ePara lidar com underfitting, é necessário utilizar modelos mais complexos, aumentar a quantidade e qualidade dos dados de treinamento e considerar o uso de características mais relevantes para a solução do problema\u003c/mark\u003e.\n\n## Overfitting\n*Overfitting* acontece quando o modelo se ajusta bem demais aos dados de treinamento, incorporando não apenas os padrões reais, mas também o erro irredutível presente nos dados de treino. O modelo se torna muito complexo e específico ao conjunto de dados apresentado inicialmente, resultando em baixa capacidade de generalização para novos dados de teste.\n\nEm outras palavras, o modelo **decora** os exemplos de treinamento, mas falha em capturar a estrutura geral dos dados para aplicar em uma nova amostra.\n\nSinais de *overfitting* incluem um desempenho excepcionalmente bom nos dados de treinamento, mas desempenho muito menor em dados de teste não vistos anteriormente. O modelo pode ser tornar muito sensível a pequenas variações nos dados de treino e tende a apresentar alta variância.\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003ePara evitar o overfitting é comum utilizar técnicas de \u003c/mark\u003e [[Regularização]]\u003cmark style=\"background: #ADCCFFA6;\"\u003e, como a redução de  complexidade do modelo, a adição de termos de penalização (L1/L2) ou o aumento do tamanho do conjunto de treinamento.\u003c/mark\u003e\n![[Pasted image 20230717210409.png | center]]\n\nA complexidade de um modelo define a flexibilidade para aproximar a previsão da distribuição real dos dados. Quanto \u003cmark style=\"background: #ADCCFFA6;\"\u003emais complexidade\u003c/mark\u003e tem o modelo, \u003cmark style=\"background: #ADCCFFA6;\"\u003emaior tende a ser sua variância e menor o viés\u003c/mark\u003e, por outro lado \u003cmark style=\"background: #ADCCFFA6;\"\u003emodelos muito simples possuem viés elevado e baixa variância\u003c/mark\u003e:\n\n![[Pasted image 20230717210840.png | center]]\nComo o erro do modelo é a soma dos três termos e, **o erro irredutível é constante**, é preciso encontrar um equilíbrio entre viés e variância para garantirmos o melhor desempenho do nosso modelo, e \"filosofia\" de encontrar as quantidades ótimas de viés e variância é chamada de **trade-off viés-variância**.\n\n![[Pasted image 20230717211153.png | center]]\n#conceitos","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/XGBClassifier":{"title":"XGBClassifier","content":"É um algoritmo derivado do XGBoost(Extreme Gradient Boosting) baseado em [[Ensemble]] de árvores de decisão que utiliza o [[Gradient Boost]] como estrutura de forma otimizada computacionalmente, aproveitando do paralelismo.\n![[Pasted image 20230716212019.png | center]]\n![[Pasted image 20230716212041.png | center]] \nConsegue melhorar o tempo de processamento construindo os modelo base de árvore de forma paralela, além de ter sido projetado para utilizar os recursos do hardware de forma mais eficiente. Além disso, **realiza a poda das árvores durante o processamento, que gera um ganho de performance**.\nUtiliza a regularização [[Regularização|L1 (Lasso)]] e [[Regularização|L2 (Ridge)]] para prevenir *overfitting*, admite naturalmente features esparsas, sabendo lidar de forma eficiente com valores nulos. Além disso realiza validação cruzada em cada iteração.\n\n### Vantagens\n- Dispensa a necessidade de *feature engineering* (não precisa de normalização/padronização, também pode lidar com valores nulos)\n- Pode ser utilizado para determinar *feature importance*\n- Pouco sensível a outliers\n- Lida bem com datasets muito grandes\n- Custo computacional razoável\n- Menos propenso a *overfitting*\n- Modelo possui boa performance, normalmente aparece nas melhores soluções em sites de competições\n\n### Desvantagem\n- Pouca interpretabilidade (modelo black box)\n- Pode ocorrer *overfitting* se não houver ajuste adequado dos hiperparâmetros\n- Quantidade extensa de hiperparâmetros para serem tunados (requer cuidado nessa etapa)\n\n\n#todo \nVer detalhadamente como funciona o gradient boosting\n\n\n#classificação #xgboost","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Machine-Learning/XGBoost":{"title":"XGBoost","content":"","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Private/Apresenta%C3%A7%C3%A3o-f%C3%B3rum-boas-pr%C3%A1ticas":{"title":"Apresentação fórum boas práticas","content":"\n### Intro ~ 15s\nComo a marina comentou, a gente sabe que existe oportunidade para reconhecer melhor a renda para alguns públicos específicos e nós atacamos esses pontos dessas maneiras:\n\n#### Teto Select ~ 1m10s\nNós vamos implementar um novo teto para o público select que comprova renda com IR pois hoje os gerentes notam o impacto do cadastro na renda final porém pelos tetos atuais a renda riscos dificilmente se iguala ao valor do comprovante, principalmente para clientes NH21. \n\nComo no exemplo do cliente select Edson que levou um IR de 87mil na agência para comprovar renda e teve a renda riscos calculada pela nossa política limitada no teto máximo de 39mil.\n\nPara tentarmos tratar esses casos nós vamos flexibilizar para 100mil o teto para esse perfil de público, para garantirmos que caso haja a atualização de renda com um comprovante forte, o cliente possa chegar a um patamar mais alto de renda riscos\n\n#### Santander On ~ 1m15s\nO nosso segundo ponto de atenção são os clientes que atualizam renda no santander on e acabam ficando com a renda estagnada até uma nova comprovação de renda ou para os clientes folha 12 meses (após esse periodo nós priorizamos o crédito salário)\n\nAqui a gente trouxe um exemplo dessa situação pra ilustrar, o Warley que atualizou sua renda pelo aplicativo para 39mil, 7 meses depois passou a receber um crédito salário com valor maior do que o atualizado mas a renda riscos iria se manter no mesmo patamar mais 2 meses até nós priorizarmos o fluxo \"normal\" da riscos\n\nO nosso ajuste aqui vai ser a partir de 6 meses que o cliente atualizou pelo aplicativo, a política vai olhar suas informações e decidir se existe a possibilidade de aumento de renda com as demais informações internas do cliente, caso exista, ele terá o acréscimo na renda riscos de maneira antecipada.\n\n#### Travas Salário ~ 1m30s\nAs travas que a gente cita aqui surgem a partir do momento que passamos a usar de forma mais forte o salário dentro da política, e a gente sabe que é uma formação muito boa e de um fluxo seguro porque o salário é uma informação sistêmica sem input do cliente/gerente\n\nPorém notamos que existia uma pequena fragilidade na informação de salário quando notamos o exemplo da maria:\n\nMaria é dona de uma empresa E1 (de pequeno porte) e tem uma conta PF no Santander, porém nós notamos que ela recebia na conta PF, salários de 140mil reais que no ano representariam mais de 50% do faturamento total de uma empresa do porte que ela tem, e com todo esse fluxo duvidoso a gente acaba superestimando o salário na hora de calcular a renda riscos\n\nPara esse problema nós adicionamos valores máximos a serem considerados como crédito salário dependendo do porte da cnpj que paga o cliente, exclusivamente das duas menores classes (E1 e E2), assim nós não prejudicamos o cálculo da renda riscos com o valor do salário inflado\n\n#### Demais políticas ~ 1m\nEssas três são as mudanças com motivamação mais especificas, mas não são todas que teremos, seguindo aqui:\n\nA nova **renda premium** é uma informação que vamos o histórico de faturas internas e externas de clientes com perfil premium para garantir um piso de renda mais adequado para esse público\n\n**Conselho profissional** é outra informação que vamos adicionar para reconhecer melhor um perfil de público alta renda que tem cadastro em conselhos profissionais como os de medicina, oab, etc. Definindo novos valores de piso e tetos de rendas.\n\nVamos substituir a informação do calculo do salário pela revisão que a Ana já apresentou e agora também utilizamos a informação de **renda de servidor público** que compramos da quod como um valor mínimo de salário para os servidores que não são folha","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/Machine-Learning/Private/Resum%C3%A3o":{"title":"Resumão","content":"### Viés e Variância\n- O que é vies?\n- O que é variancia\n- Relaciones viés com variância\n- Quais são as principais formas de se controlar viés?\n- Quais são as principais formas de se controlar variância?\n\nViés e variância são dois dos conceitos gerais de erros em modelagem, \u003cmark style=\"background: #ADCCFFA6;\"\u003eviés é o tipo de erro que ocorre quando o modelo assume suposições incorreta dos dados a partir do conjunto de treino. Um modelo com alto viés está relacionado ao underfit, quando um modelo aprende muito pouco com os dados de treino.\u003c/mark\u003e\n\nPor outro lado, \u003cmark style=\"background: #FF5582A6;\"\u003ea variância reflete o quão sensível o modelo é em relação à variações dos dados de conjunto de treino. Dizemos que um modelo muito sensível possui alta variância e está relacionado ao problema de overfit, quando o modelo não generaliza bem para novos dados (teste)\u003c/mark\u003e.\n\nA relação entre os dois é o famoso trade-off viés e variância, normalmente na modelagem existe uma balança entre reduzir o viés e a variância. Ao passo que um modelo muito simples inicialmente começam a ganhar complexidade e flexibilidade (ao comportamento dos dados), ele tem uma redução no viés porém pode apresentar aumento na variância, indicando perda de performance para novos dados não observados, \u003cmark style=\"background: #ADCCFFA6;\"\u003eo objetivo do trade-off é encontrar o ponto de equilíbrio entre a redução do viés e da variância\u003c/mark\u003e\n\nViés alto pode ser controlado usando modelos mais complexos e flexíveis, usando mais features (principalmente se elas apresentarem poder preditivo) e para alguns algoritmos, reduzir a penalização aplicada. Para alta variância, podemos usar modelos mais simples/com menos parâmetros, aumentar a quantidade de dados no treino, utilizar regularizadores (lasso e ridge) e também é possível utilizar técnicas de boosting\n\n### Árvores\n- Qual o critério de quebra?\n- Como a saída é calculada? \n- Quais são os pontos fortes do algoritmo?\n- Quais são os critérios principais de parada?\n- Quais são os principais problemas encontrados no algoritmo?\n- Qual a forma de regularização de uma árvore?\n\nÁrvores de decisão podem ser utilizadas tanto para problemas de regressão quanto pra de classificação e funcionam de maneira minimamente diferentes para cada tipo. É chamada de árvore pois as condições de decisão do modelo são feitas por ramificações criando \"visualmente\" algo muito parecido com uma raiz de uma árvore.\n\nNo geral a ramificação da árvore é feita de maneira que os dados que sobram em cada grupo após a separação sejam mais homogêneos do que antes da quebra, nas árvores de regressão verificamos a \"homogeneidade\" com métricas como [[MSE]] e [[MAE]], e para as árvores de classificação utilizamos [[Gini]] ou [[Entropia]] para validar as quebras.\n\nApós serem feitas todas as quebras, nós temos folhas no nível mais baixo de cada ramificação que representa a saída do modelo, para regressão utilizamos a média da target dos dados que pertencem a folha e para classificação nós utilizamos a classe mais frequente dentro da folha (caso ela não seja pura).\n\nPessoal gosta muito da interpretabilidade que as árvores de decisão oferecem e a capacidade de lidar com os dados sem a necessidade de padronização ou tratamentos. Porém se não tomar cuidado com os parâmetros da árvore é bem fácil de acontecer overfitting e o algoritmo tem a tendência de gerar árvores diferentes se os dados de treino forem alterados.\n\nUma maneira de evitar o overfitting é definir bem os critérios de parada da árvore, que são a profundidade máxima da árvore, o tanto que você quer que ela se ramifique, número mínimo de observações dentro de um nó para que seja possível continuar dividindo e o número mínimo de observações dentro de uma folha do modelo.\n\nRegularizadores de árvore de decisão são basicamente os critérios de parada\n\n### Ensembles\n- Quais as principais formas de ensemble?\n- Cite um algoritmo de bagging e outro de boosting\n- Qual problema o bagging se propõe a resolver?\n- Qual problema o boosting se propõe a resolver?\n- Quais são os principais parâmetros de uma random forest e quais são seus efeitos?\n- Quais são os principais parâmetros de um gradient boosting e quais são seus efeitos?\n- Relacione bagging a viés e variância\n- Relacione boosting a viés e variância\n- Cite duas implementações de boosting e explique suas diferenças\n\nEnsemble são técnicas que vários modelos treinados para resolver um mesmo problema, combinados para ter um melhor poder preditivo. Os principais métodos de ensembles são o bagging e o boosting.\n\nBagging utiliza várias instâncias do \"mesmo modelo\" para diferentes subconjuntos dos dados originais (realizado por bootstrap) que no fim são combinados por voto da maioria (classificação) e média/mediana das predições (regressão). No geral bagging tenta tratar o problema de modelos que tendem a ter alta variância com sua combinação, e um exemplo de bagging é a Random Forest (agregação de árvores de decisões)\n\nBoosting busca resolver o problema underfit de modelos fracos \"melhorando\" o modelo de forma sequencial, em cada iteração o modelo é treinado em um conjunto de dados \"ajustado\" dando mais importância para os erros passado, ou predizendo o erro gerado pelo modelo anterior. Exemplos de boosting são Gradient Boosting e XGBoost\n\nPrincipais parâmetros da Random Forest:\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003enumero de árvores\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003etamanho do subconjunto de features pra ser utilizado em cada árvore\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003emetodo de reamostragem das observações para cada árvore\u003c/mark\u003e\n- profundidade máxima das árvores\n- número minimo de amostras (folha/nós)\n\nPrincipais parâmetros do Gradient Boosting:\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003enumero de árvores\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003etamanho do subconjunto de features pra ser utilizado em cada árvore\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003elearning rate\u003c/mark\u003e\n- profundidade máxima das arvores\n- numero mínimo de amostras (folha/nós)\n\nTanto Gradient Boosting quanto XGBoost são técnicas de boosting que buscam melhorar um modelo weak learner predizendo os resíduos porém possuem algumas diferenças: O XGBoost possui termos regularizadores, como o gamma e o lambda para diminuir o impacto que observações individuais possuem nas previsões e melhorar a generalização do modelo, além de também possuir um sistema de poda dinamica que não depende de completar a execução da arvore antes de realizar\n\n### Outros Modelos \nFalar de naive bayes\n\n### Métricas de avaliação\n- Principais métricas para avaliar um classificador\n- Funcionamento / caso de uso / restrições\n- Diferenciar métricas de poder e calibração\n- Técnicas multiclasse/multilabel\n- Principais métricas para avaliar um regressor\n- Funcionamento/ caso de uso / restrições\n\n#### As métricas mais comuns pra avaliar classificadores são:\n##### Métricas de poder:\n- Acuracia: Reflete o percentual de classes que seu modelo acerta, útil pra ter uma ideia inicial do modelo mas péssima quando os dados são muito desbalanceados\n- Precisão: Mede a proporção de observações corretamente classificadas como positivas, bom quando queremos controlar os falsos positivos, \u003cmark style=\"background: #ADCCFFA6;\"\u003eimportante para problemas de recomendação\u003c/mark\u003e\n- Recall/Sensibilidade: Mede a proporção de observações positivas classificadas corretamente, útil em problemas de saúde/medicina \u003cmark style=\"background: #ADCCFFA6;\"\u003eonde não queremos de maneira alguma deixar de classificar um cliente doente corretamente\u003c/mark\u003e\n- F1-Score: Média harmônica de precisão e recall, penaliza mais os valores extremos, útil quando ambas o custo dos dois erros são semelhantes.\n- ROC-AUC: Gráfico entre TPR e FPR, mede quão bem o classificador separa duas classes (quando o valor se aproxima de 1) para vários pontos de corte, boa métrica para avaliar a classificação de um modelo no geral para problemas de classes desbalanceadas\n##### Métricas de calibração:\n- Log-Loss: Mede a discrepância entre a probabilidade observada pelo modelo e as classes reais através da log-verossimilhança\n\n#### Para avaliar problemas multiclass:\n- **Macro Average** das métricas acima: Média simples da soma das métricas dividas pelo número de classes, ex: precisão\n$$Macro Avg = \\frac{Precisão_{c1}+Precisão_{c2}+Precisão_{c3}}{3}$$\n- **Micro Average** das métricas acima: Média considerando toda a soma individual de TP, TN, FP e FN de todas as classes do conjunto de dados, ex: precisao\n$$Micro Avg = \\frac{\\sum_{1,2,3}TruePositive}{\\sum_{1,2,3}TruePositive+\\sum_{1,2,3}FalsePositive}$$\n- **Weighted Average** das métricas acima: Média com pesos atribuídos pela frequência de cada classe no conjunto de dados, ex: precisão\n$$Weighted Avg = \\frac{Precisão_{c1}*10+Precisão_{c2}*20+Precisão_{c3}*50}{10+20+50}$$\n\n#### Para problemas de múltiplos rótulos pra mesma observação:\n- **Jaccard Score** mede a interseção das classificações sobre a união de todas as classificações, \u003cmark style=\"background: #ADCCFFA6;\"\u003epara problemas binários é idêntico à acurácia, mas também podemos entender o uso para problemas multiclasse e de multirotulo\u003c/mark\u003e\n\n\n#### As métricas mais comuns pra avaliar regressores são:\n- **MSE** representa a média do quadrado dos resíduos, penaliza de maneira mais forte erros maiores porém é sensível a outliers, como é uma função derivável, é muito útil como função de custo\n- **RMSE** representa a raiz quadrada do MSE, tem as mesmas vantagens com o adicional de manter o erro na escala original dos dados, aumentando interpretabilidade.\n- **MAE** média dos erros absolutos, penaliza de acordo com a magnitude dos erros porém é menos sensível a outliers, como não é derivável possui limitações como função de custo, o ponto positivo é que facilita a interpretabilidade pois mantem a escala original dos dados.\n- **R²** representa a porcentagem de ganho de predição ao usar o modelo em comparação à média da feature (diferença entre SSR da média e SSR do ajuste), desvantagem é não levar em conta a quantidade de features, que pode influenciar negativamente a métrica\n- **R² Ajustado** é uma adaptação do R² com uma penalização pelo número de features, ou seja, leva em conta a quantidade de explicação fornecida pelas variáveis preditoras, útil para comparar modelos com diferentes número de parâmetros\n- \n### Não supervisionado\n- Quais são as principais categorias de algoritmos de clusterização\n- Cite um algoritmo de cada categoria?\n- Explique rapidamente os algoritmos citado\n\n\n#### Clusterização Hierárquica\nConstroi dendogramas para representar os clusters em uma hierarquia, onde em certo ponto de corte todos os pontos podem fazer parte de um mesmo cluster, ou cada ponto ser seu próprio cluster\n\n##### Aglomeração\nNa inicialização cada ponto é seu próprio e a cada iteração os  dois clusters mais próximos se unem para formar um novo cluster, esse processo se repete até existir apenas 1 cluster só, contendo todo o dataset\n\n##### Divisão\nO algoritmo começa considerando todos os pontos em um único cluster e a cada passo as observações com maior dissimilaridade é realocado em um cluster separado, processo se repete até existir um cluster para cada observação\n\nAs medidas utilizadas podem ser **vizinho mais proximo**, **vizinho mais distante** ou **media das distancias** \n\n#### Clusterização Particionais\nTécnicas de agrupamento que divide os dados em um número pre definido de clusters e assim como na hierárquica, no fim do processo cada ponto pertence a apenas um cluster, o objetivo é encontrar a divisão do hiperplano que otimiza a métrica de distância intra-cluster e inter-cluster\n\n##### K-means\nestima o centroides do cluster com a media dos pontos - indicado usar distancia euclidiana\n##### K-Medoids\nestima centroide do cluster com a mediana - indicado usar com distancia de manhattan\n\n#### Clusterização baseado em densidade - DBSCAN\nAlgoritmo de agrupamento que considera pontos muito próximos em mesmo cluster por densidade, teoricamente consegue identificar qualquer formato na distribuição dos dados olhando a proximidade entre pontos\n\nfunciona com os parâmetros de **pontos minimos** e **tamanho do raio** para classificar os pontos do dataset e depois atribuir em algum cluster\n\n#### Clusterização baseado em mistura de modelos\nCluster definido em uma abordagem probabilística, cada modelo representa um cluster e é ajustado aos dados usando expectation-maximization, permitindo medir a incerteza dos agrupamentos gerados.\n\n##### GMM\n","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/notes/CJK-+-Latex-Support-%E6%B5%8B%E8%AF%95":{"title":"CJK + Latex Support (测试)","content":"\n## Chinese, Japanese, Korean Support\n几乎在我们意识到之前，我们已经离开了地面。\n\n우리가 그것을 알기도 전에 우리는 땅을 떠났습니다.\n\n私たちがそれを知るほぼ前に、私たちは地面を離れていました。\n\n## Latex\n\nBlock math works with two dollar signs `$$...$$`\n\n$$f(x) = \\int_{-\\infty}^\\infty\n    f\\hat(\\xi),e^{2 \\pi i \\xi x}\n    \\,d\\xi$$\n\t\nInline math also works with single dollar signs `$...$`. For example, Euler's identity but inline: $e^{i\\pi} = -1$\n\nAligned equations work quite well:\n\n$$\n\\begin{aligned}\na \u0026= b + c \\\\ \u0026= e + f \\\\\n\\end{aligned}\n$$\n\nAnd matrices\n\n$$\n\\begin{bmatrix}\n1 \u0026 2 \u0026 3 \\\\\na \u0026 b \u0026 c\n\\end{bmatrix}\n$$\n\n## RTL\nMore information on configuring RTL languages like Arabic in the [config](notes/config.md) page.\n","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/notes/callouts":{"title":"Callouts","content":"\n## Callout support\n\nQuartz supports the same Admonition-callout syntax as Obsidian.\n\nThis includes\n- 12 Distinct callout types (each with several aliases)\n- Collapsable callouts\n\nSee [documentation on supported types and syntax here](https://help.obsidian.md/Editing+and+formatting/Callouts).\n\n## Showcase\n\n\u003e [!EXAMPLE] Examples\n\u003e\n\u003e Aliases: example\n\n\u003e [!note] Notes\n\u003e\n\u003e Aliases: note\n\n\u003e [!abstract] Summaries \n\u003e\n\u003e Aliases: abstract, summary, tldr\n\n\u003e [!info] Info \n\u003e\n\u003e Aliases: info, todo\n\n\u003e [!tip] Hint \n\u003e\n\u003e Aliases: tip, hint, important\n\n\u003e [!success] Success \n\u003e\n\u003e Aliases: success, check, done\n\n\u003e [!question] Question \n\u003e\n\u003e Aliases: question, help, faq\n\n\u003e [!warning] Warning \n\u003e\n\u003e Aliases: warning, caution, attention\n\n\u003e [!failure] Failure \n\u003e\n\u003e Aliases: failure, fail, missing\n\n\u003e [!danger] Error\n\u003e\n\u003e Aliases: danger, error\n\n\u003e [!bug] Bug\n\u003e\n\u003e Aliases: bug\n\n\u003e [!quote] Quote\n\u003e\n\u003e Aliases: quote, cite\n","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":[]},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Jacky Zhao\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to render copy buttons for code blocks\nenableCodeBlockCopy: true \n\n# whether to render callouts\nenableCallouts: true\n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flashes of unstyled content and improves\n# smoothness of Quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# whether to display an 'edit' button next to the last edited field\n# that links to github\nenableGitHubEdit: true\nGitHubLink: https://github.com/jackyzha0/quartz/tree/hugo/content\n\n# whether to render mermaid diagrams\nenableMermaid: true\n\n# whether to use Operand to power semantic search\n# IMPORTANT: replace this API key with your own if you plan on using\n# Operand search!\nsearch:\n  enableSemanticSearch: false\n  operandApiKey: \"REPLACE-WITH-YOUR-OPERAND-API-KEY\"\n  operandIndexId: \"REPLACE-WITH-YOUR-OPERAND-INDEX-ID\"\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"🪴 Quartz 3.3\"\n\n# links to show in the footer\nlinks:\n  - link_name: Twitter\n    link: https://twitter.com/_jzhao\n  - link_name: Github\n    link: https://github.com/jackyzha0\n```\n\n### Code Block Titles\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur, and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your Quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. For example, here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to Quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current and past standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n    # whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `assets/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = 'مدونتي'\n    weight = 1\n```\n","lastmodified":"2023-08-07T23:34:18.702981075Z","tags":["setup"]},"/notes/custom-Domain":{"title":"Custom Domain","content":"\n### Registrar\nThis step is only applicable if you are using a **custom domain**! If you are using a `\u003cYOUR-USERNAME\u003e.github.io` domain, you can skip this step.\n\nFor this last bit to take effect, you also need to create a CNAME record with the DNS provider you register your domain with (i.e. NameCheap, Google Domains).\n\nGitHub has some [documentation on this](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site), but the tldr; is to\n\n1. Go to your forked repository (`github.com/\u003cYOUR-GITHUB-USERNAME\u003e/quartz`) settings page and go to the Pages tab. Under \"Custom domain\", type your custom domain, then click **Save**.\n2. Go to your DNS Provider and create a CNAME record that points from your domain to `\u003cYOUR-GITHUB-USERNAME.github.io.` (yes, with the trailing period).\n\n\t![Example Configuration for Quartz](/notes/images/google-domains.png)*Example Configuration for Quartz*\n3. Wait 30 minutes to an hour for the network changes to kick in.\n4. Done!","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":[]},"/notes/docker":{"title":"Hosting with Docker","content":"\nIf you want to host Quartz on a machine without using a webpage hosting service, it may be easier to [install Docker Compose](https://docs.docker.com/compose/install/) and follow the instructions below than to [install Quartz's dependencies manually](notes/preview%20changes.md).\n## Hosting Quartz Locally\nYou can serve Quartz locally at `http://localhost:1313` with the following script, replacing `/path/to/quartz` with the \nactual path to your Quartz folder.\n\ndocker-compose.yml\n```\nservices:\n  quartz-hugo:\n    image: ghcr.io/jackyzha0/quartz:hugo\n    container_name: quartz-hugo\n    volumes:\n      - /path/to/quartz:/quartz\n    ports:\n      - 1313:1313\n\n    # optional\n    environment:\n      - HUGO_BIND=0.0.0.0\n      - HUGO_BASEURL=http://localhost\n      - HUGO_PORT=1313\n      - HUGO_APPENDPORT=true\n      - HUGO_LIVERELOADPORT=-1\n```\n\nThen run with: `docker-compose up -d` in the same directory as your `docker-compose.yml` file.\n\nWhile the container is running, you can update the `quartz` fork with: `docker exec -it quartz-hugo make update`.\n\n## Exposing Your Container to the Internet\n\n### To Your Public IP Address with Port Forwarding (insecure)\n\nAssuming you are already familiar with [port forwarding](https://en.wikipedia.org/wiki/Port_forwarding) and [setting it up with your router model](https://portforward.com):\n\n1. You should set the environment variable `HUGO_BASEURL=http://your-public-ip` and then start your container.\n2. Set up port forwarding on your router from port `p` to `your-local-ip:1313`.\n3. You should now be able to access Quartz from outside your local network at `http://your-public-ip:p`.\n\nHowever, your HTTP connection will be unencrypted and **this method is not secure**.\n\n### To a Domain using Cloudflare Proxy\n\n1. Port forward 443 (HTTPS) from your machine.\n2. Buy a custom domain (say, `your-domain.com`) from [Cloudflare](https://www.cloudflare.com/products/registrar/). Point a DNS A record from `your-domain.com` to your public IP address and enable the proxy.\n3. Set the environment variables `HUGO_BASEURL=https://your-domain.com`, `HUGO_PORT=443`, and `HUGO_APPENDPORT=false`. Change `1313:1313` to `443:443` for the `ports` in `docker-compose.yml`.\n4. Spin up your Quartz container and enjoy it at `https://your-domain.com`!\n\n### To a Domain using a Reverse Proxy\n\nIf you want to serve more than just Quartz to the internet on this machine (or don't want to use the Cloudflare registrar and proxy), you should follow the steps in the section above (as appropriate) and also set up a reverse proxy, like [Traefik](https://doc.traefik.io/traefik). Be sure to configure your TLS certificates too!\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":["setup"]},"/notes/editing":{"title":"Editing Content in Quartz","content":"\n## Editing \nQuartz runs on top of [Hugo](https://gohugo.io/) so all notes are written in [Markdown](https://www.markdownguide.org/getting-started/).\n\n### Folder Structure\nHere's a rough overview of what's what.\n\n**All content in your garden can found in the `/content` folder.** To make edits, you can open any of the files and make changes directly and save it. You can organize content into any folder you'd like.\n\n**To edit the main home page, open `/content/_index.md`.**\n\n### Front Matter\nHugo is picky when it comes to metadata for files. Make sure that your title is double-quoted and that you have a title defined at the top of your file like so, otherwise the generated page will not have a title!\n\nYou can also add tags here as well.\n\n```yaml\n---\ntitle: \"Example Title\"\ntags:\n- example-tag\n---\n\nRest of your content here...\n```\n\n### Obsidian\nI recommend using [Obsidian](http://obsidian.md/) as a way to edit and grow your digital garden. It comes with a really nice editor and graphical interface to preview all of your local files.\n\nThis step is **highly recommended**.\n\n\u003e 🔗 Step 3: [How to setup your Obsidian Vault to work with Quartz](notes/obsidian.md)\n\n## Previewing Changes\nThis step is purely optional and mostly for those who want to see the published version of their digital garden locally before opening it up to the internet. This is *highly recommended* but not required.\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n\nFor those who like to live life more on the edge, viewing the garden through Obsidian gets you pretty close to the real thing.\n\n## Publishing Changes\nNow that you know the basics of managing your digital garden using Quartz, you can publish it to the internet!\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":["setup"]},"/notes/hosting":{"title":"Deploying Quartz to the Web","content":"\n## Hosting on GitHub Pages\nQuartz is designed to be effortless to deploy. If you forked and cloned Quartz directly from the repository, everything should already be good to go! Follow the steps below.\n\n### Enable GitHub Actions Permissions\nBy default, GitHub disables workflows from modifying your files (for good reason!). However, Quartz needs this to write the actual site files back to GitHub.\n\nHead to `Settings \u003e Action \u003e General \u003e Workflow Permissions` and choose `Read and Write Permissions`\n\n![[notes/images/github-actions.png]]\n*Enable GitHub Actions*\n\n### Enable GitHub Pages\n\nHead to the 'Settings' tab of your forked repository and go to the 'Pages' tab.\n\n1. (IMPORTANT) Set the source to deploy from `master` (and not `hugo`) using `/ (root)`\n2. Set a custom domain here if you have one!\n\n![Enable GitHub Pages](/notes/images/github-pages.png)*Enable GitHub Pages*\n\n### Pushing Changes\nTo see your changes on the internet, we need to push it them to GitHub. Quartz is a `git` repository so updating it is the same workflow as you would follow as if it were just a regular software project.\n\n```shell\n# Navigate to Quartz folder\ncd \u003cpath-to-quartz\u003e\n\n# Commit all changes\ngit add .\ngit commit -m \"message describing changes\"\n\n# Push to GitHub to update site\ngit push origin hugo\n```\n\nNote: we specifically push to the `hugo` branch here. Our GitHub action automatically runs everytime a push to is detected to that branch and then updates the `master` branch for redeployment.\n\n### Setting up the Site\nNow let's get this site up and running. Never hosted a site before? No problem. Have a fancy custom domain you already own or want to subdomain your Quartz? That's easy too.\n\nHere, we take advantage of GitHub's free page hosting to deploy our site. Change `baseURL` in `/config.toml`. \n\nMake sure that your `baseURL` has a trailing `/`!\n\n[Reference `config.toml` here](https://github.com/jackyzha0/quartz/blob/hugo/config.toml)\n\n```toml\nbaseURL = \"https://\u003cYOUR-DOMAIN\u003e/\"\n```\n\nIf you are using this under a subdomain (e.g. `\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz`), include the trailing `/`. **You need to do this especially if you are using GitHub!**\n\n```toml\nbaseURL = \"https://\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz/\"\n```\n\nChange `cname` in `/.github/workflows/deploy.yaml`. Again, if you don't have a custom domain to use, you can use `\u003cYOUR-USERNAME\u003e.github.io`.\n\nPlease note that the `cname` field should *not* have any path `e.g. end with /quartz` or have a trailing `/`.\n\n[Reference `deploy.yaml` here](https://github.com/jackyzha0/quartz/blob/hugo/.github/workflows/deploy.yaml)\n\n```yaml {title=\".github/workflows/deploy.yaml\"}\n- name: Deploy  \n  uses: peaceiris/actions-gh-pages@v3  \n  with:  \n\tgithub_token: ${{ secrets.GITHUB_TOKEN }} # this can stay as is, GitHub fills this in for us!\n\tpublish_dir: ./public  \n\tpublish_branch: master\n\tcname: \u003cYOUR-DOMAIN\u003e\n```\n\nHave a custom domain? [Learn how to set it up with Quartz ](notes/custom%20Domain.md).\n\n### Ignoring Files\nOnly want to publish a subset of all of your notes? Don't worry, Quartz makes this a simple two-step process.\n\n❌ [Excluding pages from being published](notes/ignore%20notes.md)\n\n## Docker Support\nIf you don't want to use a hosting service, you can host using [Docker](notes/docker.md) instead!\nI would *not use this method* unless you know what you are doing.\n\n---\n\nNow that your Quartz is live, let's figure out how to make Quartz really *yours*!\n\n\u003e Step 6: 🎨 [Customizing Quartz](notes/config.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":["setup"]},"/notes/ignore-notes":{"title":"Ignoring Notes","content":"\n### Quartz Ignore\nEdit `ignoreFiles` in `config.toml` to include paths you'd like to exclude from being rendered.\n\n```toml\n...\nignoreFiles = [  \n    \"/content/templates/*\",  \n    \"/content/private/*\", \n    \"\u003cyour path here\u003e\"\n]\n```\n\n`ignoreFiles` supports the use of Regular Expressions (RegEx) so you can ignore patterns as well (e.g. ignoring all `.png`s by doing `\\\\.png$`).\nTo ignore a specific file, you can also add the tag `draft: true` to the frontmatter of a note.\n\n```markdown\n---\ntitle: Some Private Note\ndraft: true\n---\n...\n```\n\nMore details in [Hugo's documentation](https://gohugo.io/getting-started/configuration/#ignore-content-and-data-files-when-rendering).\n\n### Global Ignore\nHowever, just adding to the `ignoreFiles` will only prevent the page from being access through Quartz. If you want to prevent the file from being pushed to GitHub (for example if you have a public repository), you need to also add the path to the `.gitignore` file at the root of the repository.","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":[]},"/notes/obsidian":{"title":"Obsidian Vault Integration","content":"\n## Setup\nObsidian is the preferred way to use Quartz. You can either create a new Obsidian Vault or link one that your already have.\n\n### New Vault\nIf you don't have an existing Vault, [download Obsidian](https://obsidian.md/) and create a new Vault in the `/content` folder that you created and cloned during the [setup](notes/setup.md) step.\n\n### Linking an existing Vault\nThe easiest way to use an existing Vault is to copy all of your files (directory and hierarchies intact) into the `/content` folder.\n\n## Settings\nGreat, now that you have your Obsidian linked to your Quartz, let's fix some settings so that they play well.\n\nOpen Settings \u003e Files \u0026 Links and look for these two items:\n\n1. Set the **New link format** to **Absolute Path in vault**. If you have a completely flat vault (no folders), this step isn't necessary.\n2. Turn **on** the **Automatically update internal links** setting.\n\n\n![[notes/images/obsidian-settings.png]]*Obsidian Settings*\n\n## Templates\nInserting front matter everytime you want to create a new Note gets annoying really quickly. Luckily, Obsidian supports templates which makes inserting new content really easily.\n\n\u003e [!WARNING]\n\u003e \n\u003e **If you decide to overwrite the `/content` folder completely, don't remove the `/content/templates` folder!**\n\nHead over to Options \u003e Core Plugins and enable the Templates plugin. Then go to Options \u003e Hotkeys and set a hotkey for 'Insert Template' (I recommend `[cmd]+T`). That way, when you create a new note, you can just press the hotkey for a new template and be ready to go!\n\n\u003e 👀 Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":["setup"]},"/notes/philosophy":{"title":"Quartz Philosophy","content":"\n\u003e “[One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.” — Richard Hamming\n\n## Why Quartz?\nHosting a public digital garden isn't easy. There are an overwhelming number of tutorials, resources, and guides for tools like [Notion](https://www.notion.so/), [Roam](https://roamresearch.com/), and [Obsidian](https://obsidian.md/), yet none of them have super easy to use *free* tools to publish that garden to the world.\n\nI've personally found that\n1. It's nice to access notes from anywhere\n2. Having a public digital garden invites open conversations\n3. It makes keeping personal notes and knowledge *playful and fun*\n\nI was really inspired by [Bianca](https://garden.bianca.digital/) and [Joel](https://joelhooks.com/digital-garden)'s digital gardens and wanted to try making my own.\n\n**The goal of Quartz is to make hosting your own public digital garden free and simple.** You don't even need your own website. Quartz does all of that for you and gives your own little corner of the internet.\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":[]},"/notes/preview-changes":{"title":"Preview Changes","content":"\nIf you'd like to preview what your Quartz site looks like before deploying it to the internet, the following\ninstructions guide you through installing the proper dependencies to run it locally.\n\n\n## Install `hugo-obsidian`\nThis step will generate the list of backlinks for Hugo to parse. Ensure you have [Go](https://golang.org/doc/install) (\u003e= 1.16) installed.\n\n```bash\n# Install and link `hugo-obsidian` locally\ngo install github.com/jackyzha0/hugo-obsidian@latest\n```\n\nIf you are running into an error saying that `command not found: hugo-obsidian`, make sure you set your `GOPATH` correctly (see [[notes/troubleshooting#`command not found: hugo-obsidian`|the troubleshooting page]])! This will allow your terminal to correctly recognize hugo-obsidian as an executable.\n\n##  Installing Hugo\nHugo is the static site generator that powers Quartz. [Install Hugo with \"extended\" Sass/SCSS version](https://gohugo.io/getting-started/installing/) first. Then,\n\n```bash\n# Navigate to your local Quartz folder\ncd \u003clocation-of-your-local-quartz\u003e\n\n# Start local server\nmake serve\n\n# View your site in a browser at http://localhost:1313/\n```\n\n\u003e [!INFO] Docker Support\n\u003e\n\u003e If you have the Docker CLI installed already, you can avoid installing `hugo-obsidian` and `hugo`. Instead, open your terminal, navigate to your folder with Quartz and run `make docker`\n\nAfterwards, start the Hugo server as shown above and your local backlinks and interactive graph should be populated! Now, let's get it hosted online.\n\n\u003e 🌍 Step 5: [Hosting Quartz online!](notes/hosting.md)\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":["setup"]},"/notes/search":{"title":"Search","content":"\nQuartz supports two modes of searching through content.\n\n## Full-text\nFull-text search is the default in Quartz. It produces results that *exactly* match the search query. This is easier to setup but usually produces lower quality matches.\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nenableSemanticSearch: false\n```\n\n## Natural Language\nNatural language search is powered by [Operand](https://beta.operand.ai/). It understands language like a person does and finds results that best match user intent. In this sense, it is closer to how Google Search works.\n\nNatural language search tends to produce higher quality results than full-text search.\n\nHere's how to set it up.\n\n1. Login or Register for a new Operand account. Click the verification link sent to your email, and you'll be redirected to the dashboard. (Note) You do not need to enter a credit card to create an account, or get started with the Operand API. The first $10 of usage each month is free. To learn more, see pricing. If you go over your free quota, we'll (politely) reach out and ask you to configure billing.\n2. Create your first index. On the dashboard, under \"Indexes\", enter the name and description of your index, and click \"Create Index\". Note down the ID of the index (obtained by clicking on the index name in the list of indexes), as you'll need it in the next step. IDs are unique to each index, and look something like `uqv1duxxbdxu`.\n3. Click into the index you've created. Under \"Index Something\", select \"SITEMAP\" from the dropdown and click \"Add Source\".\n4. For the \"Sitemap.xml URL\", put your deployed site's base URL followed by `sitemap.xml`. For example, for `quartz.jzhao.xyz`, put `https://quartz.jzhao.xyz/sitemap.xml`. Leave the URL Regex empty. \n5. Get your API key. On the dashboard, under \"API Keys\", you can manage your API keys. If you don't already have an API key, click \"Create API Key\". You'll need this for the next step.\n6. Open `data/config.yaml`. Set `enableSemanticSearch` to `true`, `operandApiKey` to your copied key, and `operandIndexId` to the ID of the index we created from earlier..\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nsearch:\n  enableSemanticSearch: true\n  operandApiKey: \"jp9k5hudse2a828z98kxd6z3payi8u90rnjf\"\n  operandIndexId: \"s0kf3bd6tldw\"\n```\n7. Push your changes to the site and wait for it to deploy.\n8. Check the Operand dashboard and wait for your site to index. Enjoy natural language search powered by Operand!\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":[]},"/notes/setup":{"title":"Setup","content":"\n## Making your own Quartz\nSetting up Quartz requires a basic understanding of `git`. If you are unfamiliar, [this resource](https://resources.nwplus.io/2-beginner/how-to-git-github.html) is a great place to start!\n\n### Forking\n\u003e A fork is a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.\n\nNavigate to the GitHub repository for the Quartz project:\n\n📁 [Quartz Repository](https://github.com/jackyzha0/quartz)\n\nThen, Fork the repository into your own GitHub account. **Make sure that when you fork, you _uncheck_ the 'Copy the `hugo` branch only' option**.\n\nIf you don't have an account, you can make on for free [here](https://github.com/join). More details about forking a repo can be found on [GitHub's documentation](https://docs.github.com/en/get-started/quickstart/fork-a-repo).\n\n![[notes/images/fork.png]]\n\n### Cloning\nAfter you've made a fork of the repository, you need to download the files locally onto your machine. Ensure you have `git`, then type the following command in your terminal replacing `YOUR-USERNAME` with your GitHub username.\n\n```shell\ngit clone https://github.com/YOUR-USERNAME/quartz\n```\n\n## Editing\nGreat! Now you have everything you need to start editing and growing your digital garden. If you're ready to start writing content already, check out the recommended flow for editing notes in Quartz.\n\n\u003e ✏️ Step 2: [Editing Notes in Quartz](notes/editing.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":["setup"]},"/notes/showcase":{"title":"Showcase","content":"\nWant to see what Quartz can do? Here are some cool community gardens :)\n\n- [Quartz Documentation (this site!)](https://quartz.jzhao.xyz/)\n- [Jacky Zhao's Garden](https://jzhao.xyz/)\n- [Scaling Synthesis - A hypertext research notebook](https://scalingsynthesis.com/)\n- [AWAGMI Intern Notes](https://notes.awagmi.xyz/)\n- [Shihyu's PKM](https://shihyuho.github.io/pkm/)\n- [SlRvb's Site](https://slrvb.github.io/Site/)\n- [Course notes for Information Technology Advanced Theory](https://a2itnotes.github.io/quartz/)\n- [Brandon Boswell's Garden](https://brandonkboswell.com)\n- [Siyang's Courtyard](https://siyangsun.github.io/courtyard/)\n- [Data Dictionary 🧠](https://glossary.airbyte.com/)\n- [sspaeti.com's Second Brain](https://brain.sspaeti.com/)\n- [oldwinterの数字花园](https://garden.oldwinter.top/)\n- [SethMB Work](https://sethmb.xyz/)\n- [Abhijeet's Math Wiki](https://abhmul.github.io/quartz/Math-Wiki/)\n- [Mike's AI Garden 🤖🪴](https://mwalton.me/)\n\nIf you want to see your own on here, submit a [Pull Request adding yourself to this file](https://github.com/jackyzha0/quartz/blob/hugo/content/notes/showcase.md)!\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":[]},"/notes/troubleshooting":{"title":"Troubleshooting and FAQ","content":"\nStill having trouble? Here are a list of common questions and problems people encounter when installing Quartz.\n\nWhile you're here, join our [Discord](https://discord.gg/cRFFHYye7t) :)\n\n### Does Quartz have Latex support?\nYes! See [CJK + Latex Support (测试)](notes/CJK%20+%20Latex%20Support%20(测试).md) for a brief demo.\n\n### Can I use \\\u003cObsidian Plugin\\\u003e in Quartz?\nUnless it produces direct Markdown output in the file, no. There currently is no way to bundle plugin code with Quartz.\n\nThe easiest way would be to add your own HTML partial that supports the functionality you are looking for.\n\n### My GitHub pages is just showing the README and not Quartz\nMake sure you set the source to deploy from `master` (and not `hugo`) using `/ (root)`! See more in the [hosting](/notes/hosting) guide\n\n### Some of my pages have 'January 1, 0001' as the last modified date\nThis is a problem caused by `git` treating files as case-insensitive by default and some of your posts probably have capitalized file names. You can turn this off in your Quartz by running this command.\n\n```shell\n# in the root of your Quartz (same folder as config.toml)\ngit config core.ignorecase true\n\n# or globally (not recommended)\ngit config --global core.ignorecase true\n```\n\n### Can I publish only a subset of my pages?\nYes! Quartz makes selective publishing really easy. Heres a guide on [excluding pages from being published](notes/ignore%20notes.md).\n\n### Can I host this myself and not on GitHub Pages?\nYes! All built files can be found under `/public` in the `master` branch. More details under [hosting](notes/hosting.md).\n\n### `command not found: hugo-obsidian`\nMake sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize `hugo-obsidian` as an executable.\n\n```shell\n# Add the following 2 lines to your ~/.bash_profile (~/.zshrc if you are on Mac)\nexport GOPATH=/Users/$USER/go\nexport PATH=$GOPATH/bin:$PATH\n\n# In your current terminal, to reload the session\nsource ~/.bash_profile # again, (~/.zshrc if you are on Mac)\n```\n\n### How come my notes aren't being rendered?\nYou probably forgot to include front matter in your Markdown files. You can either setup [Obsidian](notes/obsidian.md) to do this for you or you need to manually define it. More details in [the 'how to edit' guide](notes/editing.md).\n\n### My custom domain isn't working!\nWalk through the steps in [the hosting guide](notes/hosting.md) again. Make sure you wait 30 min to 1 hour for changes to take effect.\n\n### How do I setup analytics?\nQuartz by default uses [Plausible](https://plausible.io/) for analytics. \n\nIf you would prefer to use Google Analytics, you can follow this [guide in the Hugo documentation](https://gohugo.io/templates/internal/#google-analytics). \n\nAlternatively, you can also import your Google Analytics data into Plausible by [following this guide](https://plausible.io/docs/google-analytics-import).\n\n\n### How do I change the content on the home page?\nTo edit the main home page, open `/content/_index.md`.\n\n### How do I change the colours?\nYou can change the theme by editing `assets/custom.scss`. More details on customization and themeing can be found in the [customization guide](notes/config.md).\n\n### How do I add images?\nYou can put images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\n### My Interactive Graph and Backlinks aren't up to date\nBy default, the `linkIndex.json` (which Quartz needs to generate the Interactive Graph and Backlinks) are not regenerated locally. To set that up, see the guide on [local editing](notes/editing.md)\n\n### Can I use React/Vue/some other framework?\nNot out of the box. You could probably make it work by editing `/layouts/_default/single.html` but that's not what Quartz is designed to work with. 99% of things you are trying to do with those frameworks you can accomplish perfectly fine using just vanilla HTML/CSS/JS.\n\n## Still Stuck?\nQuartz isn't perfect! If you're still having troubles, file an issue in the GitHub repo with as much information as you can reasonably provide. Alternatively, you can message me on [Twitter](https://twitter.com/_jzhao) and I'll try to get back to you as soon as I can.\n\n🐛 [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":[]},"/notes/updating":{"title":"Updating","content":"\nHaven't updated Quartz in a while and want all the cool new optimizations? On Unix/Mac systems you can run the following command for a one-line update! This command will show you a log summary of all commits since you last updated, press `q` to acknowledge this. Then, it will show you each change in turn and press `y` to accept the patch or `n` to reject it. Usually you should press `y` for most of these unless it conflicts with existing changes you've made! \n\n```shell\nmake update\n```\n\nOr, if you don't want the interactive parts and just want to force update your local garden (this assumed that you are okay with some of your personalizations been overriden!)\n\n```shell\nmake update-force\n```\n\nOr, manually checkout the changes yourself.\n\n\u003e [!warning] Warning!\n\u003e\n\u003e If you customized the files in `data/`, or anything inside `layouts/`, your customization may be overwritten!\n\u003e Make sure you have a copy of these changes if you don't want to lose them.\n\n\n```shell\n# add Quartz as a remote host\ngit remote add upstream git@github.com:jackyzha0/quartz.git\n\n# index and fetch changes\ngit fetch upstream\ngit checkout -p upstream/hugo -- layouts .github Makefile assets/js assets/styles/base.scss assets/styles/darkmode.scss config.toml data \n```\n","lastmodified":"2023-08-07T23:34:18.706981173Z","tags":[]}}