{"/":{"title":"ü™¥ Quartz 3.3","content":"\nHost your second brain and [digital garden](https://jzhao.xyz/posts/networked-thought) for free. Quartz features\n\n1. Extremely fast natural-language [[notes/search]]\n2. Customizable and hackable design based on [Hugo](https://gohugo.io/)\n3. Automatically generated backlinks, link previews, and local graph\n4. Built-in [[notes/CJK + Latex Support (ÊµãËØï) | CJK + Latex Support]] and [[notes/callouts | Admonition-style callouts]]\n5. Support for both Markdown Links and Wikilinks\n\nCheck out some of the [amazing gardens that community members](notes/showcase.md) have published with Quartz or read about [why I made Quartz](notes/philosophy.md) to begin with.\n\n## Get Started\n\u003e üìö Step 1: [Setup your own digital garden using Quartz](notes/setup.md)\n\nReturning user? Figure out how to [[notes/updating|update]] your existing Quartz garden.\n\nIf you prefer browsing the contents of this site through a list instead of a graph, you see a list of all [setup-related notes](/tags/setup).\n\n### Troubleshooting\n- üöß [Troubleshooting and FAQ](notes/troubleshooting.md)\n- üêõ [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n- üëÄ [Discord Community](https://discord.gg/cRFFHYye7t)\n\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/Machine-Learning/LightGBM":{"title":"LightGBM","content":"","lastmodified":"2023-08-06T23:13:33.101022308Z","tags":[]},"/Machine-Learning/Machine-Learning/%C3%81rvores-de-decis%C3%A3o-Classifica%C3%A7%C3%A3o":{"title":"√Årvores de decis√£o - Classifica√ß√£o","content":"√Årvores de decis√£o s√£o algoritmos supervisionados n√£o param√©tricos que realizam classifica√ß√£o por meio da constru√ß√£o de uma estrutura em forma de √°rvore. Cada n√≥ interno da √°rvore representa uma condi√ß√£o sobre uma ou mais caracter√≠sticas, enquanto **as folhas** representam as classes finais preditas.\n\nA √°rvore come√ßa com um **n√≥ raiz**, onde a sele√ß√£o do atribute √© feita com base em algum crit√©rio, geralmente **[[Entropia]]** ou **[[Gini]]**. O intuito das separa√ß√µes √© obter o m√°ximo de homogeneidade poss√≠vel nas folhas.\n\n![[Pasted image 20230716175205.png | center]]\n\nCom base no atributo selecionado, os dados de treinamento s√£o divididos em subconjuntos em **n√≥s**, de acordo com os diferentes valores/resposta do atributo selecionado onde cada **n√≥** representa uma ramifica√ß√£o da √°rvore.\n\nO processo de sele√ß√£o de feature e ponto de corte se repete, criando uma estrutura de √°rvore, at√© que uma **condi√ß√£o de parada** seja atingida. A condi√ß√£o de parada geralmente reflete um determinado **√≠ndice de pureza das folhas** da √°rvore ou ocorre quando um **limite m√°ximo de profundidade** √© atingido, esses termos podem ser definidos nos hiperpar√¢metros \n\n![[Pasted image 20230716180257.png | center]]\n\nAp√≥s a constru√ß√£o da √°rvore, uma nova observa√ß√£o √© classificada percorrendo **as condi√ß√µes de cada n√≥ at√© chegar uma folha**, que cont√©m a classe predita pelo modelo.\n\n## **Exemplo**: \nClassificador se uma pessoa gosta ou n√£o gosta do filme Troll 2. partindo dos dados de treino a seguir:\n![[Pasted image 20230716185613.png | center]]\n\nPara decidir a raiz da √°rvore, vamos calcular o **√≠ndice de GINI** para de cada uma das duas vari√°veis categ√≥ricas:\n![[Pasted image 20230716191329.png | center]]\n\nPara a vari√°vel cont√≠nua **Age**, devemos ordenar (j√° est√° no exemplo), tirar a m√©dia entre cada linha e calcular o **√≠ndice de GINI** considerando **cada uma d√°s m√©dias como condi√ß√£o de ramifica√ß√£o no n√≥** e pegar a condi√ß√£o que retorna o melhor √≠ndice:\n![[Pasted image 20230716191834.png | center]]\n\nLogo a nossa raiz ser√° a condi√ß√£o **Loves Soda com GINI = 0.214**, devemos seguir com as demais vari√°veis, em qualquer n√≥ que ainda apresentar impureza, para determinar o resto da ramifica√ß√£o da √°rvore repetindo o mesmo processo **(Lembrando que o n√≥ resultando da resposta \"no\" j√° est√° puro e n√£o precisamos alterar)**\n\n![[Pasted image 20230716192751.png]]\n\nCom essa nova quebra, utilizando a condi√ß√£o **Age \u003c 12.5 com Gini = 0**, conseguimos ter uma √°rvore onde todas as folhas s√£o 100% puras, e assim n√£o temos mais pra que continuar ramificando, chegando a seguinte √°rvore de decis√£o:\n\n![[Pasted image 20230716193136.png | center]]\n\n## Problema de Overfitting\nPor ser um algoritmo de parti√ß√£o recursivo, a √°rvore estende a sua profundidade at√© o ponto de classificar perfeitamente os elementos do conjunto de treino, **podendo at√© mesmo zerar o n√∫mero de erros**. Desta forma o modelo pode n√£o generalizar para dados n√£o vistos.\nUma forma de reduzir o overfitting √© realizando a **poda** da √°rvore, que pode ser utilizada de duas formas: para o crescimento da √°rvore mais cedo ou ap√≥s a √°rvore j√° estar completa, geralmente tunando os hiperpar√¢metros\n\n### Vantagens\n- N√£o √© necess√°rio normalizar/padronizar os dados\n- F√°cil interpretabilidade e de f√°cil visualiza√ß√£o\n- Bom para problemas bin√°rios ou multiclasses\n- √ötil para saber descobrir a *feature importance* (sele√ß√£o de vari√°veis)\n- Features com baixa signific√¢ncia n√£o afetam a predi√ß√£o (por√©m aumenta o custo computacional)\n\n### Desvantagem\n- F√°cil de acontecer *overfitting* se n√£o cuidar dos hiperpar√¢metros\n- Sens√≠vel aos dados: varia√ß√£o nas amostras podem gerar √°rvores bem diferentes\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/Machine-Learning/Machine-Learning/%C3%81rvores-de-decis%C3%A3o-Regress%C3%A3o":{"title":"√Årvores de decis√£o - Regress√£o","content":"√Årvores de decis√£o s√£o algoritmos supervisionados n√£o param√©tricos que realizam a regress√£o por meio da constru√ß√£o de uma estrutura em forma de √°rvore. Cada n√≥ interno da √°rvore representa uma condi√ß√£o sobre uma ou mais caracter√≠sticas, enquanto **as folhas** representam as classes finais preditas.\n\nA √°rvore come√ßa com um **n√≥ raiz**, onde a sele√ß√£o do atribute √© feita com base em algum crit√©rio, como o [[Mean Squared Error (MSE)|MSE]] ou [[Mean Absolute Error (MAE)|MAE]]. O atributo selecionado √© aquele que melhor divide os dados e resulta na maior redu√ß√£o do erro de regress√£o.\n\nAs √°rvores de regress√£o tendem a fazer uma boa predi√ß√£o porque cada **folha** se torna um cluster de dados no gr√°fico e a **predi√ß√£o se torna a m√©dia dos pontos que ent√£o dentro da folha**:\n\n![[Pasted image 20230719215921.png|center]]\n\nOs pontos de ramifica√ß√£o s√£o definidos testando todas as m√©dias de dois pontos e verificando qual corte reduz com mais efici√™ncia o SSR:\n\n![[Pasted image 20230719221622.png|center]]\nNo nosso exemplo, Dose \u003c 14.5 foi o ponto escolhido, no n√≥ √† esquerda sobraram apenas 6 pontos, na teoria seria poss√≠vel dividir ainda mais esses dados, \u003cmark style=\"background: #FF5582A6;\"\u003epor√©m seguir com um n√∫mero t√£o baixo de pontos faz com que seja muito prov√°vel que ocorra overfitting do modelo\u003c/mark\u003e.\n\nUma maneira simples de evitar esse problema √© definir um valor m√≠nimo necess√°rio na folha para continuar a ramifica√ß√£o, 20 geralmente √© um valor razo√°vel, por√©m \u003cmark style=\"background: #ADCCFFA6;\"\u003eno exemplo usaremos 7 observa√ß√µes como valor m√≠nimo.\u003c/mark\u003e\n\nSeguindo o mesmo processo e considerando o crit√©rio m√≠nimo de observa√ß√µes definido acima, chegaremos √† seguinte √°rvore:\n\n![[Pasted image 20230719222315.png|center]]\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eOs ensembles como Random Forest e XGBoost tamb√©m podem ser utilizados em problemas de regress√£o\u003c/mark\u003e\n\n### Vantagens\n- N√£o √© necess√°rio normalizar/padronizar os dados\n- F√°cil interpretabilidade e de f√°cil visualiza√ß√£o\n- √ötil para saber descobrir a *feature importance* (sele√ß√£o de vari√°veis)\n- Features com baixa signific√¢ncia n√£o afetam a predi√ß√£o (por√©m aumenta o custo computacional)\n\n### Desvantagem\n- F√°cil de acontecer *overfitting* se n√£o cuidar dos hiperpar√¢metros\n- Sens√≠vel aos dados: varia√ß√£o nas amostras podem gerar √°rvores bem diferentes\n- Dif√≠cil captura de rela√ß√µes complexas nos dados\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/Machine-Learning/Machine-Learning/Acur%C3%A1cia":{"title":"Acur√°cia","content":"Representa a propor√ß√£o de classifica√ß√µes corretas **(independente da classe)** em rela√ß√£o ao total de amostras observadas\n$$ Acur√°cia = \\frac{TP+TN}{TP+TN+FP+FN} $$\n**Desvantagens**\n- Pode ser ilus√≥rio para classifica√ß√µes de problemas com **desbalanceamento de classes** (acur√°cia elevada mesmo com performance ruim do classificador)\n- Atribui o mesmo peso para ambos os erros, (alguns problemas tem maior ganho ao minimizar FP ou FN)\n\n**Vantagens**\n- M√©trica altamente interpret√°vel\n- Pode ser utilizada para comparar dois modelos\n- Medida √∫til para problemas de **classes balanceadas** onde a import√¢ncia de cada classifica√ß√£o √© semelhante (TP, TN)\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Aglomera%C3%A7%C3%A3o-Bottom-Up":{"title":"Aglomera√ß√£o (Bottom Up)","content":"O algoritmo se inicia com cada observa√ß√£o sendo seu pr√≥prio cluster (n clusters). Os dois clusters mais pr√≥ximos se unem para formar um novo cluster, os seguintes clusters que est√£o mais pr√≥ximos se unem para formar um novo e esse processo continua at√© existir apenas 1 cluster no fim, contendo todos o dataset.\n\n\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Boruta":{"title":"Boruta","content":"Boruta √© um algoritmo de feature selection desenvolvido em 2010 e desenhado para fazer uma sele√ß√£o autom√°tica de features em um banco de dados. Surgiu originalmente como um m√≥dulo no R, por√©m foi feita uma implanta√ß√£o em Python com mais flexibilidade nos par√¢metros.\n\nResumidamente, o Boruta permuta as features existentes nos bancos de dados (chamadas de **shadow features**) e compara sua import√¢ncia com as features originais, em teoria **qualquer feature significante** para a solu√ß√£o do problema tende a ser **mais importante do que a melhor shadow feature**.\n\n## Exemplo\nA seguir vamos exemplificar o funcionamento do m√©todo com um dataset simples, onde queremos **inferir a renda** de uma pessoa a partir da sua **idade**, **altura** e **peso**:\n\n![[Pasted image 20230719225255.png|center]]\n\n### Shadow Features\nNo Boruta, as features n√£o competem entre si, em vez disso elas s√£o comparadas com uma vers√£o randomizada delas mesmas, as denominadas **shadow features**. No nosso exemplo, ser√° criada a coluna **shadow_age** que representa a permuta√ß√£o das observa√ß√µes de **age**, e analogamente **shadow_height** e **shadow_weight**.\n\nEssas shadow features s√£o agrupadas ao dataset original de features, obtendo agora um novo dataframe *\"X_Boruta\"*:\n![[Pasted image 20230719230722.png|center]]\n\nPr√≥ximo passo √© ajustar uma [[Random Forest - Classifica√ß√£o|Random Forest]] utilizando **X_Boruta** para predizer **income**.\n\n### Avaliando as features importances\nAgora que temos as shadow features e o modelo ajustado, vamos calcular as features importances de cada uma das features no dataset *X_Boruta* e **identificar a maior feature importance obtida entre as shadow features**.\n\nQuando a importance de uma feature √© maior do que esse threshold, consideramos um \"acerto\". A ideia √© que **uma feature s√≥ √© importante se for capaz de explicar melhor a target do que a melhor shadow feature**.\n![[Pasted image 20230719231703.png|center]]\nAqui o threshold √© 14%, logo apenas 2 features atingiram a expectativa e foram consideradas √∫teis, **age** e **height**, enquanto **weight** n√£o performou bem. Aparentemente dever√≠amos desconsiderar a √∫ltima feature, por√©m \u003cmark style=\"background: #ADCCFFA6;\"\u003edevemos acreditar em apenas uma estimativa?\u003c/mark\u003e\n\n### Distribui√ß√£o Binomial\nComo em outros diversos m√©todos em machine learning, a itera√ß√£o √© uma ferramenta √∫til e que nos tr√°s muitos benef√≠cios, principalmente para validarmos a feature importance utilizando Boruta.\n\nSe realizarmos o processo de ajuste de modelo e contagem de \"acertos\" em 20 itera√ß√µes, obtemos os seguintes resultados:\n![[Pasted image 20230719232402.png|center]]\n\nAgora como podemos definir um **crit√©rio de decis√£o?** Vamos partir do pressuposto que n√£o temos a menor ideia se uma feature √© significante ou n√£o, qual a probabilidade que devemos mant√™-la? **O n√≠vel m√°ximo de incerteza √© 50%, como jogar uma moeda para tomar essa decis√£o**. \n\nComo cada itera√ß√£o nos retorna um resultado bin√°rio (acerto ou n√£o), \u003cmark style=\"background: #ADCCFFA6;\"\u003euma s√©rie de n itera√ß√µes segue uma distribui√ß√£o binomial\u003c/mark\u003e e vamos utilizar essa distribui√ß√£o para tomar a decis√£o:\n\n![[Pasted image 20230719233226.png|center]]\n\nAqui n√£o teremos um crit√©rio 100% objetivo para manter ou remover a feature, em vez disso usaremos √°reas de aceita√ß√£o:\n**√Årea de recusa**: representada de \u003cmark style=\"background: #FF5582A6;\"\u003evermelho\u003c/mark\u003e, se a distribui√ß√£o dos acertos de uma feature ca√≠rem aqui, consideramos ela n√£o significante e removemos do dataset.\n**√Årea de d√∫vida**: representada de \u003cmark style=\"background: #ADCCFFA6;\"\u003eazul\u003c/mark\u003e √© a √°rea onde o m√©todo √© indeciso se devemos manter ou remover a vari√°vel, e portanto, *temos a liberdade para tomar a decis√£o*.\n**√Årea de aceita√ß√£o:** representada de \u003cmark style=\"background: #BBFABBA6;\"\u003everde\u003c/mark\u003e, √°rea onde caem as features consideradas significantemente preditivas para o problema em quest√£o, e devem sempre ser mantidas.\n\nAs regi√µes s√£o definidas selecionando as duas caudas mais extremas da distribui√ß√£o binomial, onde cada cauda corresponde a aproximadamente 0.5% da distribui√ß√£o.\n\nEm resumo, ap√≥s 20 itera√ß√µes n√≥s podemos tomar decis√µes com base em estat√≠sticas bem definidas:\n1. Para o problema de inferir o **income**, devemos manter **age** como vari√°vel preditiva e remover a vari√°vel de **weight**\n2. O m√©todo de Boruta foi indeciso com rela√ß√£o a vari√°vel **height** e a escolha fica na nossa m√£o se devemos ou n√£o manter (se n√£o houver extrema necessidade de redu√ß√£o de custo operacional, √© recomend√°vel manter as vari√°veis na zona de d√∫vida)\n\nAp√≥s a defini√ß√£o das vari√°veis importante, \u003cmark style=\"background: #FF5582A6;\"\u003en√£o devemos esquecer de desconsiderar completamente as shadow features para o modelo final\u003c/mark\u003e.\n\n### Conclus√£o\nBoruta √© um m√©todo que realiza feature selection de maneira estatisticamente robusta, removendo o processo subjetivo de definir o threshold de corte que √© necess√°rio em v√°rias outras t√©cnicas de feature selection.","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Brier-Score":{"title":"Brier Score","content":"M√©trica de avalia√ß√£o utilizada para pedir a acur√°cia e a precis√£o de modelos de regress√£o probabil√≠stica ou at√© mesmo para problemas de classifica√ß√£o que possuem o output como probabilidade. √â equivalente ao erro quadr√°tico m√©dio ([[Mean Squared Error (MSE)|MSE]]) aplicado √†s probabilidades previstas.\n\nO Brier Score √© calculado como a m√©dia dos quadrados das diferen√ßas entre as probabilidades previstas pelo modelo e as probabilidades reais.\n\nSeja **y** o valor real e **p** o valor previsto pelo modelo, o Brier Score √© dado por:\n$$Brier Score = (p-y)^2$$\n\nO Brier Score varia entre 0 e 1, onde 0 representa uma previs√£o perfeita, e 1 representa a pior previs√£o poss√≠vel.\n\nDe forma geral, deve ser menor que 0.25\n\n\u003cmark style=\"background: #FF5582A6;\"\u003eDeve ser sempre aplicada √† regress√µes probabil√≠sticas\u003c/mark\u003e\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Classifica%C3%A7%C3%A3o":{"title":"Classifica√ß√£o","content":"Os modelos de classifica√ß√£o \u003cmark style=\"background: #ADCCFFA6;\"\u003eanalisam os dados de entrada e os padr√µes existentes para fazer previs√µes ou tomar decis√µes\u003c/mark\u003e\nUtilizado quando temos o objetivo de atribuir uma categoria ou r√≥tulo a uma entrada com base em caracter√≠sticas conhecidas. Por exemplo, √© poss√≠vel utilizar algoritmos de classifica√ß√£o para identificar se um e-mail √© spam ou n√£o bom base no conte√∫do e nas palavras utilizadas.\n\n[[T√©cnicas de modelagem - Classifica√ß√£o]]\n\n[[M√©tricas de avalia√ß√£o - Classifica√ß√£o]]\n\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Clustering":{"title":"Clustering","content":"Um modelo de clustering √© uma t√©cnica de machine learning n√£o supervisionada usada para agrupar dados em subgrupos ou clusters com base em suas similaridades. O objetivo √© encontrar padr√µes e estruturas nos dados, agrupando exemplos sem a necessidade de r√≥tulos ou categorias pr√©-definidas.\n\n[[T√©cnicas de modelagem - Clustering]]\n\n[[M√©tricas de avalia√ß√£o - Clustering]]\n#clustering\n","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Cross-Validation":{"title":"Cross Validation","content":"T√©cnica utilizada em aprendizado de m√°quina e estat√≠stica para avaliar o desempenho de um modelo de forma mais confi√°vel e evitar problemas de *overfitting*.\n\nPara evitar problemas de selecionarmos um subconjunto dos dados para treinamento que podem acabar gerando um modelo que sofra de *underfit* ou *overfit*, o **Cross Validation** nos oferece a possibilidade de utilizar \u003cmark style=\"background: #FF5582A6;\"\u003etodos\u003c/mark\u003e os dados para treinamento de maneira iterativa e \u003cmark style=\"background: #ADCCFFA6;\"\u003eavaliar a performance m√©dia do modelo.\u003c/mark\u003e\n\n\u003cmark style=\"background: #FF5582A6;\"\u003eObs: Cuidado para n√£o reutilizar os dados para treinamento e teste na mesma itera√ß√£o para n√£o acontecer Data Leakage.\u003c/mark\u003e\n\nNa Cross Validation executamos o processo de modelagem em diferentes subconjuntos dos dados para obtermos v√°rias avalia√ß√µes de desempenho do modelo.\n\n## Benef√≠cios\nCross-validation nos ajuda a obter uma valida√ß√£o mais assertiva da qualidade do modelo, por√©m devemos nos \u003cmark style=\"background: #ADCCFFA6;\"\u003eperguntar se o ganho gerado com essa t√©cnica compensa o incremento no custo computacional gerado pelo uso de cross-validation\u003c/mark\u003e.\n\nEm datasets menores, o processamento adicional de executar cross-validation n√£o ser√° significativo, poucos dados tamb√©m √© a situa√ß√£o onde utilizar apenas a separa√ß√£o de train-test n√£o √© muito eficiente, \u003cmark style=\"background: #ADCCFFA6;\"\u003eEm resumo quando temos poucos dados, o uso de cross-validation √© mais indicado.\u003c/mark\u003e\n\nPara datasets maiores o custo computacional extra √© mais expressivo, mas no geral se o modelo n√£o demorar muito para realizar o treinamento utilizar o cross-validation √© recomendado pois tende a trazer ganhos de modelagem.\n\n### Hold-Out\nForma mais simples de separar os dados. Define-se um percentual para cada conjunto de dados (treino, valida√ß√£o e teste) e cria-se as amostras. Geralmente utilizado quando h√° bastante dado, suficiente para que as amostram tenham signific√¢ncia estat√≠stica para representar a popula√ß√£o.\n![[image3_11zon_3898fc87c8.jpg|center]]\n\n### K-Fold\nNa t√©cnica de K-fold, n√≥s separamos o dataset original em K partes iguais e realizamos cada itera√ß√£o de experimento em um subconjunto diferentes de folds.\n![[1fXzJ.png|center]]\n\nNo exemplo, realizamos o treinamento no Experimento 1 usando o primeiro fold para teste e todos os outros para treinamento, ent√£o realizamos o segundo treinamento no Experimento 2 analogamente. Repetimos esse processo at√© que cada fold seja utilizada uma vez como teste, garantindo que usamos 100% dos dados como conjunto de teste em algum momento.\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eAo final das K itera√ß√µes, calcula-se o valor m√©dia para a m√©trica de avalia√ß√£o, obtendo-se assim uma medida mais confi√°vel sobre a capacidade de predi√ß√£o do modelo\u003c/mark\u003e, al√©m disso, podemos realizar uma divis√£o em k-fold estratificada. \n\n\n### Leave-one-out\nCaso especifico do **K-Fold, sendo K igual ao n√∫mero total de dados** N. Nesta abordagem s√£o realizados N c√°lculos de erro, um para cada dado.\n![[image2_11zon_cac3fb4270.jpg|center]]\n\nApesar de apresentar uma investiga√ß√£o completa sobre a varia√ß√£o do modelo, possui um alto custo computacional, sendo indicado para situa√ß√µes com poucos dados dispon√≠veis.\n\n### Out-of-sample e Out-of-time\n**Out-of-sample** s√£o dados n√£o vistos pelo modelo, n√£o foram utilizados no treino e ser√£o utilizados apenas para a previs√£o\n\n**Out-of-time** √© um out-of-time com dados obtidos posteriormente de quando o modelo foi treinado. S√£o amostras de dados de diferentes per√≠odos de tempo\n\n### Times Series Cross-Validation\nPara modelos de series temporais, podemos considerar uma t√©cnica de cross-validation que utiliza o tempo de captura dos dados para avaliar diferentes per√≠odos de tempo e no entanto, a generaliza√ß√£o do modelo para tempo futuro.\n\nComo a ordem dos dados √© de extrema import√¢ncia para series temporais, o corte entre conjunto de treino e teste deve ser definido conforme a cronologia dos dados:\n![[image6_11zon_1664949880.jpg|center]]","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/DBSCAN":{"title":"DBSCAN","content":"O algoritmo de clusteriza√ß√£o n√£o hier√°rquico que considera os clusters como regi√µes de maior/menor densidade, muito √∫til para distribui√ß√µes de dados que n√£o seguem um padr√£o esf√©rico/convexo.\n\nEsse algoritmo consegue identificar qualquer formato na distribui√ß√£o dos dados, verificando primariamente a similaridade entre os pontos.\n\nN√£o exige que o n√∫mero de clusters seja definido previamente e pode ser utilizado para detectar quais pontos apresentam caracter√≠sticas de ru√≠do/outliers. \n\nFunciona identificando pontos que est√£o em regi√µes densas:\n**Core**: S√£o os pontos que tiverem pelo menos um n√∫mero espec√≠fico de pontos (argumento *MinPts*) dentro do raio (argumento *Eps*). **S√£o pontos localizados no interior de um cluster**.\n**Border**: S√£o considerados pontos de fronteiras aqueles que tem um n√∫mero menos do que o definido pelo MinPts em seu raio, mas est√° na vizinhan√ßa de pelo menos 1 ponto **core**.\n**Noise:** S√£o os pontos que n√£o foram classificados como **core** ou **border**.\n\n![[Pasted image 20230722160043.png|center]]\n\n**Passo a passo:**\n1. Percorre e marca os pontos como **core**, **border** ou **noise**\n2. Desconsiderar os pontos marcados como **noise**\n3. Inserir uma aresta entre cada par de objetos de **core** vizinhos\n4. Cada componente conectado forma uma cluster\n5. Cada border √© atribu√≠do ao cluster de um de seus **core** associados\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Divis%C3%A3o-Top-Down":{"title":"Divis√£o (Top Down)","content":"O algoritmo se inicia com um √∫nico cluster, contendo todo o dataset. A observa√ß√£o com maior dissimilaridade (mais distante do cluster a partir de uma determina m√©trica) √© realocado no seu pr√≥prio cluster, as observa√ß√µes no cluster antigo que estiverem pr√≥ximas deste novo cluster ser√£o realocadas nele.\n\nEsse processo se repete at√© que cada observa√ß√£o se encontre em seu pr√≥prio cluster.\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Ensemble":{"title":"Ensemble","content":"T√©cnica utilizada em que m√∫ltiplos modelos (normalmente chamados de **modelos fracos**) s√£o treinados para resolver o mesmo problema e s√£o combinados posteriormente para gerar resultados melhores.\n\nOs modelos fracos (ou aprendizes fracos/modelos base) s√£o aqueles utilizados como blocos para a constru√ß√£o de modelo mais complexos. Na maioria dos casos estes modelos n√£o performam t√£o bem sozinhos pois podem ter um alto vi√©s e/ou alta vari√¢ncia. \n\nLogo a ideia de **Ensemble** √© reduzir vi√©s e/ou vari√¢ncia dos modelos fracos, combinando v√°rios deles com o objetivo de criar um √∫nico modelo preditivo forte que atinge melhores performances.\n\nDe forma geral, podemos dizer que **Bagging** ir√° focar principalmente em obter um modelo de ensemble com menos vari√¢ncia do que seus modelos base, enquanto **Boosting** e **Stacking** principalmente ir√£o tentar produzir modelos fortes com menos vi√©s dos que seus modelos base.\n\n## Bagging\nTamb√©m conhecido como **Bootstrap Aggregating**, essa t√©cnica se baseia na ideia de combinar o resultado de diferentes modelos do mesmo algoritmo que foram ajustados a amostras diferentes do conjunto de dados original. \u003cmark style=\"background: #ADCCFFA6;\"\u003eTal combina√ß√£o normalmente √© feita de forma uniforme, ou seja, o voto de cada modelo possui o mesmo peso.\u003c/mark\u003e\n\nEssa t√©cnica funciona por reduzir a variabilidade aleat√≥ria e considerar o voto majorit√°rio, especialmente em modelos inst√°veis como as de arvore de decis√£o.\n\nNo *bagging* \u003cmark style=\"background: #ADCCFFA6;\"\u003ev√°rias inst√¢ncias do mesmo modelo base s√£o treinadas em paralelo (de forma independente) em diferentes amostragens dos dados\u003c/mark\u003e e depois s√£o \u003cmark style=\"background: #ADCCFFA6;\"\u003eagregados em um processo \"m√©dio\"\u003c/mark\u003e. Como o objetivo √© obter um \u003cmark style=\"background: #FF5582A6;\"\u003emodelo com menor vari√¢ncia\u003c/mark\u003e, √© por esse motivo que o \u003cmark style=\"background: #FF5582A6;\"\u003emodelo base escolhido deve ter baixo vi√©s e alta vari√¢ncia\u003c/mark\u003e\n\n![[Pasted image 20230717222349.png | center]]\n\n[[Random Forest - Classifica√ß√£o |Random Forest]] √© um caso especial de *bagging* com √°rvore de decis√£o. Al√©m de cada √°rvore fazer uma amostragem nos dados, tamb√©m faz uma amostragem nas vari√°veis explicativas a serem utilizadas. Dessa forma o modelo d√° liberdade para destacar a import√¢ncia de features diferentes, que em um bagging simples n√£o apareceriam\n\n## Boosting\nEnsemble que reamostra os casos com base no erro do modelo. Ao identificar quais exemplos de treinamento um modelo do conjunto ensemble errou, na pr√≥xima reamostragem as observa√ß√µes previstas de forma errada ter√£o mais import√¢ncia, desta forma os erros ser√£o corrigidos em cada itera√ß√£o. \n\nExistem v√°rios algoritmos de Boosting, sendo os mais famosos: [[AdaBoost]], [[Gradient Boost]], [[XGBoost]], [[LightGBM]], [[CatBoost]]\n\nAo contr√°ria do *bagging* que tem como objetivo reduzir a vari√¢ncia, Boosting √© uma t√©cnica que \u003cmark style=\"background: #ADCCFFA6;\"\u003econsiste em ajustar de forma sequencial v√°rios modelos fraco\u003c/mark\u003es, de forma que uma import√¢ncia maior √© dada para as observa√ß√µes no dataset que tiveram maior erro no modelo anterior da sequ√™ncia. De forma intuitiva, cada novo modelo ir√° focar nas observa√ß√µes mais dif√≠ceis, dessa forma \u003cmark style=\"background: #ADCCFFA6;\"\u003eobtemos no final do processo um modelo forte com menor vi√©s (mesmo assim √© poss√≠vel perceber que o boosting tamb√©m pode ter o efeito de reduzir a vari√¢ncia)\u003c/mark\u003e.\n\n![[Pasted image 20230717223104.png | center]]\n\n## Stacking\nGeralmente considera diferentes tipos de modelos fracos (algoritmos diferentes), aprende eles de forma paralela e os combina atrav√©s do treino de um \"meta-modelo\", para ter uma predi√ß√£o final baseada na predi√ß√£o dos modelos fracos.\n\nNeste m√©todos os modelos fracos s√£o ajustados de forma independente e o meta-modelo √© treinado em cima das predi√ß√µes obtidas dos modelos fracos.\n\nAssumindo que queremos ajustar um *stacking* composto de \"L\" modelos fracos, ent√£o devemos:\n- Dividir a base de treino em duas partes\n- Escolher os \"L\" modelos fracos e ajusta-los em uma das  partes divididas (1¬™ parte)\n- Para cada modelo fraco devemos fazer a predi√ß√£o para as observa√ß√µes contidas na outra parte do dataset (2¬™ parte)\n- Ajuste o meta-modelo na 2¬™ parte do dataset dividido, usando as predi√ß√µes obtidas pelos modelos fracos como input\n![[Pasted image 20230717223749.png | center]]\n![[Pasted image 20230717223808.png | center]]\n\n","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Entropia":{"title":"Entropia","content":"Entropia pode ser definida como o grau de impureza de um conjunto. Se a amostra for completamente **homog√™nea** com rela√ß√£o as classes de um problema, **a entropia √© zero**. Se a amostra for **igualmente dividida entre as classes, tem entropia igual a 1**. \n\n$$Entropia = -\\sum_i P_i * log_2P_i$$\nA escolha do atributo para um n√≥ √© dada pelo **ganho de informa√ß√£o**, que √© definido como a redu√ß√£o na entropia esperada dado cada categoria do atributo.\n\n$$Ganho(A) = Entropia(S) - \\sum^{k}_{i=1}P_i*Entropia(A_i)$$\n$$\n\\begin{aligned}\n  \u0026Entropia(S): \\text{Entropia da amostra no n√≥ pai} \\\\\n  \u0026Entropia(A_i): \\text{Entropia na categoria \"i\" do atributo \"A\"} \\\\\n  \u0026P_i: \\text{Propor√ß√£o dos dados na categoria \"i\" do atributo \"A\" (comparado com o total de amostras)}\n\\end{aligned}\n$$\n\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/F1-Score":{"title":"F1-Score","content":"M√©dia harm√¥nica entre Precis√£o e Sensibilidade. Uma boa m√©trica para ser utilizada em conjunto de dados com classes desbalanceadas.\n$$ F1 = 2 *\\frac{Precis√£o *Recall}{Precis√£o + Recall} $$\nSe a precis√£o ou recall forem baixos, o F1 tamb√©m ser√° baixo. Ou seja, um modelo com alto F1 √© capaz de acertar suas predi√ß√µes (precis√£o alta) e tamb√©m recuperar os exemplos da classe de interesse (recall alto).\n\n**Desvantagens**\n- N√£o indicado para problemas onde uma das m√©tricas utilizadas √© de maior interesse (precis√£o ou recall), pois **assume a mesma import√¢ncia para ambas**\n- N√£o considera as classifica√ß√µes dos TN\n\n**Vantagens**\n- M√©trica adequada para problemas com **classes balanceadas**\n- Combina precis√£o e recall em uma m√©trica √∫nica\n- Pode ser utilizado para comparar modelos classificadores\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Feature-Selection":{"title":"Feature Selection","content":"Feature selection √© uma t√©cnica usada no campo de aprendizado de m√°quina e minera√ß√£o de dados para selecionar um subconjunto relevante e informativo de caracter√≠sticas (atributos) a partir de um conjunto de dados original. O objetivo da feature selection √© reduzir a dimensionalidade dos dados, mantendo apenas as caracter√≠sticas mais importantes para o problema em quest√£o.\n\nSelecionando as features mais relevantes, a *feature selection* busca:\n- **Reduzir a complexidade**: Diminuir o n√∫mero de caracter√≠sticas pode levar a modelos mais simples, r√°pidos e f√°ceis de interpretar\n- **Melhorar o desempenho**: Como teremos features mais significantes, os modelos podem obter uma melhor generaliza√ß√£o e desempenho em dados n√£o vistos\n- **Evitar overfitting**: Eliminar caracter√≠sticas irrelevantes ou redundantes pode ajudar a evitar o overfitting, onde o modelo se ajusta muito bem aos dados de treinamento, mas tem baixa capacidade de generaliza√ß√£o\n\nVamos conhecer alguns m√©todos de feature selection\n\n### [[Boruta]]","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Gaussian-Mixture-Models-GMM":{"title":"Gaussian Mixture Models (GMM)","content":"Algoritmos de clusteriza√ß√£o como o K-Means apesar de simples entendimento e f√°cil explica√ß√£o, possuem limita√ß√µes como a falta de flexibilidade no formato dos clusters (considera formatos circulares) e a falta de uma medida probabil√≠stica de atribui√ß√£o, ou seja, um elemento √© atribu√≠do apenas a um cluster e n√£o se tem ideia da probabilidade dele pertencer a um outro cluster.\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eCom o GMM √© poss√≠vel medir a incerteza na atribui√ß√£o do cluster,\u003c/mark\u003e incorporando as dist√¢ncia de cada ponto a todos os centroides, e a \u003cmark style=\"background: #ADCCFFA6;\"\u003eforma dos clusters passam a ser elipses\u003c/mark\u003e, podendo se ajustar melhor aos dados.\n\nO modelo GMM tenta encontrar uma mistura de distribui√ß√µes gaussianas de probabilidades multidimensionais que melhor modelem um conjunto de dados de entrada. Como ele trabalha com probabilidades, √© poss√≠vel saber qual a probabilidade de um elemento pertencer a cada cluster.\n\n![[Pasted image 20230722161112.png|center]]\n\nCada uma das K gaussianas possuem os seguintes par√¢metros:\n- Uma **m√©dia** que define seu centro.\n- Uma **matriz de covari√¢ncia** que define sua largura.\n- Uma fun√ß√£o de probabilidade que define qu√£o grande a gaussiana ser√°.\n![[Pasted image 20230722161411.png|center]]\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Gini":{"title":"Gini","content":"Indica o poder discriminat√≥rio do modelo, est√° relacionado com a curva ROC-AUC\n$$Gini = 2*AUC-1$$\n![[Pasted image 20230712202438.png]]\nEle varia de 0 a 1, onde 0 representa igualdade perfeita (ou seja, todas as observa√ß√µes t√™m o mesmo valor) e 1 representa desigualdade m√°xima (ou seja, uma √∫nica observa√ß√£o det√©m todo o valor)\n\n### Gini como m√©trica de ganho de informa√ß√£o (√Årvore)\nMede o grau de heterogeneidade dos dados, logo pode ser usado para medir a impureza de um **n√≥**\n$$Gini = 1 - \\sum^{c}_{i=1}P_{i}^{2}$$\n$$\\text{onde, } P_{i}^{2}: \\text{Frequ√™ncia relativa de cada classe(c) em cada n√≥ (em probabilidade)}$$\nQuando o √≠ndice √© igual a **zero, indica que o n√≥ √© puro**. Por outro lado, quanto mais se aproxima de 1 mais evid√™ncias temos de que o n√≥ √© **impuro (existem diversas classes dentro da mesma folha)**\n\nEm classifica√ß√µes bin√°rias, utilizar Gini tende a isolar num ramo os registros que representam a classe mais frequente.\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Gradient-Boost":{"title":"Gradient Boost","content":"","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Gradiente-Descendente":{"title":"Gradiente Descendente","content":"Gradiente descendente √© um algoritmo de otimiza√ß√£o utilizado para encontrar os m√≠nimos de uma fun√ß√£o, especialmente para problemas de machine learning e ajuste de modelos param√©tricos.\n\nO gradiente indica em qual dire√ß√£o o valor de uma fun√ß√£o cresce/decresce com maior velocidade.\n\nConsidere a equa√ß√£o de regress√£o linear:\n$$Y = \\beta_0+\\beta_1x+\\epsilon$$\nO m√©todo do gradiente descendente tem como objetivo minimizar o erro quadr√°tico m√©dio ([[Mean Squared Error (MSE)|MSE]] - fun√ß√£o de custo) de forma iterativa (atualizando todos os par√¢metros ao mesmo tempo) e consequentemente, encontrar os melhores valores para os coeficientes da equa√ß√£o (nesse exemplo **B0** e **B1**).\n\nO vetor gradiente tem uma dire√ß√£o e uma magnitude, a cada itera√ß√£o um novo ponto √© definido. Os algoritmos de gradiente descendente multiplicam o gradiente por um escalar conhecido como **taxa de aprendizado** para determinar o pr√≥ximo ponto.\nO valor da taxa de aprendizado √© importante, se for muito pequeno pode fazer o algoritmo demorar muito para aprender e se for muito grande pode fazer o algoritmo n√£o convergir.\n![[Pasted image 20230721172614.png|center]]\n\nDe forma geral, taxas de aprendizados menores requerem um n√∫mero maior de itera√ß√µes, dado que pequenas varia√ß√µes s√£o feitas a cada passo.","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Means":{"title":"K-Means","content":"M√©todo de agrupamento n√£o hier√°rquico que utiliza a \u003cmark style=\"background: #ADCCFFA6;\"\u003edist√¢ncia euclidiana\u003c/mark\u003e entre os pontos para o c√°lculo do centr√≥ide:\n$$d = \\sqrt{\\sum^{n}_{i=1}(x_i - y_i)^{2}}$$\n\nAjusta os centroides dos clusters com base nos valores m√©dios, e \u003cmark style=\"background: #FF5582A6;\"\u003epor utilizar a m√©dia √© mais sens√≠vel a outliers\u003c/mark\u003e.\n\nOs centroides finais podem n√£o ser pontos verdadeiras presentes na base, apenas o valor m√©dios dos pontos presentes no cluster.\n\nObs: A dist√¢ncia de Minkowski √© uma generaliza√ß√£o da dist√¢ncia euclidiana e da de Manhattan:\n$$d = (\\sum^{n}_{i=1}(x_i - y_i)^{p})^{\\frac{1}{p}}$$\n**Quando P=1** a dist√¢ncia √© de Manhattan\n**Quando P=2** a dist√¢ncia √© a Euclidiana\n\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Medians":{"title":"K-Medians","content":"M√©todo de agrupamento n√£o hier√°rquico que utiliza a \u003cmark style=\"background: #ADCCFFA6;\"\u003edist√¢ncia de Manhattan\u003c/mark\u003e entre os pontos para o c√°lculo dos centroides:\n$$d=\\sum^{n}_{i=1}(x_i-y_i)$$\nAjusta os centroides com base nos valores medianos de cada dimens√£o das inst√¢ncias atribu√≠das ao cluster e por considerar a \u003cmark style=\"background: #ADCCFFA6;\"\u003emediana, √© menos sens√≠vel a outliers\u003c/mark\u003e\n\n\n#clustering","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Medoids":{"title":"K-Medoids","content":"A ideia desse algoritmo √© fazer com que os centroides finais sejam pontos verdadeiros, ou seja, dados que de fato est√£o presentes no dataset. O principal objetivo √© tornar os centroides interpret√°veis, assim aumentando a interpretabilidade do cluster.\n\nO passo a passo se difere na atualiza√ß√£o dos centroides: \u003cmark style=\"background: #ADCCFFA6;\"\u003eao inv√©s de usar a m√©dia/mediana de todos os pontos do cluster, √© escolhido o ponto com menor valor de custo (objeto que se encontra mais pr√≥ximo do centro de gravidade do cluster)\u003c/mark\u003e\n\n#clustering","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Modes":{"title":"K-Modes","content":"M√©todo de agrupamento n√£o hier√°rquico utilizado para agrupar dados categ√≥ricos, j√° que os anteriores funcionam de maneira eficiente apenas para dataset com valores num√©ricos.\n\nK-Modes define os clusters com base no n√∫mero de categorias coincidentes entre os dados (n√∫mero de atributos categ√≥ricos comuns que s√£o compartilhados por dois pontos).\n\nSe baseia no algoritmo do K-means com as seguintes altera√ß√µes:\n1. Utiliza uma medida de dissimilaridade simples para dados categ√≥ricos\n2. Substitui a m√©dia dos clusters pela moda\n3. Utiliza m√©todo de frequ√™ncia para atualizar os valores das moda\n\nObs: Apesar de trabalhar com vari√°veis categ√≥ricas, as mesmas devem estar no formato num√©rico para entrar no modelo.\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/K-Prototypes":{"title":"K-Prototypes","content":"√â uma modifica√ß√£o do K-Means com K-Modes para trabalhar com datasets que possuem tanto vari√°veis num√©ricas quanto categ√≥ricas.\n\nEle mede a dist√¢ncia entre as vari√°veis usando a dist√¢ncia euclidiana e mede a dist√¢ncia entre as vari√°veis categ√≥ricas usando o n√∫mero de categorias coincidentes.\n\n#clustering","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Log-Loss":{"title":"Log-Loss","content":"![[1 rdBw0E-My8Gu3f_BOB6GMA.webp]]\n\n- M√©trica de classifica√ß√£o baseada nas probabilidades. Esta m√©trica pune previs√µes incorretas muito confiantes (alta probabilidade), por exemplo, prever uma classe com uma probabilidade de 95% e na realidade a correta ser a outra\n- √â uma medi√ß√£o suave de acur√°cia que incorpora a ideia de confian√ßa probabil√≠stica. De forma geral ==n√£o √© bom ser utilizada em datasets com classes desbalanceadas==\n- √â uma m√©trica boa para compara√ß√£o de modelos, para qualquer tipo de problema, quanto menor o valor do log-loss significa melhor predi√ß√£o\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/M%C3%A9tricas-de-avalia%C3%A7%C3%A3o-Classifica%C3%A7%C3%A3o":{"title":"M√©tricas de avalia√ß√£o - Classifica√ß√£o","content":"## Introdu√ß√£o\nAs seguintes m√©tricas servem para quantificar o desempenho e a qualidade das previs√µes feitas por modelos classificadores. Em resumo s√£o usadas para avaliar qu√£o bem um modelo est√° solucionando o problema em quest√£o, comparar diferentes modelos e selecionar o mais apropriado para a tarefa\n\n### [[Matriz de confus√£o]]\nResume a volumetria todos os poss√≠veis resultados de predi√ß√£o modelo de classifica√ß√£o\n\n### [[Acur√°cia]]\nPropor√ß√£o de classifica√ß√µes corretamente classificadas pelo modelo de classifica√ß√£o\n\n### [[Precision]]\nAKA: Precis√£o\nPropor√ß√£o de observa√ß√µes ==corretamente classificadas como positivas==\n\n### [[Recall]]\nAKA: Sensibilidade\nPropor√ß√£o de ==observa√ß√µes positivas classificadas corretamente==\n\n### [[F1-Score]]\nCombina√ß√£o de [[Precision]] e [[Recall]], penalizando sempre pela m√©trica de menor valor\n\n### [[Specificity]]\nAKA: Especificidade\nPropor√ß√£o de ==observa√ß√µes negativas classificadas corretamente==\n\n### [[ROC-AUC]]\nCurva criada a partir da TPR([[Recall]]) e FPR(1-[[Specificity]])\n\n### [[Gini]]\nMedida de dissimilaridade variando de 0 a 1, onde 1 representa dissimilaridade m√°xima\n\n### [[Log-Loss]]\nMede a discrep√¢ncia entre as probabilidades previstas pelo modelo de classifica√ß√£o e as classes reais\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/M%C3%A9tricas-de-avalia%C3%A7%C3%A3o-Clustering":{"title":"M√©tricas de avalia√ß√£o - Clustering","content":"Como as t√©cnicas de clustering n√£o s√£o supervisionadas, n√£o h√° resposta para o c√°lculo do **erro**, por√©m existem 3 tipos de crit√©rios que podemos considerar para avaliar os agrupamentos gerados:\n\n## Externos\nAvaliam o grau de correspond√™ncia entre a estrutura dos grupos (parti√ß√£o ou hierarquia) \u003cmark style=\"background: #ADCCFFA6;\"\u003esob avalia√ß√£o e informa√ß√£o a priori\u003c/mark\u003e na forma de uma solu√ß√£o de agrupamento esperada ou conhecida.\n\n#### Resultado previamente conhecido:\n- Reconhecimento visual dos clusters naturais (bases em duas ou tr√™s dimens√µes)\n- Opini√£o de um especialista de dom√≠nio\n- Bases geradas sinteticamente com distribui√ß√µes conhecidas (benchmark)\n- Bases de classifica√ß√£o sob hip√≥tese que classes s√£o clusters\n\n#### Rand Index\nMede a similaridade entre dois clusters (compara√ß√£o de pares de objetos).\n$$RI = \\frac{a+d}{a+b+c+d}$$\n**a**: N√∫mero de pares que pertencem √† mesma classe e ao mesmo cluster\n**b**: N√∫mero de pares que pertencem √† mesma classe e a clusters distintos\n**c**: N√∫mero de pares que pertencem √† classes distintas e mesmo cluster\n**d**: N√∫mero de pares que pertencem √† classes e clusters distintos\n**Classes:** Grupos da parti√ß√£o de refer√™ncia\n**Clusters:** Grupos da parti√ß√£o sob avalia√ß√£o\n\nO Rand Index pode ser interpretado como a porcentagem de decis√µes corretas feitas pelo algoritmo. Varia de 0 a 1, onde 0 indica que os clusters n√£o se assemelham em nenhum par de pontos e 1 indica que os clusters s√£o id√™nticos.\n\n#### Limita√ß√µes\nVi√©s de favorecer a compara√ß√£o de parti√ß√µes com n√≠veis mais elevados de granularidade (valores mais elevados ao comparar parti√ß√µes com mais grupos), h√° mesmo peso para objetos agregados (a) e separados (d), sendo que **d** tende a dominar o √≠ndice (quanto mais grupos, mais pares pertencem a grupos distintos)\n\n## Internos\nAvaliam o grau de compatibilidade enrtre a estrutura de grupos sob avalia√ß√£o e os dados, usando apenas os pr√≥prios dados. \n\nComo o **WCSS** utilizado no m√©todo de cotovelo.\n\n## Relativos\nAvaliam qual dentre duas ou mais estruturas de grupos √© melhor sob algum aspecto. Tipicamente s√£o crit√©rios internos capazes de quantificar a qualidade relativa. \n\nComo o crit√©rio da largura de Silhueta (**SWC**)\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/M%C3%A9tricas-de-avalia%C3%A7%C3%A3o-Regress%C3%A3o":{"title":"M√©tricas de avalia√ß√£o - Regress√£o","content":"### Introdu√ß√£o\nAs m√©tricas de avalia√ß√£o para modelos de regress√£o s√£o medidas usadas para quantificar o desempenho e a qualidade das previs√µes feitas por esses modelos. Elas s√£o usadas para avaliar o qu√£o bem o modelo de regress√£o est√° ajustando-se aos dados e para comparar diferentes modelos.\n\n### [[Mean Squared Error (MSE)]]\n\n### [[Root Mean Squared Error (RMSE)]]\n\n### [[Mean Absolute Error (MAE)]]\n\n### [[Mean Absolute Percentual Error (MAPE)]]\n\n### [[R¬≤]]\n\n### [[Brier Score]]\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Machine-Learning":{"title":"Machine Learning","content":"Machine learning √© um campo da intelig√™ncia artificial que se concentra no desenvolvimento de algoritmos e modelos capazes de aprender padr√µes e tomar decis√µes com base em dados, sem a necessidade de serem explicitamente programados para cada tarefa especifica. \n\nEssa abordagem ==tende a melhores resultados √† medida que temos mais dados== dispon√≠veis para nos auxiliar nas resolu√ß√µes de problemas.\n\nExistem diferentes tipos de problemas que podem ser abordados com Machine Learning, e eles podem ser agrupados em tr√™s grandes grupos: Regress√£o, Classifica√ß√£o e Agrupamento\n\n## [[Classifica√ß√£o]]\nOs modelos de classifica√ß√£o ==analisam os dados de entrada e os padr√µes existentes para fazer previs√µes ou tomar decis√µes.==\nUtilizado quando temos o objetivo de atribuir uma categoria ou r√≥tulo a uma entrada com base em caracter√≠sticas conhecidas. Por exemplo, √© poss√≠vel utilizar algoritmos de classifica√ß√£o para identificar se um e-mail √© spam ou n√£o bom base no conte√∫do e nas palavras utilizadas.\n\n## [[Regress√£o]]\nOs modelos de regress√£o buscam ==identificar rela√ß√µes e tend√™ncias nos dados para realizar previs√µes num√©ricas==.\nUtilizado quando o objetivo √© prever um valor cont√≠nuo com base em vari√°veis de entrada. Por exemplo, √© poss√≠vel utilizar algoritmos de regress√£o para prever o pre√ßo de uma casa com base em recursos como tamanho, n√∫mero de quartos, localiza√ß√£o, entre outros.\n\n## [[Clustering]]\nOs modelos de agrupamento buscam identificar estruturas e relacionamentos ocultos nos dados sem a necessidade de r√≥tulos categorias pr√©-definidas.\nUtilizado quando o objetivo √© ==identificar grupos ou clusters naturais nos dados==, onde as observa√ß√µes s√£o semelhantes umas √†s outras dentro de um mesmo grupo, mas diferentes de observa√ß√µes em outros grupos. Por exemplo, √© poss√≠vel utilizar algoritmos de agrupamento para segmentar clientes com base em seus padr√µes de compra ou agrupar documentos por t√≥picos similares.\n\n\n","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Matriz-de-confus%C3%A3o":{"title":"Matriz de confus√£o","content":"Representa a frequ√™ncia com que cada classe do modelo √© classificada corretamente ou incorretamente. Sua diagonal principal representa as classifica√ß√µes corretas, enquanto as demais c√©lulas mostram as classifica√ß√µes incorretas.\n![[Untitled.png]]\nA partir de suas informa√ß√µes pode-se calcular diversos outros indicadores de qualidade de classifica√ß√£o\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Mean-Absolute-Error-MAE":{"title":"Mean Absolute Error (MAE)","content":"Representa a m√©dia do erro absoluto do modelo de regress√£o, **penaliza mais os erros com maiores magnitudes**, dando menos import√¢ncia para os erros pequenos.\n\n$$MAE = \\frac{1}{n}\\sum^{n}_{i=1}|y-\\hat{y}|$$\n### Vantagens\n- M√©trica de f√°cil interpreta√ß√£o, medida sai na mesma escala original dos dados de interesse\n- Pouco sens√≠vel √† outliers\n\n### Desvantagens\n- Fun√ß√£o da m√©trica n√£o √© diferenci√°vel, n√£o pode ser utilizada como fun√ß√£o de custo\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Mean-Absolute-Percentual-Error-MAPE":{"title":"Mean Absolute Percentual Error (MAPE)","content":"Transforma√ß√£o do [[Mean Absolute Error (MAE)|MAE]] que representa a m√©dia do erro percentual absoluto do modelo de regress√£o, **penalizando mais os erros com maiores magnitudes**, dando menos import√¢ncia para os erros pequenos.\n\n$$MAPE = \\frac{100}{n}\\sum^{n}_{i=1}\\frac{|y-\\hat{y}|}{y}$$\n### Vantagens\n- M√©trica de f√°cil interpreta√ß√£o, pois representa o percentual de erro que o modelo nos retorna\n- Pouco sens√≠vel √† outliers\n\n### Desvantagens\n- Fun√ß√£o da m√©trica n√£o √© diferenci√°vel, n√£o pode ser utilizada como fun√ß√£o de custo\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Mean-Squared-Error-MSE":{"title":"Mean Squared Error (MSE)","content":"Representa a m√©dia dos erros (res√≠duos) elevado ao quadrado, **penaliza mais os erros com maior diferen√ßa**, dando menos import√¢ncia para os erros pequenos.\n\n$$MSE = \\frac{1}{n}\\sum^{n}_{i=1}(y - \\hat{y})^2 = \\frac{SSR}{n}$$\n### Vantagens\n- Fun√ß√£o deriv√°vel, pode ser utilizada como fun√ß√£o de custo\n\n### Desvantagens\n- Muito sens√≠vel a outliers\n- Dificulta a interpreta√ß√£o da m√©trica pelo resultado ser o quadrado da magnitude real da vari√°vel de interesse\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Naive-Bayes":{"title":"Naive Bayes","content":"√â um algoritmo de e classifica√ß√£o baseado no Teorema de Bayes e na suposi√ß√£o de independ√™ncia condicional entre as vari√°veis explicativas, costumando ter alto vi√©s e baixa vari√¢ncia. **Considerado ing√™nuo (naive) porque assume total independ√™ncia entre as vari√°veis**, mesmo que n√£o seja necessariamente verdade nos dados reais.\n\n*Durante a descri√ß√£o ser√° utilizado um exemplo de classifica√ß√£o de e-mail como \"\u003cmark style=\"background: #ADCCFFA6;\"\u003eNormal\u003c/mark\u003e\" ou \"\u003cmark style=\"background: #FF5582A6;\"\u003eSpam\u003c/mark\u003e\"*\nO primeiro passo √© calcular as probabilidades a priori de cada classe com base na frequ√™ncia que cada classe ocorre nos dados de treinamento:\n![[Pasted image 20230716151827.png]]\nTamb√©m calculamos as probabilidades condicionais de cada valor de cada caracter√≠stica para cada classe, no nosso exemplo s√£o palavras presentes nos e-mail de treino:\n![[Pasted image 20230716152356.png]]\n\nQuando uma nova observa√ß√£o surge e temos que fazer a predi√ß√£o com Naive Bayes, o algoritmo utiliza as probabilidades calculadas para calcular a probabilidade posterior de cada classe para aquela observa√ß√£o (gera um Score). A classe com maior Score √© selecionada como a classe predita para a informa√ß√£o\n\nVamos supor que receber um novo e-mail contendo **\"Dear friend\"** e desejamos utilizar o modelo para classifica-lo como Normal ou Spam, vamos calcular os Scores para cada classe:\n\n$$P(N)*P(Dear|N)*P(Friend|N) = 0.67*0.47*0.29 = 0.09$$\n$$P(S)*P(Dear|S)*P(Friend|S) = 0.33*0.29*0.25 = 0.01$$\nComo a classe predita √© derivada da classe com maior Score calculado, definimos esse novo e-mail como \u003cmark style=\"background: #ADCCFFA6;\"\u003eNormal\u003c/mark\u003e\n\nO exemplo **\"Dear friend\"** funciona porque existe, em ambas as classes, observa√ß√µes que apareceram durante os e-mails de treinamento, por√©m dados discretos faltantes podem se tornar um grande problema bem r√°pido para o Naive Bayes.\n\nUm exemplo problem√°tico seria classificar um novo e-mail **\"Lunch Money Money Money Money\"** dados que a probabilidade a priori de observar \"Lunch\" no Spam √© zero:\n\n$$P(N)*P(Lunch|N)*P(Money|N)^4 = 0.67*0.18*0.06^4 = 0.000002$$\n$$P(S)*P(Lunch|S)*P(Money|S)^4 = 0.33*0.00*0.57^4 = 0$$\n## Como Naive Bayes trata dados faltantes\nNormalmente, o algoritmo de Naive Bayes elimina o problema de dados faltantes realizando uma \"pseudo contagem\" de cada palavra. N√£o √© nada mais do que adicionar uma contagem para **cada palavra em todas as classes**.\n\nAssim podemos recalcular as **probabilidades condicionais** de cada palavra e n√£o corremos o risco de alguma ser zero e impactar o c√°lculo de qualquer combina√ß√£o presente no e-mail:\n![[Pasted image 20230716155700.png]]\n\n$$P(N)*P(Lunch|N)*P(Money|N)^4 = 0.67*0.19*0.10^4 = 0.00001$$\n$$P(S)*P(Lunch|S)*P(Money|S)^4 = 0.33*0.09*0.45^4 = 0.00121$$\nAssim classificando o e-mail corretamente como \u003cmark style=\"background: #FF5582A6;\"\u003eSpam\u003c/mark\u003e\n\n## Utilizando dados cont√≠nuos\nQuando existe a necessidade de utilizar dados cont√≠nuos dentro do Naive Bayes utilizamos na formula  em vez da probabilidade condicional, a verossimilhan√ßa da vari√°vel considerando as distribui√ß√µes para cada uma das classes.\n\n*Obs: Probabilidade e Verossimilhan√ßa representam informa√ß√µes diferentes em estat√≠stica, consultar:[[Probabilidade vs Verossimilhan√ßa]]*\n\nVamos seguir com o exemplo de classificar se uma pessoa vai \u003cmark style=\"background: #ADCCFFA6;\"\u003egostar\u003c/mark\u003e ou \u003cmark style=\"background: #FF5582A6;\"\u003en√£o gostar\u003c/mark\u003e do filme Troll 2:\n![[Pasted image 20230716161544.png]]\n$$P(Gostar) = \\frac{4}{7}=0.57$$\n$$P(N Gostar) = \\frac{3}{7}=0.42$$\nSurge uma nova observa√ß√£o para predizer, com os seguintes dados: Popcorn = 20g, Soda= 500ml e Candy = 100g\n\n$$(1):P(G)*L(Popcorn=20|G)*L(Soda=500|G)*L(Candy=100|G) = 0.57*0.06*0.004*0.000000001$$\n==Para evitar problemas de *Underfloat* quando multiplicamos n√∫meros muito pr√≥ximos de zero, uma alternativa √© utilizar log natural para transformar toda a f√≥rmula e tornar a multiplica√ß√£o em adi√ß√£o:==\n\n$$(1):log(0.57*0.06*0.004*0.000000001)$$\n$$log(0.57)+log(0.06)+log(0.004)+log(0.000000001) = -124$$\n$$(2): P(NG)*L(Popcorn=20|NG)*L(Soda=500|NG)*L(Candy=100|NG)$$\n$$log(0.4)*log(0.000000001)*log(0.00008)*log(0.02) = -48$$\nLogo classificamos a nova observa√ß√£o como \u003cmark style=\"background: #FF5582A6;\"\u003eN√£o Gosta de Troll 2\u003c/mark\u003e\n\n### Vantagens\n- Algoritmo de baixa complexidade computacional e pode ser usado em *\"real time\"*\n- Escal√°vel para datasets grandes (performa bem em base com alta dimensionalidade)\n- Pouco sens√≠vel para features n√£o significantes\n- Eficaz em problemas de multiclasses\n- √ötil para classificar textos, an√°lise de sentimentos, detec√ß√£o de spam e sistemas de recomenda√ß√£o\n\n### Desvantagem\n- Sup√µe que as vari√°veis s√£o independentes, o que n√£o √© verdade na maioria das vezes\n- Mau estimador em probabilidade, suas probabilidades (*predict_proba*) n√£o s√£o t√£o assertivas\n- Os dados de treino devem representar muito bem a popula√ß√£o (preenchimento de vari√°vel/p√∫blico todo capturado na base de treino)\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.105022356Z","tags":[]},"/Machine-Learning/Machine-Learning/Precision":{"title":"Precision","content":"M√©trica que d√° √™nfase para erros por FP (casos incorretamente classificados como positivos). Responde a pergunta: **Dos exemplos classificados como positivos, quantos s√£o realmente positivos?**\n$$ Precis√£o = \\frac{TP}{TP+FP} $$\n\n**Desvantagens**\n- Ignora completamente os erros de classificar uma amostra positiva como negativa (falso negativo)\n\n**Vantagens**\n- M√©trica adequada para problemas onde existe **grave consequ√™ncia para falsos positivos**\n- Ao ser utilizado junto √† ==Sensibilidade==, traz um insight valioso quando a **classifica√ß√£o positiva √© mais relevante**\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Probabilidade-vs-Verossimilhan%C3%A7a":{"title":"Probabilidade vs Verossimilhan√ßa","content":"Probabilidade e Verossimilhan√ßa s√£o termos comumente intercalados durante conversas sobre Machine Learning. Por√©m no contexto de estat√≠stica cada um tem um papel e descreve informa√ß√µes completamente diferentes.\n\n### Probabilidade\nProbabilidade √© uma medida num√©rica que quantifica a chance de um evento ocorrer e √© derivada a partir de uma distribui√ß√£o, calculando a **√°rea abaixo da curva entre dois pontos**:\n![[Pasted image 20230715180903.png]]\nPor exemplo: dada a distribui√ß√£o de altura de uma popula√ß√£o que segue um Normal com m√©dia = 155.7 e desvio padr√£o = 6.6, podemos calcular a **probabilidade de realizar uma medi√ß√£o e observar um valor entre 142.5 e 155.7cm**. \nA √°rea abaixo da curva no exemplo anterior √© igual a 0.48, logo a probabilidade de medirmos algu√©m que possua o altura no intervalo descrito √© de 48%.\n\nAnalogamente √© f√°cil notar que em **qualquer distribui√ß√£o cont√≠nua** ==a probabilidade de observar um valor especifico √© sempre **ZERO**==, pois n√£o conseguimos calcular √°rea de um figura com comprimento 0.\n\n### Likelihood\nLikelihood ou Verossimilhan√ßa √© uma medida estat√≠stica que quantifica a plausibilidade de qu√£o bem os par√¢metros de um modelo se ajustam aos dados.\n\nSeguindo o exemplo anterior, a verossimilhan√ßa √© usada para calcular o qu√£o prov√°vel √© os par√¢metros do modelo gerarem exatamente as observa√ß√µes que temos.\n![[Pasted image 20230715182357.png]]\n\nEm resumo, a principal diferen√ßa entre probabilidade e likelihood √© a dire√ß√£o do racioc√≠nio estat√≠stico. A probabilidade √© usada para calcular a chance de eventos futuros com base em um modelo conhecido, enquanto a verossimilhan√ßa √© usada para estimar os par√¢metros do modelo com base em dados observados\n\n#conceitos","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/R":{"title":"R¬≤","content":"Representa a porcentagem de ganho de predi√ß√£o por usar o modelo, quando comparado apenas a m√©dia dos dados.\n\n$$R^2=\\frac{SSR(mean)-SSR(fit)}{SSR(mean)}$$\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eO R¬≤ tamb√©m pode ser calculado com o MSE no lugar do SSR\u003c/mark\u003e.\n\nQuanto mais perto o R¬≤ se aproximar de 1, melhor o modelo de ajusta ao dados de treinamento em compara√ß√£o com a m√©dia dos valores.\n\nPara verificar o c√°lculo, vamos seguir com um exemplo que prediz altura com base no peso de uma pessoa:\n\nCome√ßamos calculando a soma do res√≠duos ao quadrado da m√©dia:\n![[Pasted image 20230718225252.png|center]]\n$$SSR(mean) = (1.2-1.9)^2 +(2.2-1.9)^2 +(1.4-1.9)^2 +(2.7-1.9)^2 +(2.3-1.9)^2 =1.6$$\nEm seguida, calculamos a soma dos res√≠duos ao quadrado do modelo ajustado:\n![[Pasted image 20230718225552.png|center]]\n$$SSR(fit) = (1.2-1.1)^2 +(2.2-1.8)^2 +(1.4-1.9)^2 +(2.7-2.4)^2 +(2.3-2.5)^2 =0.5$$\nAgora temos todos os componentes necess√°rios para o c√°lculo da m√©trica:\n$$R^2=\\frac{SSR(mean)-SSR(fit)}{SSR(mean)}=\\frac{1.6-0.5}{1.6}=0.7$$\nO R¬≤ ser 0.7 indica que tivemos uma **redu√ß√£o de 70% no tamanho dos res√≠duos** por usar a reta ajustada pelo modelo.\n\n### Rela√ß√£o com Correla√ß√£o de Pearson\nA correla√ß√£o de Pearson pode ser calculada a partir do R¬≤ com a seguinte rela√ß√£o:\n$$R^2 = r^2 =\\rho^2$$\n### R¬≤ ajustado\n\n\n\n#todo \nR¬≤ ajustado\nrelacionar R¬≤ com p-valor\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/ROC-AUC":{"title":"ROC-AUC","content":"Avalia a performance de um classificador para diferentes limiares de classifica√ß√£o, relacionando a Taxa de Falso Positivo (FPR) e a Taxa de Verdadeiro Positivo (TPR)\n$$TPR = \\frac{TP}{TP+FN}; FPR = \\frac{FP}{FP+TN}$$\n![[Pasted image 20230712201216.png]]\n-  Quanto mais pr√≥xima a curva estiver do canto superior esquerdo melhor √© a predi√ß√£o do modelo, uma vez que sua TPR = 100% com FPR = 0%\n-  Linha tracejada indica qual seria a curva que atribui as classes aleatoriamente\n-  √Årea sob a curva (AUC) pode ser usada como m√©trica do modelo\n-  ==M√©trica pouco sens√≠vel a problemas de classes desbalanceadas==\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Random-Forest-Classifica%C3%A7%C3%A3o":{"title":"Random Forest - Classifica√ß√£o","content":"Random Forest √© um algoritmo que realiza o [[Ensemble]] de v√°rias [[√Årvores de decis√£o - Classifica√ß√£o|√Årvores de decis√£o]] para realizar classifica√ß√£o em problemas complexos. Ele utiliza um conjunto de √°rvores de decis√£o aleat√≥rias e faz **predi√ß√£o com base em uma vota√ß√£o majorit√°ria das √°rvores individuais**\n\nUtilizando **Bagging** para criar diferentes conjuntos de treinamento a partir do conjunto de dados original. Cada conjunto de treinamento √© obtido atrav√©s de uma amostragem aleat√≥ria com reposi√ß√£o, o que permite que exemplos se repitam ou sejam omitidos em cada conjunto.\n\nPara cada conjunto de treinamento √© constru√≠da uma [[√Årvores de decis√£o - Classifica√ß√£o|√Årvore de decis√£o]]. Durante a constru√ß√£o o algoritmo seleciona um subconjunto aleat√≥rio de features a partir do conjunto total de caracter√≠sticas. Isso ajuda a reduzir a corre√ß√£o entre as √°rvores e aumentar a diversidade do conjunto de √°rvores.\n\nAp√≥s a constru√ß√£o de todas √°rvores, a Random Forest faz a classifica√ß√£o de um exemplo de teste atrav√©s de uma vota√ß√£o majorit√°ria. Cada √°rvore d√° o seu voto e a classe mais votada √© considerada a classe final predita.\n\nTamb√©m pode ser utilizada para fornecer uma medida de import√¢ncia de cada feature, calculando a **redu√ß√£o m√©dia do √≠ndice Gini** ou do **ganho de informa√ß√£o** ao usar cada caracter√≠stica para dividir os n√≥s das √°rvores, ajudando a identificar quais s√£o as features mais importantes para o problema\n\nEm resumo Random Forest √© muito utilizado por sua capacidade de lidar com dados complexos, grande quantidade de features e tend√™ncia de *overfitting*. Ele combina as previs√µes de v√°rias √°rvores de decis√£o (modelos fracos) para **reduzir a vari√¢ncia** e **melhorar a precis√£o geral** do modelo.\n\n### Vantagens\n- Erro reduzido (em compara√ß√£o a uma √°rvore de decis√£o)\n- Boa performance em datasets desbalanceados\n- Pode trabalhar com conjunto de dados muito grandes\n- Lida bem com valores nulos\n- N√£o tem problema t√£o grande de *overfitting*, pela utiliza√ß√£o de v√°rias √°rvores aleat√≥rias\n- N√£o sens√≠vel a outliers\n- √ötil para extrair o feature importance\n\n### Desvantagem\n- Features precisam ter import√¢ncia para predi√ß√£o, se n√£o pode prejudicar o algoritmo\n- Predi√ß√µes das √°rvores n√£o devem estar correlacionadas\n- Abre m√£o da interpretabilidade/processo de tomada de decis√£o pela performance\n\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Recall":{"title":"Recall","content":"Tamb√©m conhecida como taxa de verdadeiro positivo (TPR), d√° maior √™nfase para erros por FN (casos incorretamente classificados como negativos).\n\nResponde a pergunta: Dos exemplo positivos, quantos foram classificados corretamente?\n$$ Sensibilidade = \\frac{TP}{TP+FN} $$\n**Desvantagens**\n- N√£o considera erros ao classificar amostras negativas como positivas (falso positivo)\n\n**Vantagens**\n- M√©trica adequada para problemas onde existe **grave consequ√™ncia para falsos negativos**\n- Ao ser utilizado junto √† Precis√£o, traz um insight valioso quando a **classifica√ß√£o positiva √© mais relevante**\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Rede-Neural":{"title":"Rede Neural","content":"","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Regress%C3%A3o":{"title":"Regress√£o","content":"Um modelo de regress√£o √© uma t√©cnica estat√≠stica usada para modelar a rela√ß√£o entre uma vari√°vel dependente cont√≠nua e uma ou mais vari√°veis independente. \n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eO objetivo √© encontrar uma fun√ß√£o matem√°tica que descreva essa rela√ß√£o e permita fazer previs√µes ou infer√™ncias sobre os valores da vari√°vel dependente com base nas vari√°veis independentes.\u003c/mark\u003e\n\n[[T√©cnicas de modelagem - Regress√£o]]\n\n[[M√©tricas de avalia√ß√£o - Regress√£o]]\n\n#regress√£o\n","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Regress%C3%A3o-Linear":{"title":"Regress√£o Linear","content":"Tipo de regress√£o em que os coeficientes podem ser expressos por uma combina√ß√£o linear de elementos (b0, b1, b2, ...), os quais s√£o justamente os valores que n√£o sabemos.\n\n### Simples\nS√≥ temos uma vari√°vel independente:\n$$Y = \\beta_0+\\beta_1X$$\n### M√∫ltipla\nTemos mais de 1 vari√°vel independentes para explicar Y\n$$Y = \\beta_0+\\beta_1X_1+\\beta_2X_2+...+\\beta_nX_n$$\n### Polinomial\nFormada por uma equa√ß√£o polinomial \n$$Y = \\beta_0+\\beta_1X+\\beta_2X^2+...+\\beta_nX^n$$\n## Hip√≥teses consideradas\n- **Vari√°veis Explicativas**:\n\t- **Linearidade**: a vari√°vel resposta y deve estar linearmente correlacionada com as vari√°veis explicativas \"x\"\n\t- **Falta de multicolinearidade**: A multicolinearidade deixa os coeficientes inst√°veis, modelo n√£o consegue atribuir bons valores para coeficientes de vari√°veis altamente correlacionadas\n\n- **Erros**:\n\t* **Normalidade Multivariada**: os erros devem ter uma distribui√ß√£o normal\n\t* **Independentes e identicamente distribu√≠dos (iid)**: depois de treinar o modelo, os erros do modelo devem ser vari√°veis aleat√≥rias independentes (n√£o ter interse√ß√£o) e devem ser identicamente distribu√≠das (ter a mesma fun√ß√£o de distribui√ß√£o acumulada). Por defini√ß√£o, uma vari√°vel aleat√≥ria √© uma vari√°vel \"iid\" \n\t* **Homocedasticidade**: Os erros devem ter uma vari√¢ncia constante, ou seja, n√£o podem ter um padr√£o em rela√ß√£o ao eixo x\n![[Pasted image 20230717220328.png | center]]\n### Principais causas de heterocedasticidade nos res√≠duos\n- Natureza das vari√°veis: alguns relacionamentos apresentam tend√™ncia √† heterocedasticidade\n- Outliers: um valor extremo na amostra pode inflacionar a variabilidade me um determinado ponto do ajuste\n- Falhas na especifica√ß√£o do modelo: omiss√£o de vari√°veis importantes, explicativas\n- Transforma√ß√£o dos dados: utiliza√ß√£o de transforma√ß√µes (como propor√ß√µes, log, etc) pode reduzir a heterocedasticidade\n- Em resumo, os erros (res√≠duos) n√£o devem ser correlacionadas, ter a m√©dia zero, vari√¢ncia constante e ter distribui√ß√£o normal\n\nObs: para verificar se uma vari√°vel possui distribui√ß√£o normal em uma amostra, podemos fazer o teste de **Shapiro Wilk**\n\n#todo \ncompletar ap√≥s ver statquest\n\n#regress√£o","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Regress%C3%A3o-Logistica":{"title":"Regress√£o Logistica","content":"A regress√£o log√≠stica √© uma t√©cnica de [[Classifica√ß√£o]] que nos ajuda a estimar uma curva para predizer a probabilidade (entre 0 e 1) de features discretas utilizando vari√°veis cont√≠nuas e/ou discretas, por exemplo se um cliente est√° insatisfeito ou satisfeito.\n\nO eixo y na regress√£o log√≠stica representa a probabilidade de uma observa√ß√£o pertencer a alguma classe do problema, e a curva de ajuste do modelo(roxo) nos d√° a probabilidade predita da pessoa pertencer a uma determinada classifica√ß√£o.\n\nOs par√¢metros s√£o estimados **maximizando a fun√ß√£o de log verossimilhan√ßa** do modelo a partir dos dados de treino. Uma vez que temos os par√¢metros definidos determinamos se uma observa√ß√£o faz parte de determinada classe realizando com o auxilio de um corte no valor da probabilidade (geralmente 0.5).\n![[Pasted image 20230714175014.png]]\n\n==Existe a possibilidade de ajustar o ponto de corte de probabilidade para melhor adequar a predi√ß√£o ao problema em quest√£o, √© um m√©todo muito utilizado quando utilizamos a [[ROC-AUC]] como m√©trica de avalia√ß√£o==\n\nNo exemplo abaixo, temos um modelo que infere se uma pessoa gosta do filme Troll 2, com a linha no ponto de corte de 50% de probabilidade.\n![[Pasted image 20230715175805.png]]\n*Normalmente √© utilizado a log verossimilhan√ßa para evitarmos problemas de erro computacional (Underflow), para em vez de multiplicarmos n√∫meros muito pequenos, somamos*\n\nSimilar √† [[Regress√£o Linear]] tamb√©m √© poss√≠vel avaliar o desempenho da predi√ß√£o com um **\"pseudo\" R¬≤** (McFadden's R¬≤) e calculando o **p-valor**, al√©m das m√©tricas usuais para classifica√ß√£o\n\n### Vantagens\n- Implementa√ß√£o simples\n- Score de probabilidade para as observa√ß√µes (pode ser utilizado no aux√≠lio do problema)\n- F√°cil interpretabilidade de como a sa√≠da do modela foi calculada\n- N√£o √© necess√°rio realizar *feature scaling*\n- N√£o √© necess√°rio realizar tunning de hiperpar√¢metros\n\n### Desvantagem\n- Baixo desempenho com dados n√£o lineares\n- Baixo desempenho com vari√°veis de baixo poder preditivo (pouca signific√¢ncia) \n- Algoritmo n√£o t√£o poderoso, normalmente superado por t√©cnicas mais recentes e robustas\n* A regress√£o log√≠stica sempre assume podemos atribuir uma curva em \"forma de S\" para predizer os dados, quando temos correla√ß√£o com a resposta que oscila durante a distribui√ß√£o das vari√°veis descritivas a condi√ß√£o para uso de regress√£o log√≠stica n√£o √© satisfeita:\n\t![[Pasted image 20230715193458.png]]\n\tPara problemas que os dados tem rela√ß√£o mais complexas (n√£o linearidade), podemos seguir com as t√©cnicas de [[SVM]], [[√Årvores de decis√£o - Classifica√ß√£o]] ou [[Rede Neural]] \n* Sens√≠vel a outlier nos dados de treinamento, principalmente na determina√ß√£o dos coeficientes\n\n#todo \n- [ ] entender como funciona a generaliza√ß√£o one-vs-rest\n\n#classifica√ß√£o","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Regulariza%C3%A7%C3%A3o":{"title":"Regulariza√ß√£o","content":"T√©cnicas utilizadas para evitar *overfitting* e ajudar na sele√ß√£o de vari√°veis de **Modelos Lineares Generalizados (GLM)**\n\n## Lasso (L1)\nO lasso adiciona uma **penalidade igual ao valor absoluto da magnitude dos coeficientes multiplicados por um lambda**\n$$L1 =\\sum^{n}_{i=1}(y_i - \\sum^{p}_{j=1}X_{ij}\\beta_j)^2 + \\lambda\\sum^{p}_{j=1}|B_j|$$ ou simplificando os termos:\n$$L1 = SSR - \\lambda*|\\text{slope}|$$\n![[Pasted image 20230718215505.png | center]] \n**Obs:**\n- Se **lambda = 0**, temos a fun√ß√£o de custo padr√£o\n- Se **lambda tende a 0**, temos uma aproxima√ß√£o do modelo sem regularizador (pode n√£o tratar o overfitting)\n- Se **lambda tende a infinito**, temos uma aproxima√ß√£o de um modelo que despreza qualquer efeito das features, tende ao *underfitting* pois os **coeficientes tender√£o a zero**\n\n- Pelo fato de usar o m√≥dulo no termo de penalidade, e n√£o elevar ao quadrado, **pode zerar os coeficientes** de vari√°veis pouco importantes e por conta disso **pode ser utilizado para sele√ß√£o de vari√°veis**.\n- O lasso adiciona um penalidade aos coeficientes que o modelo enfatiza demais, isso reduz o grau de *overfitting* do modelo.\n- Lasso tende a se sair bem quando h√° poucas features significativas e a magnitude das demais features for pr√≥xima de zero.\n- \u003cmark style=\"background: #FF5582A6;\"\u003eLasso n√£o lida bem com multicolinearidade\u003c/mark\u003e, pois pode eliminar de forma aleat√≥ria vari√°veis correlacionadas, podendo eliminar alguma que seja relevante para o modelo.\n\n## Ridge (L2)\nAdiciona uma **penalidade igual ao quadrado da magnitude dos coeficientes multiplicado por um lambda.**\nComo no lasso, adiciona uma penalidade aos coeficientes que o modelo enfatiza demais, por√©m, por elevar ao quadrado **n√£o tem a capacidade de zerar coeficientes e auxiliar no feature selection**\n\n$$L2 =\\sum^{n}_{i=1}(y_i - \\sum^{p}_{j=1}X_{ij}\\beta_j)^2 + \\lambda\\sum^{p}_{j=1}B^2_j$$\nou simplificando os termos:\n$$L2 = SSR - \\lambda*\\text{slope}^2$$\n![[Pasted image 20230718215644.png | center]]\n- Interessante para ser usada quando h√° multicolinearidade e n√£o se pode descartar nenhuma vari√°vel\n- Quando duas features s√£o correlacionadas e seus coeficientes est√£o muito desproporcionais, a Ridge faz com que as features correlacionadas tenham coeficientes parecidos.\n- Funciona bem se h√° varias features minimamente importantes.\n- Por n√£o eliminar features n√£o importantes, pode ser ruim ao utilizar em bases com muitas features.\n![[Pasted image 20230718214432.png | center]]\n\n## Elastic Net\nElastic Net combina as caracter√≠sticas da Lasso e Ridge. **Ela reduz o impacto de diferentes features ao mesmo tempo que n√£o elimina todas as features.**\n\n$$\\text{Elastic Net} =\\sum^{n}_{i=1}(y_i - \\sum^{p}_{j=1}X_{ij}\\beta_j)^2 + \\lambda_1\\sum^{p}_{j=1}|B_j| + \\lambda_2\\sum^{p}_{j=1}B^2_j$$\nComo funciona sendo a combina√ß√£o de L1 e L2, √© necess√°rio o ajuste de 2 hiperpar√¢metros, por√©m oferece um melhor equil√≠brio geral no requisito de regularizador.","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Root-Mean-Squared-Error-RMSE":{"title":"Root Mean Squared Error (RMSE)","content":"Representa a raiz quadrada da m√©dia dos erros (res√≠duos) elevado ao quadrado (raiz do [[Mean Squared Error (MSE)|MSE]]), **penaliza mais os erros com maior diferen√ßa**, dando menos import√¢ncia para os erros pequeno.\n$$RMSE = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}(y - \\hat{y})^2}$$\n### Vantagens\n- Fun√ß√£o deriv√°vel, pode ser utilizada como fun√ß√£o de custo\n- M√©trica de f√°cil interpreta√ß√£o, medida sai na mesma escala original dos dados de interesse\n### Desvantagens\n- Muito sens√≠vel a outliers\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/SVM":{"title":"SVM","content":"Support Vector Machine tem o objetivo de encontrar a **fronteira de decis√£o** que consiga separar o conjunto de dados em classes. **O SVM busca a linha ou hiperplano que melhor separa os dados**, maximizando a dist√¢ncia entre os pontos e a fronteira.\n\nPara encontrar esse hiperplano o SVM usa um processo de minimiza√ß√£o para encontrar os pontos que servir√£o de suporte para criar o vetor delimitante de fronteira, tais pontos s√£o encontrados de forma a maximizar a dist√¢ncia entre eles e a fronteira.\n\nO SVM em sua formula√ß√£o original apenas ser√° capaz de modelar problemas de classifica√ß√£o bin√°ria, por√©m t√©cnicas podem ser aplicadas para fazer expans√£o para problemas multiclasses, al√©m de problemas regressivos. \u003cmark style=\"background: #ADCCFFA6;\"\u003eEm sua forma original, √© um classificador linear, por√©m pode ser utilizados em problemas n√£o lineares utilizando o \"Kernel Trick\"\u003c/mark\u003e.\n\n## Soft Margin\n\nQualquer varia√ß√£o na posi√ß√£o dos pontos pr√≥ximos √† fronteira pode influenciar de maneira forte a posi√ß√£o do hiperplano. Dessa forma, o **soft margin** tem como objetivo permitir que o SVM cometa uma certa quantidade de erros e mantenha a margem o mais larga poss√≠vel, para que outros pontos ainda possam ser classificados corretamente **(Pode ser interpretado como um trade-off entre vi√©s e vari√¢ncia)**.\n- Ajuda a reduzir o problema de *overfitting*, uma vez que com uma margem mais larga √© poss√≠vel generalizar melhor dados n√£o vistos.\n- √â feito utilizando o hiperpar√¢metro \"C\": decide o trade-off entre maximizar a margem e minimizar os erros. Quando \"C\" √© pequeno, os erros de classifica√ß√£o recebem menos import√¢ncia e o foco maior √© em maximizar a margem, todavia quando \"C\" √© grande, o foco √© mais em evitar erros de classifica√ß√£o ao custo de manter a margem mais estreita\n\n## Kernel Trick\n\nQuando os dados n√£o s√£o linearmente separ√°veis a solu√ß√£o √© aumentar a dimensionalidade, de forma que em uma nova proje√ß√£o os dados sejam linearmente separ√°veis. O aumento de dimensionalidade √© feito utilizando uma fun√ß√£o **(kernel)**, a qual mapeia os dados em outro espa√ßo.\n\nO \u003cmark style=\"background: #ADCCFFA6;\"\u003eKernel Trick\u003c/mark\u003e se refere ao fato do SVM, a partir dos kernels, ser capaz de calcular a rela√ß√£o entre os dados em dimensionalidade aumentada sem que de fato os dados sejam transformados para uma maior dimens√£o. Fator que torna poss√≠vel utilizar o Kernel RBF que funciona com dimensionalidade infinita e que as rela√ß√µes sejam calculadas.\n![[Pasted image 20230716214419.png | center]]\n- Os **Kernels** mais utilizados s√£o:\n\t- RBF (Radial Basis Function), sendo a principal a Gaussiana\n\t- Polinomial\n\t- Sigmoide\n![[Pasted image 20230716214548.png | center]]\n![[Pasted image 20230716214601.png | center]]\n\n### Vantagens\n- Boa performance em problemas com alta dimensionalidade (muitas features)\n- √ìtimo algoritmo quando as classes s√£o separ√°veis\n- Pouco sens√≠vel a outliers\n- Mais adequado para classifica√ß√µes bin√°rias\n\n### Desvantagem\n- Custo computacional elevado para datasets muito grandes (requer bastante processamento para alterar a dimensionalidade)\n- Todas as features devem ser num√©ricas\n- N√£o performa bem quando as classes est√£o muito sobrepostas\n- Requer cuidado para selecionar de forma apropriada os hiperpar√¢metros (C, Kernel, etc)\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Specificity":{"title":"Specificity","content":"Representa o oposto do Recall, demonstra a taxa de acerto na classe negativa obtida pelo classificador.\nResponde a pergunta: De todos os casos negativos, quantos foram classificados corretamente?\n$$ Especificidade = \\frac{TN}{TN+FP} $$\n$$ FPR = 1 - especificidade $$\n**Desvantagens**\n- N√£o mede o desempenho completo do modelo\n- Pode ser ilus√≥rio em problemas com **desbalanceamento de classes**\n\n**Vantagens**\n- Medida direta da capacidade do classificador **evitar falsos positivos**\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/T%C3%A9cnicas-de-modelagem-Classifica%C3%A7%C3%A3o":{"title":"T√©cnicas de modelagem - Classifica√ß√£o","content":"\n[[√Årvores de decis√£o - Classifica√ß√£o]]\n\n[[Random Forest - Classifica√ß√£o]]\n\n[[XGBClassifier]]\n\n[[Naive Bayes]]\n\n[[Regress√£o Logistica]]\n\n[[SVM]]\n\n[[KNN]]\n\n[[Rede Neural]]\n\n\n#classifica√ß√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/T%C3%A9cnicas-de-modelagem-Clustering":{"title":"T√©cnicas de modelagem - Clustering","content":"\n## Agrupamento N√£o Hier√°rquico\nT√©cnica de aprendizado n√£o supervisionado em que o objetivo √© encontrar nos dados uma estrutura de agrupamento natural, agrupando indiv√≠duos com base na similaridade ou dist√¢ncias (dissimilaridades).\n- **Parti√ß√£o r√≠gida**: Todos os pontos do dataset possuem um cluster, sendo que nenhum cluster fica vazio e n√£o existe intersec√ß√£o entre eles.\n- **Objetivo:** \u003cmark style=\"background: #ADCCFFA6;\"\u003eMinimizar dist√¢ncia intra-cluster\u003c/mark\u003e (pontos dentro de um mesmo cluster est√£o pertos um dos outros) e \u003cmark style=\"background: #ADCCFFA6;\"\u003emaximizar a dist√¢ncia inter-cluster\u003c/mark\u003e (pontos em diferentes cluster est√£o distantes)\n\n#### Passo a passo geral:\n1. Escolher o n√∫mero **k** de clusters\n\t1. Pode ser utilizado m√©todos como cotovelo, silhueta, etc\n2. Selecionar os centroides iniciais (n√£o necessariamente pontos presentes no dataset)\n\t\tA inicializa√ß√£o pode gerar clusters diferentes (\u003cmark style=\"background: #FF5582A6;\"\u003eproblema de sensibilidade da inicializa√ß√£o\u003c/mark\u003e). Maneira de lidar com esse problema s√£o:\n\t\t**Repeti√ß√£o:** Repetir o algoritmo e a inicializa√ß√£o diversas vezes e escolher a clusteriza√ß√£o que tiver menor dist√¢ncia intra-cluster e maior dist√¢ncia inter-cluster\n\t\t**K++ (K-means ++, K-medians ++, etc):** T√©cnica inteligente para inicializa√ß√£o dos centroides em que o 1¬∫ √© escolhido de forma aleat√≥ria a partir dos dados e os demais centroides s√£o escolhidos a partir dos pontos restantes com probabilidade proporcional √† dist√¢ncia ao quadrado do centroide mais pr√≥ximo\n3. Atribuir para cada ponto o cluster do centroide mais pr√≥ximo\n4. Avaliar e recalcular a nova posi√ß√£o dos centroides de cada cluster\n5. Repetir os passos 3 e 4 at√© atingir a converg√™ncia (elementos n√£o trocam mais de grupos ap√≥s recalculo de centroides)\n\n##### [[K-Means]]\n\n##### [[K-Medians]]\n\n##### [[K-Modes]]\n\n##### [[K-Medoids]]\n\n##### [[K-Prototypes]]\n\n#### Defini√ß√£o do n√∫mero K de clusters\n\n##### M√©todo do cotovelo\nConsiste em tra√ßar uma curva do WCSS (Within-Cluster Sum of Square ou soma do quadrado das dist√¢ncias intra-cluster) e o n√∫mero de clusters. O valor de k a ser escolhido ser√° aquele em que a varia√ß√£o do WCSS torna-se menos discrepante:\n![[Pasted image 20230721235857.png|center]]\n**Passo a passo:**\n1. Realizar a clusteriza√ß√£o para diferentes valores de K (ex: 1 at√© 10)\n2. Para cada K, calcular a soma total dos quadrados das dist√¢ncias intra-cluster (inercia)\n3. Plotar a curva de WCSS contra K\n4. O local do **cotovelo** no gr√°fico indicar√° o n√∫mero apropriado de clusters\n![[Pasted image 20230722000449.png|center]]\n\n##### M√©todo da Silhueta\nConsiste em plotar o valor m√©dio do coeficiente de silhueta para diferentes valores de K. O n√∫mero √≥timo de clusters ser√° aquele que tiver o valor m√°ximo da silhueta:\n![[Pasted image 20230722000349.png|center]]\nO coeficiente de silhueta mede a qualidade da clusteriza√ß√£o, ou seja, ele determina qu√£o bem cada ponto est√° dentro do seu cluster. Um valor alto indica uma boa clusteriza√ß√£o.\n![[Pasted image 20230722000506.png|center]]\n\nO coeficiente nos diz se os pontos est√£o corretamente atribu√≠dos aos seus clusters:\n**S(i) pr√≥ximo de 0:** o ponto encontra-se entre dois clusters\n**S(i) pr√≥ximo de -1:** o ponto teria sido melhor classificado em outro cluster\n**S(i) pr√≥ximo de 1:** o ponto foi agrupado corretamente\n\n## Agrupamento por Densidade\n#### [[DBSCAN]]\nO algoritmo de clusteriza√ß√£o n√£o hier√°rquico que considera os clusters como regi√µes de maior/menor densidade, muito √∫til para distribui√ß√µes de dados que n√£o seguem um padr√£o esf√©rico/convexo.\n\n## Agrupamento Hier√°rquico\nT√©cnica de clusteriza√ß√£o que baseia-se no tamanho e dist√¢ncia (medida de dissimilaridade/similaridade) dos dados em um conjunto. \n\nPara realizar a clusteriza√ß√£o √© necess√°rio definir a m√©trica de dist√¢ncia a ser utilizada (euclidiana, manhattan, etc) e um crit√©rio de liga√ß√£o. Essa t√©cnica produz de 1 a N clusters, sendo N o n√∫mero de observa√ß√µes presentes no dataset, ocorrendo por processo de **aglomera√ß√£o (bottom up)** ou por **divis√£o (top down)**.\n\n**Vantagens:** F√°cil implementa√ß√£o, produz um dendograma (facilita no entendimento de como a clusteriza√ß√£o foi realizada), t√©cnica menos sens√≠vel a outliers\n**Desvantagens:** As vezes pode ser dif√≠cil identificar um n√∫mero ideal de clusters, mesmo com a ajuda do dendograma. Geralmente requer um maior tempo para o algoritmo terminar de rodar.\n\n##### [[Aglomera√ß√£o (Bottom Up)]]\n\n##### [[Divis√£o (Top Down)]]\n\n![[Pasted image 20230722154126.png|center]]\n\n### Crit√©rios de liga√ß√£o\n![[Pasted image 20230722154335.png|center]]\n\n##### Single Linkage\nT√©cnica de **vizinho mais pr√≥ximo**, √© a menor dist√¢ncia entre dois pontos dentro de dois clusters. As vezes pode produzir clusters onde as observa√ß√µes em diferentes clusters est√£o mais pr√≥ximas do que as observa√ß√µes dentro de seu pr√≥prio cluster.\n\nEsses clusters podem aparecer de forma espalha e no \u003cmark style=\"background: #FF5582A6;\"\u003egeral s√£o sens√≠veis a outliers\u003c/mark\u003e.\n\n##### Complete Linkage\nT√©cnica de **vizinho mais distante**, √© a maior dist√¢ncia entre dois pontos em dois clusters. Geralmente produz clusters mais compactos do que o m√©todo de **single linkage**, mas esses clusters podem acabar ficando muito pr√≥ximos.\n\nUma das m√©tricas mais populares e s√£o \u003cmark style=\"background: #FFB86CA6;\"\u003emenos sens√≠veis a outliers\u003c/mark\u003e.\n\n##### Average Linkage\nA dist√¢ncia entre cada par de pontos em cada cluster √© somada e dividida pelo n√∫mero de pares para ser obter uma dist√¢ncia m√©dia. \n\nT√£o popular quanto **complete linkage** por√©m \u003cmark style=\"background: #BBFABBA6;\"\u003emuito menos sens√≠vel a outliers\u003c/mark\u003e.\n\n![[Pasted image 20230722154935.png|center]]\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003eDependendo de como os dados est√£o distribuidos, o crit√©rio de liga√ß√£o escolhido pode alterar muito a agrupamento gerado.\u003c/mark\u003e\n\n## Agrupamento por Distribui√ß√£o Probabil√≠stica\n#### [[Gaussian Mixture Models (GMM)]]\nAlgoritmo de clusteriza√ß√£o que √© mais flex√≠vel no formato dos clusters e nos fornece uma medida probabil√≠stica de atribui√ß√£o a um determinado cluster\n\n\n\n#todo \nestudar inicializa√ß√£o K++\n\n#clustering ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/T%C3%A9cnicas-de-modelagem-Regress%C3%A3o":{"title":"T√©cnicas de modelagem - Regress√£o","content":"\n[[Regress√£o Linear]]\n\n[[√Årvores de decis√£o - Regress√£o]]\n\n\n#regress√£o ","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Todo":{"title":"Todo","content":"#todo\n- [x] Vi√©s e Vari√¢ncia  \n- [x] Boruta\n- [x] √Årvore de Decis√£o/Regress√£o  \n- [x] Ensemble Methods  \n- [x] Bagging  \n- [x] Random Forest  \n- [x] Boosting  \n- [x] Overfit e Underfit  \n- [x] Cross Validation \n- [x] Regulariza√ß√£o (L1 e L2)  \n- [x] M√©tricas de Avalia√ß√£o (Classifica√ß√£o, Regress√£o e Clustering)  \n\t- [x] Classifica√ß√£o\n\t- [x] Regress√£o\n\t- [x] Clustering\n- [x] Clustering  \n\n  \n- [x] Gradient Boosting  \n- [ ] XGBoost  \n\t- [x] XGBClassifier\n\t- [ ] XGBRegressor\n- [ ] Calibragem \n- [x] Regress√£o Log√≠stica  \n- [x] Regress√£o Linear  \n- [ ] Tunagem de Hiperparametros (Hyperopt, optuna, Grid Search, Random Search)  \n- [x] K-Means  \n- [x] Hier√°rquico  \n- [x] DBSCAN  \n- [ ] Tipos de aprendizado - supervisionado/nao supervisionado/semi supervisionado\n\n- [x] Hard Clustering / Soft Clustering\n- [ ] Complexidade Computacional\n- [ ] Rede Neurais\n\t- [x] basico\n\t- [ ] convolucao +\n  \n- [x] Xtrees  \n- [ ] Light GBM  \n- [ ] CatBoost  \n- [ ] Data Augmentation  \n- [x] Naive Bayes  \n- [ ] KNN  \n- [x] SVM  \n- [ ] PCA  \n \n- [ ] AdaBoost  \n- [ ] GLM  \n- [x] K-Medoides / K-Prototypes  \n- [x] GMM\n\n- Linear Regression\n- [ ] [A BEGINNERS GUIDE TO REGRESSION TECHNIQUES](https://analyticsindiamag.com/a-beginners-guide-to-regression-techniques/)\n- [ ] [Linear Regression Algorithm | Linear Regression in Python | Machine Learning Algorithm | Edureka - YouTube](https://www.youtube.com/watch?v=E5RjzSK0fvY)\n- [ ] [In Depth: Linear Regression | Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html)\n- [ ] [Linear Models - YouTube](https://www.youtube.com/playlist?list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU)\n- [ ] [Statistics 101: Linear Regression, The Very Basics - YouTube](https://www.youtube.com/watch?v=ZkjP5RJLQF4\u0026list=PLIeGtxpvyG-LoKUpV0fSY8BGKIMIdmfCi\u0026index=1)\n- [ ] [How to Implement Linear Regression From Scratch in Python](https://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/)\n- [ ] [Linear Regression using Python - Towards Data Science](https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2)\n- [ ] [Mathematical explanation for Linear Regression working - GeeksforGeeks](https://www.geeksforgeeks.org/mathematical-explanation-for-linear-regression-working/)\n- [ ] [Gradient Descent in Linear Regression - GeeksforGeeks](https://www.geeksforgeeks.org/gradient-descent-in-linear-regression/)\n- [ ] [ML | Normal Equation in Linear Regression - GeeksforGeeks](https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/)\n- [ ] [Univariate Linear Regression in Python - GeeksforGeeks](https://www.geeksforgeeks.org/univariate-linear-regression-in-python/)\n- [ ] [How to do Linear Regression and Logistic Regression in Machine Learning?](https://mlfromscratch.com/machine-learning-introduction-8-linear-regression-and-logistic-regression/#/)\n- [ ] [Linear Regression (Python Implementation) - GeeksforGeeks](https://www.geeksforgeeks.org/linear-regression-python-implementation/)\n- [ ] [ML | Multiple Linear Regression using Python - GeeksforGeeks](https://www.geeksforgeeks.org/ml-multiple-linear-regression-using-python/)\n- [ ] [Python | Implementation of Polynomial Regression - GeeksforGeeks](https://www.geeksforgeeks.org/python-implementation-of-polynomial-regression/)\n- [ ] [Simple Linear Regression From Scratch in Numpy - Towards Data Science](https://towardsdatascience.com/simple-linear-regression-from-scratch-in-numpy-871335e14b7a)\n- [ ] [A Complete Tutorial on Ridge and Lasso Regression in Python](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n- [ ] [Python/linear_regression.py at master ¬∑ TheAlgorithms/Python](https://github.com/TheAlgorithms/Python/blob/master/machine_learning/linear_regression.py)\n- [ ] [Python | Linear Regression using sklearn - GeeksforGeeks](https://www.geeksforgeeks.org/python-linear-regression-using-sklearn/)\n- [ ] [ML | Locally weighted Linear Regression - GeeksforGeeks](https://www.geeksforgeeks.org/ml-locally-weighted-linear-regression/)\n- [ ] [Statistics PL15 - Multiple Regression - YouTube](https://www.youtube.com/playlist?list=PLIeGtxpvyG-IqjoU8IiF0Yu1WtxNq_4z-)\n- [ ] [Statistics PL18 - Nonlinear Regression - YouTube](https://www.youtube.com/playlist?list=PLIeGtxpvyG-KE0M1r5cjbC_7Q_dVlKVq4)\n- [ ] [Isotonic Regression is THE Coolest Machine-Learning Model You Might Not Have Heard Of](https://towardsdatascience.com/isotonic-regression-is-the-coolest-machine-learning-model-you-might-not-have-heard-of-3ce14afc6d1e)\n- Logistic Regression\n- [ ] [Logistic Regression - YouTube](https://www.youtube.com/playlist?list=PLblh5JKOoLUKxzEP5HA2d-Li7IJkHfXSe)\n- [ ] [TLM | Logistic Regression](https://www.thelearningmachine.ai/logistic)\n- [ ] [Logistic regression - Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression)\n- [ ] [Maximum likelihood and gradient descent demonstration ‚Äì Zlatan Kremonic](https://zlatankr.github.io/posts/2017/03/06/mle-gradient-descent)\n- [ ] [An Introduction to Logistic Regression - Towards Data Science](https://towardsdatascience.com/an-introduction-to-logistic-regression-8136ad65da2e)\n- [ ] [A Gentle Introduction to Logistic Regression With Maximum Likelihood Estimation](https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/)\n- [ ] [Logistic model - Maximum likelihood](https://www.statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood)\n- SVD\n- [ ] [Gilbert strang - SVD](https://www.youtube.com/watch?v=rYz83XPxiZo)\n- [ ] [You Don‚Äôt Know SVD (Singular Value Decomposition)](https://towardsdatascience.com/svd-8c2f72e264f)\n- [ ] [(114) A geometrical interpretation of the SVD - YouTube](https://www.youtube.com/watch?v=NsNNI_-JPUY)\n- [ ] [SVD playlist](https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv)\n- [ ] [Gilbert strang - Computing Eigenvalues and Singular Values](https://www.youtube.com/watch?v=d32WV1rKoVk)\n- [ ] [Gilbert strang - Singular Value Decomposition](https://www.youtube.com/watch?v=mBcLRGuAFUk)\n- [ ] [Computing the SVD](https://www.youtube.com/watch?v=cOUTpqlX-Xs\u0026t=22s)\n- [ ] [Lecture 47 ‚Äî Singular Value Decomposition | Stanford University](https://www.youtube.com/watch?v=P5mlg91as1c)\n- [ ] [How to Calculate the Singular-Value Decomposition (SVD) from Scratch with Python](https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/)\n- [ ] [What is an intuitive explanation of singular value decomposition (SVD)? - Quora](https://www.quora.com/What-is-an-intuitive-explanation-of-singular-value-decomposition-SVD)\n- [ ] [What is the meaning behind the singular value in Singular Value Decomposition? - Quora](https://www.quora.com/What-is-the-meaning-behind-the-singular-value-in-Singular-Value-Decomposition)\n- [ ] [What is the best way of introducing singular value decomposition (SVD) on a linear algebra course? Why is it so important? Are there any applications which have a real impact? - Quora](https://www.quora.com/What-is-the-best-way-of-introducing-singular-value-decomposition-SVD-on-a-linear-algebra-course-Why-is-it-so-important-Are-there-any-applications-which-have-a-real-impact)\n- [ ] [What's the difference between SVD and SVD++? - Quora](https://www.quora.com/Whats-the-difference-between-SVD-and-SVD++)\n- [ ] [What is the purpose of Singular Value Decomposition? - Quora](https://www.quora.com/What-is-the-purpose-of-Singular-Value-Decomposition)\n- Covariance\n- [ ] [Baffled by Covariance and Correlation??? Get the Math and the Application in Analytics for both the terms..](https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22)\n- [ ] [Covariance and Correlation Part 1: Covariance - YouTube](https://www.youtube.com/watch?v=qtaqvPAeEJY)\n- [ ] [The Covariance Matrix : Data Science Basics](https://www.youtube.com/watch?v=152tSYtiQbw)\n- [ ] [Statistics 101: The Covariance Matrix](https://www.youtube.com/watch?v=locZabK4Als\u0026t=1s)\n- PCA\n- [ ] [Implementing a Principal Component Analysis (PCA)‚Äì in Python, step by step](https://sebastianraschka.com/Articles/2014_pca_step_by_step.html#4-computing-eigenvectors-and-corresponding-eigenvalues)\n- [ ] [The Mathematics Behind Principal Component Analysis](https://towardsdatascience.com/the-mathematics-behind-principal-component-analysis-fff2d7f4b643)\n- [ ] [A tutorial on Principal Components Analysis](http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf)\n- [ ] [Principal Component Analysis - Youtube](https://www.youtube.com/playlist?list=PLBv09BD7ez_5_yapAg86Od6JeeypkS4YM)\n- [ ] [Dimensionality Reduction For Dummies ‚Äî Part 1: Intuition](https://towardsdatascience.com/https-medium-com-abdullatif-h-dimensionality-reduction-for-dummies-part-1-a8c9ec7b7e79)\n- [ ] [Data Analysis 6: Principal Component Analysis (PCA) - Computerphile](https://www.youtube.com/watch?v=TJdH6rPA-TI)\n- [ ] [Visual Explanation of Principal Component Analysis, Covariance, SVD](https://www.youtube.com/watch?v=5HNr_j6LmPc)\n- [ ] [luis serrano pca](https://www.youtube.com/watch?v=g-Hb26agBFg)\n- [ ] [StatQuest: Principal Component Analysis (PCA), Step-by-Step - YouTube](https://www.youtube.com/watch?v=FgakZw6K1QQ)\n- [ ] [StatQuest: PCA in Python - YouTube](https://www.youtube.com/watch?v=Lsue2gEM9D0)\n- [ ] [StatQuest: PCA - Practical Tips](https://www.youtube.com/watch?v=oRvgq966yZg\u0026list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\u0026index=24)\n- [ ] [Dimensionality reduction and PCA](https://www.youtube.com/playlist?list=PLBv09BD7ez_4InDh85LM_43Bsw0cFDHdN)\n- [ ] [Principal Component Analysis (PCA) and Singular Value Decomposition (SVD)](https://mlfromscratch.com/principal-component-analysis-pca-svd/#/)\n- [ ] [Visualizing Classifier Boundaries Using Kernel PCA](https://www.kaggle.com/jsultan/visualizing-classifier-boundaries-using-kernel-pca)\n- [ ] [Understanding Principal Component Analysis Once And For All](https://medium.com/bluekiri/understanding-principal-component-analysis-once-and-for-all-9f75e7b33635)\n- [ ] [How to Calculate Principal Component Analysis (PCA) from Scratch in Python](https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/)\n- [ ] [Implementing a Principal Component Analysis (PCA)](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html)\n- [ ] [What is an intuitive explanation for PCA? - Quora](https://www.quora.com/What-is-an-intuitive-explanation-for-PCA)\n- [ ] [What is an intuitive explanation of the relation between PCA and SVD? - Quora](https://www.quora.com/What-is-an-intuitive-explanation-of-the-relation-between-PCA-and-SVD)\n- [ ] [Why don't people use SVD in PCA rather than eigen value decomposition? - Quora](https://www.quora.com/Why-dont-people-use-SVD-in-PCA-rather-than-eigen-value-decomposition)\n- [ ] [(19) Statistics PL03 - Descriptive Statistics II - YouTube](https://www.youtube.com/playlist?list=PLIeGtxpvyG-JMH5fGDWhtniyET88Mexcw)\n- [ ] [Dimensionality Reduction and Principal Component Analysis (PCA) Explained](http://abhijitannaldas.com/ml/dimensionality-reduction-and-principal-component-analysis-pca-explained.html)\n- [ ] [In Depth: Principal Component Analysis](https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html)\n- LDA\n- [ ] [Linear Discriminant Analysis ‚Äì Bit by Bit](http://sebastianraschka.com/Articles/2014_python_lda.html)\n- [ ] [Linear Discriminant Analysis](http://www.saedsayad.com/lda.htm)\n- [ ] [Linear Discriminant Analysis](https://sebastianraschka.com/Articles/2014_python_lda.html)\n- [ ] [A Geometric Intuition for Linear Discriminant Analysis](https://omarshehata.github.io/lda-explorable/)\n- [ ] [Machine Learning with Python: Linear Discriminant Analysis in Python](https://www.python-course.eu/linear_discriminant_analysis.php)\n- [ ] [Using Linear Discriminant Analysis (LDA) for data Explore: Step by Step. | Blog](https://www.apsl.net/blog/2017/07/18/using-linear-discriminant-analysis-lda-data-explore-step-step/)\n- [ ] [Linear Discriminant Analysis (LDA) Numerical Example](https://people.revoledu.com/kardi/tutorial/LDA/Numerical%20Example.html)\n- [ ] [Classification ‚Äî Linear Discriminant Analysis](https://towardsdatascience.com/classification-part-2-linear-discriminant-analysis-ea60c45b9ee5)\n- [ ] [Linear Discriminant Analysis](https://medium.com/@srishtisawla/linear-discriminant-analysis-d38decf48105)\n- [ ] [Feature Reduction using ‚Äî PCA \u0026 LDA](https://medium.com/@adityaraj_64455/feature-reduction-using-pca-lda-338b9fe64f59)\n- [ ] [Machine Learning: In-Depth LDA (Linear Discriminant Analysis) Python Example On The Iris Dataset. - YouTube](https://www.youtube.com/watch?v=S8YSqrzqERI)\n- [ ] [How to implement Linear Discriminant Analysis python | +91-7307399944 for query - YouTube](https://www.youtube.com/watch?v=qiq4Y0ZkAwU)\n- [ ] [Linear Discriminant Analysis In Python - Towards Data Science](https://towardsdatascience.com/linear-discriminant-analysis-in-python-76b8b17817c2)\n- [ ] [Implementing LDA in Python with Scikit-Learn](https://stackabuse.com/implementing-lda-in-python-with-scikit-learn/)\n- [ ] [Machine Learning with Python: Linear Discriminant Analysis in Python](https://www.python-course.eu/linear_discriminant_analysis.php)\n- [ ] [(Linear Discriminant Analysis) using Python - Journey 2 Artificial Intelligence - Medium](https://medium.com/journey-2-artificial-intelligence/lda-linear-discriminant-analysis-using-python-2155cf5b6398)\n- SVM\n- [ ] [Please explain Support Vector Machines (SVM) like I am a 5 year old. : MachineLearning](https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/)\n- [ ] [Statquest - Support Vector Machines, Clearly Explained!!!](https://www.youtube.com/watch?v=efR1C6CvhmE)\n- [ ] [Coursera Support vector machine](https://www.coursera.org/learn/machine-learning/lecture/sKQoJ/using-an-svm)\n- [ ] [Intuition for the Support Vector Machine (primal form)](https://www.youtube.com/watch?v=ptwn9wg_s48)\n- [ ] [Chapter 2 : SVM (Support Vector Machine) Theory - Machine Learning 101 - Medium](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72)\n- [ ] [Understanding Support Vector Machines algorithm (along with code)]([https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/?)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/?))\n- [ ] [Support Vector Machines in Scikit-learn (article) - DataCamp](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python)\n- [ ] [Implementing SVM and Kernel SVM with Python Scikit-Learn](https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/)\n- [ ] [Support Vector Machines for Machine Learning](https://machinelearningmastery.com/support-vector-machines-for-machine-learning/)\n- [ ] [cs229-notes3.dvi](http://cs229.stanford.edu/notes/cs229-notes3.pdf)\n- [ ] [Classifying data using Support Vector Machines(SVMs) in Python - GeeksforGeeks](https://www.geeksforgeeks.org/classifying-data-using-support-vector-machinessvms-in-python/)\n- [ ] [Support Vector Machine (SVM) - Fun and Easy Machine Learning](https://www.youtube.com/watch?v=Y6RRHw9uN9o)\n- [ ] https://www.youtube.com/watch?v=iEQ0e-WLgkQ\n- [ ] [In-Depth: Support Vector Machines | Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n- [ ] [Sentdex - Support Vector Machine Intro and Application - YouTube](https://www.youtube.com/watch?v=mA5nwGoRAOo\u0026t=1s)\n- [ ] [Support Vector Machine ‚Äî Introduction to Machine Learning Algorithms](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)\n- [ ] [Classification From Scratch, Part 7 of 8: SVM - DZone Big Data](https://dzone.com/articles/classification-from-scratch-svm-78)\n- [ ] [Chapter 3.1 : SVM from Scratch in Python. - Deep Math Machine learning.ai - Medium](https://medium.com/deep-math-machine-learning-ai/chapter-3-1-svm-from-scratch-in-python-86f93f853dc)\n- [ ] [adityajn105/SVM-From-Scratch: An Implementation of SVM - Support Vector Machines using Linear Kernel](https://github.com/adityajn105/SVM-From-Scratch)\n- [ ] [SVM-From-Scratch/Support Vector Machine From Scratch.ipynb at master ¬∑ adityajn105/SVM-From-Scratch](https://github.com/adityajn105/SVM-From-Scratch/blob/master/Support%20Vector%20Machine%20From%20Scratch.ipynb)\n- Decision Trees\n- [ ] [StatQuest: Decision Trees](https://www.youtube.com/watch?v=7VeUPuFGJHk\u0026list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\u0026index=34)\n- [ ] [Decision Tree Algorithm | Decision Tree in Python | Machine Learning Algorithms | Edureka](https://www.youtube.com/watch?v=qDcl-FRnwSU)\n- [ ] [Classification And Regression Trees for Machine Learning](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/)\n- [ ] [How To Implement The Decision Tree Algorithm From Scratch In Python](https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/)\n- [ ] [Clas - 5 Data Science Training | Decision Tree Classifier Explained | Edureka](https://www.youtube.com/watch?v=v3tsrs1wpi4)\n- [ ] [Understanding Decision Trees for Classification in Python](https://www.kdnuggets.com/2019/08/understanding-decision-trees-classification-python.html)\n- [ ] [A Simple Explanation of Information Gain and Entropy](https://victorzhou.com/blog/information-gain/)\n- [ ] [A Simple Explanation of Gini Impurity](https://victorzhou.com/blog/gini-impurity/)\n- [ ] [In-Depth: Decision Trees and Random Forests](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html)\n- [ ] [The Simple Math behind 3 Decision Tree Splitting criterions](https://towardsdatascience.com/the-simple-math-behind-3-decision-tree-splitting-criterions-85d4de2a75fe)\n    Entropy sum\n\n    - [ ] [Decision tree Learning example | ID3 |](https://www.youtube.com/watch?v=UzpwBb3qAbs)\n    - [ ] [(137) Decision Tree Classification Algorithm ‚Äì Solved Numerical Question 2 in Hindi - YouTube](https://www.youtube.com/watch?v=JsbaJp6VaaU)\n    - [ ] [ID3](https://www.cise.ufl.edu/~ddd/cap6635/Fall-97/Short-papers/2.htm)\n    - [ ] [Decision Trees for Classification: A Machine Learning Algorithm | Xoriant Blog](https://www.xoriant.com/blog/product-engineering/decision-trees-machine-learning-algorithm.html)\n    \n    GINI sum\n    \n    - [ ] [(137) Decision Tree Solved Example Using CART Model in Hindi | Data mining | Machine Learning | AI - YouTube](https://www.youtube.com/watch?v=9K0M2KCyNYo)\n    - [ ] [Gini Index For Decision Trees](https://blog.quantinsti.com/gini-index/)\n- Feature Selection\n    \n    - [ ] [How do I select features for Machine Learning? - YouTube](https://www.youtube.com/watch?v=YaKMeAlHgqQ)\n    - [ ] [Feature Selection in Machine Learning using Python - YouTube](https://www.youtube.com/playlist?list=PLc2rvfiptPSQYzmDIFuq2PqN2n28ZjxDH)\n    - [ ] [Hands-on with Feature Selection Techniques: An Introduction](https://heartbeat.fritz.ai/hands-on-with-feature-selection-techniques-an-introduction-1d8dc6d86c16)\n    - [ ] [How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)\n    - [ ] [Feature Selection For Machine Learning in Python](https://machinelearningmastery.com/feature-selection-machine-learning-python/)\n    - [ ] [FEATURE SELECTION Techniques for Classification Models](https://medium.com/@shiwanigupta3005/feature-selection-techniques-for-classification-models-832ebfc6564d)\n    - [ ] [1.13. Feature selection ‚Äî scikit-learn 0.22.2 documentation](https://scikit-learn.org/stable/modules/feature_selection.html)\n    - [ ] [anujdutt9/Feature-Selection-for-Machine-Learning: Methods with examples for Feature Selection during Pre-processing in Machine Learning.](https://github.com/anujdutt9/Feature-Selection-for-Machine-Learning)\n- Evaluation metrics\n    \n    - [ ] [MLM- A Gentle Introduction to Model Selection for Machine Learning](https://machinelearningmastery.com/a-gentle-introduction-to-model-selection-for-machine-learning/)\n    - [ ] [Data Preprocessing : Concepts](https://towardsdatascience.com/data-preprocessing-concepts-fa946d11c825)\n    - [ ] [About Feature Scaling and Normalization](https://sebastianraschka.com/Articles/2014_about_feature_scaling.html)\n    - [ ] [Measuring Search Effectiveness](https://www.creighton.edu/fileadmin/user/HSL/docs/ref/Searching_-_Recall_Precision.pdf)\n    - [ ] [Classifier evaluation with imbalanced datasets](https://classeval.wordpress.com/introduction/basic-evaluation-measures/)\n    - [ ] [ROC](https://stats.stackexchange.com/questions/370918/must-roc-curve-be-concave)\n    - [ ] [ROC curve 101](https://stats.stackexchange.com/questions/66837/why-does-my-roc-curve-look-like-this-is-it-correct/66844#66844)\n    - [ ] [A Pirate's Guide to Accuracy, Precision, Recall, and Other Scores](https://blog.floydhub.com/a-pirates-guide-to-accuracy-precision-recall-and-other-scores/)\n    - [ ] [Multi-Class Metrics Made Simple, Part II: the F1-score](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1)\n    - [ ] [Feature Scaling with scikit-learn](http://benalexkeen.com/feature-scaling-with-scikit-learn/)\n- Bagging and boosting\n    \n    - [ ] [Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)\n    - [ ] [UDACITY: Bootstrap aggregating bagging](https://www.youtube.com/watch?v=2Mg8QD0F1dQ)\n    - [ ] [Bagging, boosting and stacking in machine learning](https://stats.stackexchange.com/questions/18891/bagging-boosting-and-stacking-in-machine-learning)\n    - [ ] [A Gentle Introduction to the Bootstrap Method](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/)\n    - [ ] [Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)\n    - [ ] [Basics of Ensemble Learning Explained in Simple English](https://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning)\n    - [ ] [A Comprehensive Guide to Ensemble Learning (with Python codes)](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/)\n    - [ ] [StatQuest: Random Forests Part 1 - Building, Using and Evaluating](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ\u0026t=2s)\n    - [ ] [Random Forests for Complete Beginners](https://victorzhou.com/blog/intro-to-random-forests/)\n    - [ ] [Random Forest(Bootstrap Aggregation) Easily Explained](https://www.youtube.com/watch?v=iajaNLLCOF4)\n    - [ ] [Selecting good features ‚Äì Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n    - [ ] [Effect of Irrelevant Features](https://bookdown.org/max/FES/feature-selection-simulation.html)\n    - [ ] [TheAlgorithms-random_forest_classification](https://github.com/TheAlgorithms/Python/tree/master/machine_learning/random_forest_classification)\n    - [ ] [UDACITY: Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)\n    - [ ] [AdaBoost, Clearly Explained](https://www.youtube.com/watch?v=LsK-xG1cLYA)\n    - [ ] [Boosting and AdaBoost for Machine Learning](https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/)\n    - [ ] [A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)\n    - [ ] [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n    - [ ] [Gradient Boost Part 1: Regression Main Ideas](https://www.youtube.com/watch?v=3CC4N4z3GJc)\n    - [ ] [Gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting)\n    - [ ] [Gradient Boosting for Linear Regression - why does it not work?](https://stats.stackexchange.com/questions/186966/gradient-boosting-for-linear-regression-why-does-it-not-work)\n    - [ ] [Boosting Machine Learning Tutorial | Adaptive Boosting, Gradient Boosting, XGBoost | Edureka](https://www.youtube.com/watch?v=kho6oANGu_A)\n    - [ ] [Xgboost (Boosting) Intuition Easily Explained](https://www.youtube.com/watch?v=YABWwCLPfZs)\n    - [ ] [An End-to-End Guide to Understand the Math behind XGBoost](https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/)\n    - [ ] [How to Develop Your First XGBoost Model in Python with scikit-learn](https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/)\n    - [ ] [Why is the boosting algorithm robust to overfitting?](https://www.quora.com/Why-is-the-boosting-algorithm-robust-to-overfitting)\n    - [ ] [30 Questions to test a data scientist on Tree Based Models](https://www.analyticsvidhya.com/blog/2017/09/30-questions-test-tree-based-models/)\n    - [ ] [45 questions to test Data Scientists on Tree Based Algorithms (Decision tree, Random Forests, XGBoost)](https://www.analyticsvidhya.com/blog/2016/12/detailed-solutions-for-skilltest-tree-based-algorithms/)\n    - [ ] [40 Questions to ask a Data Scientist on Ensemble Modeling Techniques (Skilltest Solution)](https://www.analyticsvidhya.com/blog/2017/02/40-questions-to-ask-a-data-scientist-on-ensemble-modeling-techniques-skilltest-solution/)\n- Graphical Models, Bayesian networks\n    \n    - [ ] [A Sober Look at Bayesian Neural Networks](https://jacobbuckman.com/2020-01-17-a-sober-look-at-bayesian-neural-networks/)\n    - [ ] [A Gentle Introduction to Bayesian Belief Networks](https://machinelearningmastery.com/introduction-to-bayesian-belief-networks/)\n    - [ ] [Graphical Models](http://www.cs.cmu.edu/~16831-f12/notes/F12/16831_lecture06_astamble.pdf)\n    - [ ] [Directed Graphical Models](https://personal.utdallas.edu/~nrr150130/gmbook/bayes.html)\n    - [ ] [Introduction to Bayesian Networks](https://towardsdatascience.com/introduction-to-bayesian-networks-81031eeed94e)\n    - [ ] [Probabilistic Graphical Models](https://frnsys.com/ai_notes/foundations/probabilistic_graphical_models.html)\n    - [ ] [Introduction to Bayesian Networks | Implement Bayesian Networks In Python | Edureka](https://www.youtube.com/watch?v=SkC8S3wuIfg\u0026t=81s)\n    - [ ] [Bayesian Networks - YouTube](https://www.youtube.com/watch?v=TuGDMj43ehw)\n    - [ ] [(24) Lecture 13.2 ‚Äî Belief Nets [Neural Networks for Machine Learning] - YouTube](https://www.youtube.com/watch?v=6yxJeySclIc)\n    - [ ] [A friendly introduction to Bayes Theorem and Hidden Markov Models - YouTube](https://www.youtube.com/watch?v=kqSzLo9fenk)[(24) belief network - YouTube](https://www.youtube.com/results?search_query=belief+network)\n    - [ ] [(24) Bayesian Belief Network Explained with Solved Example in Hindi - YouTube](https://www.youtube.com/watch?v=ccivrsjMsXw)\n    - [ ] [(24) BayesianNetworks - YouTube](https://www.youtube.com/watch?v=5s7XdGacztw)\n- Clustering\n    \n    - [ ] [The Most Comprehensive Guide to K-Means Clustering You‚Äôll Ever Need](https://towardsdatascience.com/mish-8283934a72df)\n    - [ ] [Beginner‚Äôs Guide To K-Means Clustering](https://www.analyticsindiamag.com/beginners-guide-to-k-means-clustering/)\n    - [ ] [K-means Clustering Algorithm: Know How It Works](https://www.edureka.co/blog/k-means-clustering-algorithm/)\n    - [ ] [In Depth: k-Means Clustering](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)\n    - [ ] [TheAlgorithms - k_means_clust](https://github.com/TheAlgorithms/Python/blob/master/machine_learning/k_means_clust.py)\n    - [ ] [K means Clustering ‚Äì Introduction](https://www.geeksforgeeks.org/k-means-clustering-introduction/)\n    - [ ] [Image compression using K-means clustering](https://www.geeksforgeeks.org/image-compression-using-k-means-clustering/)\n    - [ ] [Introduction to Image Segmentation with K-Means clustering](https://www.kdnuggets.com/2019/08/introduction-image-segmentation-k-means-clustering.html)\n    - [ ] [ML | Mini Batch K-means clustering algorithm](https://www.geeksforgeeks.org/ml-mini-batch-k-means-clustering-algorithm/)\n    - [ ] [Clustering in Machine Learning](https://www.geeksforgeeks.org/clustering-in-machine-learning/)\n    - [ ] [Different Types of Clustering Algorithm](https://www.geeksforgeeks.org/different-types-clustering-algorithm/)\n    - [ ] [In Depth: Gaussian Mixture Models](https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html)\n    - [ ] [In-Depth: Kernel Density Estimation](https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html)\n    - [ ] [A Beginner‚Äôs Guide to Hierarchical Clustering and how to Perform it in Python](https://www.analyticsvidhya.com/blog/2019/05/beginners-guide-hierarchical-clustering/)\n    - [ ] [ML | Hierarchical clustering (Agglomerative and Divisive clustering)](https://www.geeksforgeeks.org/ml-hierarchical-clustering-agglomerative-and-divisive-clustering/)\n    - [ ] [Hierarchical Clustering / Dendrogram: Simple Definition, Examples](https://www.statisticshowto.datasciencecentral.com/hierarchical-clustering/)\n    - [ ] [Hierarchical Clustering / Dendrograms](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Hierarchical_Clustering-Dendrograms.pdf)\n    - [ ] [ML | Mean-Shift Clustering](https://www.geeksforgeeks.org/ml-mean-shift-clustering/)\n    - [ ] [ML | Spectral Clustering](https://www.geeksforgeeks.org/ml-spectral-clustering/)\n    - [ ] [ML | Fuzzy Clustering](https://www.geeksforgeeks.org/ml-fuzzy-clustering/)\n    - [ ] [DBSCAN Clustering in ML | Density based clustering](https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/)\n    - [ ] [How DBSCAN works and why should we use it?](https://towardsdatascience.com/how-dbscan-works-and-why-should-i-use-it-443b4a191c80)\n    - [ ] [What is the Jaccard Index?](https://www.statisticshowto.datasciencecentral.com/jaccard-index/)\n    - [ ] [K-Means Clustering Implementation in Python | Kaggle](https://www.kaggle.com/andyxie/k-means-clustering-implementation-in-python)\n    - [ ] [Python Programming Tutorials](https://pythonprogramming.net/k-means-from-scratch-machine-learning-tutorial/)\n    - [ ] [Machine Learning Workflows in Python from Scratch Part 2: k-means Clustering](https://www.kdnuggets.com/2017/06/machine-learning-workflows-python-scratch-part-2.html)\n    - [ ] [K-Means Clustering in Python - Blog by Mubaris NK](https://mubaris.com/posts/kmeans-clustering/)\n    - [ ] [Implementing K Means Clustering from Scratch - in Python - The Nadig Blog](http://madhugnadig.com/articles/machine-learning/2017/03/04/implementing-k-means-clustering-from-scratch-in-python.html)\n    - [ ] [Machine Learning Workflows in Python from Scratch Part 1: Data Preparation](https://www.kdnuggets.com/2017/05/machine-learning-workflows-python-scratch-part-1.html)\n    - [ ] [Wikipedia - Single linkage Clustering](https://en.wikipedia.org/wiki/Single-linkage_clustering)\n    - [ ] [Pyclustering](https://github.com/annoviko/pyclustering/tree/master/pyclustering/cluster)\n- Naive bayes\n    \n    - [ ] [Luis Serrano - Naive Bayes classifier: A friendly approach](https://www.youtube.com/watch?v=Q8l0Vip5YUw)\n    - [ ] [Andrew Ng Naive Bayes Generative Learning Algorithms](https://www.youtube.com/watch?v=z5UQyCESW64)\n    - [ ] [Andrew Ng Naive Bayes Text Clasification](https://www.youtube.com/watch?v=NFd0ZQk5bR4)\n    - [ ] [3blue1brown- Bayes theorem, and making probability intuitive](https://www.youtube.com/watch?v=HZGCoVF3YvM)\n    - [ ] [3blue1brown- The quick proof of Bayes' theorem](https://www.youtube.com/watch?v=U_85TaXbeIo)\n    - [ ] [Brandon Rohrer - How Bayes Theorem works](https://www.youtube.com/watch?v=5NMxiOGL39M)\n    - [ ] [Naive Bayes - Georgia Tech - Machine Learning](https://www.youtube.com/watch?v=M59h7CFUwPU)\n    - [ ] [The Bayesian Trap](https://www.youtube.com/watch?v=R13BD8qKeTg\u0026list=RDQMQfbssw7R-TQ\u0026index=24)\n    - [ ] [In Depth: Naive Bayes Classification](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)\n    - [ ] [Naive Bayes Classifier in Python | Naive Bayes Algorithm | Machine Learning Algorithm | Edureka](https://www.youtube.com/watch?v=vz_xuxYS2PM\u0026t=11s)\n    - [ ] [How to Develop a Naive Bayes Classifier from Scratch in Python](https://machinelearningmastery.com/classification-as-conditional-probability-and-the-naive-bayes-algorithm//)\n    - [ ] [Naive Bayes Classifier From Scratch](https://chrisalbon.com/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/)\n    - [ ] [kaggle - Naive Bayes Classifier¬∂](https://www.kaggle.com/pranavpandey2511/naive-bayes-classifier-from-scratch)\n    - [ ] [Naive Bayes Classifiers](https://www.geeksforgeeks.org/naive-bayes-classifiers)\n    - [ ] [Understanding Naive Bayes Classifier from scratch : Python code](https://appliedmachinelearning.blog/2017/05/23/understanding-naive-bayes-classifier-from-scratch-python-code/)\n    - [ ] [kDnuggets - Naive Bayes from Scratch using Python only ‚Äì No Fancy Frameworks](https://www.kdnuggets.com/2018/10/naive-bayes-from-scratch-python.html)\n    - [ ] [Na√Øve Bayes for Machine Learning ‚Äì From Zero to Hero](https://blog.floydhub.com/naive-bayes-for-machine-learning/)\n    - [ ] [How Bayes‚Äô Theorem is Applied in Machine Learning](https://www.kdnuggets.com/2019/10/bayes-theorem-applied-machine-learning.html)\n- MLE, MAP, Mixture models, expectation maximization\n    \n    - [ ] [The Only Theorem Data Scientists Need To Know](https://towardsdatascience.com/the-only-theorem-data-scientists-need-to-know-a50a263d013)\n    - [ ] [Pieter abeel Maximum Likelihood Examples](https://www.youtube.com/watch?v=BFHGIE-nwME)\\\n    - [ ] [Gaussians.pdf](https://ttic.uchicago.edu/~dmcallester/ttic101-07/lectures/Gaussians/Gaussians.pdf)\n    - [ ] [normal distribution - Maximum Likelihood Estimators - Multivariate Gaussian - Cross Validated](https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian?noredirect=1\u0026lq=1)\n    - [ ] [(9) Maximum Likelihood estimation - an introduction part 1 - YouTube](https://www.youtube.com/watch?v=I_dhPETvll8)\n    - [ ] [Maximum Likelihood Estimation Explained - Normal Distribution](https://towardsdatascience.com/maximum-likelihood-estimation-explained-normal-distribution-6207b322e47f)\n    - [ ] [Probability concepts explained: Maximum likelihood estimation](https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1)\n    - [ ] [Maximum likelihood estimation of normal distribution - Daijiang Li](https://daijiang.name/en/2014/10/08/mle-normal-distribution/?source=post_page-----791153818030----------------------)\n    - [ ] [cs229-notes2.pdf](https://see.stanford.edu/materials/aimlcs229/cs229-notes2.pdf)\n    - [ ] [An Introductory Guide to Maximum Likelihood Estimation (with a case study in R)](https://www.analyticsvidhya.com/blog/2018/07/introductory-guide-maximum-likelihood-estimation-case-study-r/)\n    - [ ] [YOUTUBE - MLE](https://www.youtube.com/watch?index=23\u0026list=PLD0F06AA0D2E8FFBA\u0026t=0s\u0026v=aHwsEXCk4HA\u0026app=desktop)\n    - [ ] [Gaussian Mixture Model - GeeksforGeeks](https://www.geeksforgeeks.org/gaussian-mixture-model/)\n    - [ ] [5.pdf](https://www.cse.wustl.edu/~garnett/cse515t/fall_2019/files/lecture_notes/5.pdf)\n    - [ ] [Gaussian Mixture Models Clustering Algorithm Explained](https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e)\n    - [ ] [analytics vidya GMM](https://www.analyticsvidhya.com/blog/2019/10/gaussian-mixture-models-clustering/)\n    - [ ] [Hidden markov model-GMM-tf2](https://gitlab.com/kesmarag/hmm-gmm-tf2)\n    - [ ] [MLM-A Gentle Introduction to Maximum a Posteriori (MAP) for Machine Learning](https://machinelearningmastery.com/maximum-a-posteriori-estimation/)\n    - [ ] [MLM-A Gentle Introduction to Monte Carlo Sampling for Probability](https://machinelearningmastery.com/monte-carlo-sampling-for-probability/)\n    - [ ] [Gaussian Mixture Model clustering: how to select the number of components (clusters)](https://towardsdatascience.com/gaussian-mixture-model-clusterization-how-to-select-the-number-of-components-clusters-553bef45f6e4)\n    - [ ] [A Novel Ship Detector Based on Gaussian Mixture Model and K-Means Algorithm | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-319-98776-7_72)\n    - [ ] [Probability concepts explained: Bayesian inference for parameter estimation.](https://towardsdatascience.com/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348)\n- EXPECTATION MAXIMIZATION\n    \n    - [ ] [MLM-A Gentle Introduction to Expectation-Maximization (EM Algorithm)](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)\n    - [ ] [Edureka expectation maximization](https://www.youtube.com/watch?v=DIADjJXrgps)\n    - [ ] [YOUTUBE - EXPECTATION MAXIMIZATION](https://www.youtube.com/watch?v=AnbiNaVp3eQ\u0026list=PLD0F06AA0D2E8FFBA\u0026index=116)\n    - [ ] [YOUTUBE-EM](https://www.youtube.com/playlist?list=PLBv09BD7ez_7beI0_fuE96lSbsr_8K8YD)\n    - [ ] [Gaussian Mixture Model - GeeksforGeeks](https://www.geeksforgeeks.org/gaussian-mixture-model/)\n    - [ ] [Gaussian Mixture Models Clustering Algorithm Explained](https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e)\n    - [ ] [What are Gaussian Mixture Models? A Powerful Clustering Algorithm](https://www.analyticsvidhya.com/blog/2019/10/gaussian-mixture-models-clustering/)\n    - [ ] [A Gentle Introduction to Expectation-Maximization (EM Algorithm)](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)\n    - [ ] [EM Algorithm In Machine Learning | Expectation-Maximization | Machine Learning Tutorial | Edureka - YouTube](https://www.youtube.com/watch?v=DIADjJXrgps)\n    - [ ] [(ML 16.3) Expectation-Maximization (EM) algorithm - YouTube](https://www.youtube.com/watch?v=AnbiNaVp3eQ\u0026list=PLD0F06AA0D2E8FFBA\u0026index=116)\n    - [ ] [Mixture Models - YouTube](https://www.youtube.com/playlist?list=PLBv09BD7ez_4e9LtmK626Evn1ion6ynrt)\n    - [ ] [Expectation Maximization Algorithm - YouTube](https://www.youtube.com/playlist?list=PLBv09BD7ez_7beI0_fuE96lSbsr_8K8YD)\n    - [ ] [Clustering - YouTube](https://www.youtube.com/watch?v=vNdyhLI02bs)\n    - [ ] [Clustering (4): Gaussian Mixture Models and EM - YouTube](https://www.youtube.com/watch?v=qMTuMa86NzU\u0026t=8s)\n    - [ ] [Expectation Maximization with an Example ‚Äì Stokastik](http://www.stokastik.in/em/)\n    - [ ] [ML | Expectation-Maximization Algorithm - GeeksforGeeks](https://www.geeksforgeeks.org/ml-expectation-maximization-algorithm/)\n    - [ ] [EM Algorithm (Expectation-maximization): Simple Definition - Statistics How To](https://www.statisticshowto.datasciencecentral.com/em-algorithm-expectation-maximization/)\n    - [ ] [A Tutorial on the Expectation Maximization (EM) Algorithm](https://www.kdnuggets.com/2016/08/tutorial-expectation-maximization-algorithm.html)","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/Trade-off-Vi%C3%A9s-Vari%C3%A2ncia":{"title":"Trade-off Vi√©s-Vari√¢ncia","content":"Quando treinamos um modelo de Machine Learning, sempre teremos um erro de generaliza√ß√£o: erro que informa o \u003cmark style=\"background: #ADCCFFA6;\"\u003equ√£o bem o modelo generaliza para dados que n√£o foram usados no treinamento\u003c/mark\u003e (dados novos), e esse erro pode ser decomposto em 3 termos:\n\n### Vi√©s\nErro ou diferen√ßa entre o previsto e observado (suposi√ß√µes erradas assumidas pelo modelo)\n\n### Vari√¢ncia\nErro devido a sensibilidade excessiva do modelo √† pequenas varia√ß√µes nos dados, ou seja, um modelo com alta vari√¢ncia captura ru√≠do aleat√≥rio nos dados dispon√≠veis, ao inv√©s dos outputs pretendidos (ter√° performance ruim para dados n√£o vistos)\n\n### Erro irredut√≠vel\nErro devido ao ru√≠dos dos dados, considerados irredut√≠veis dado a aleatoriedade natural na distribui√ß√£o \"geradora\"\n\nA partir desses erros, surgem dois fen√¥menos no aprendizado de m√°quina se o modelo se ajusta aos dados de treinamento de maneira inadequada:\n\n## Underfitting\n*Underfitting* acontece quando o modelo se ajusta de maneira insuficiente ao dados de treino, ou seja, o modelo n√£o √© capaz de aprender os padr√µes presentes nos dados e/ou **n√£o consegue replicar o comportamento** dos dados pela t√©cnica de escolha (ex: utilizar [[Regress√£o Linear]] para dados que seguem uma par√°bola).\n\nComo resultado, o modelo n√£o consegue aprender com precis√£o as rela√ß√µes entre as vari√°veis e as classes, resultando em um **desempenho ruim tanto nos dados de treinamento quando nos dados de teste**\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003ePara lidar com underfitting, √© necess√°rio utilizar modelos mais complexos, aumentar a quantidade e qualidade dos dados de treinamento e considerar o uso de caracter√≠sticas mais relevantes para a solu√ß√£o do problema\u003c/mark\u003e.\n\n## Overfitting\n*Overfitting* acontece quando o modelo se ajusta bem demais aos dados de treinamento, incorporando n√£o apenas os padr√µes reais, mas tamb√©m o erro irredut√≠vel presente nos dados de treino. O modelo se torna muito complexo e espec√≠fico ao conjunto de dados apresentado inicialmente, resultando em baixa capacidade de generaliza√ß√£o para novos dados de teste.\n\nEm outras palavras, o modelo **decora** os exemplos de treinamento, mas falha em capturar a estrutura geral dos dados para aplicar em uma nova amostra.\n\nSinais de *overfitting* incluem um desempenho excepcionalmente bom nos dados de treinamento, mas desempenho muito menor em dados de teste n√£o vistos anteriormente. O modelo pode ser tornar muito sens√≠vel a pequenas varia√ß√µes nos dados de treino e tende a apresentar alta vari√¢ncia.\n\n\u003cmark style=\"background: #ADCCFFA6;\"\u003ePara evitar o overfitting √© comum utilizar t√©cnicas de \u003c/mark\u003e [[Regulariza√ß√£o]]\u003cmark style=\"background: #ADCCFFA6;\"\u003e, como a redu√ß√£o de  complexidade do modelo, a adi√ß√£o de termos de penaliza√ß√£o (L1/L2) ou o aumento do tamanho do conjunto de treinamento.\u003c/mark\u003e\n![[Pasted image 20230717210409.png | center]]\n\nA complexidade de um modelo define a flexibilidade para aproximar a previs√£o da distribui√ß√£o real dos dados. Quanto \u003cmark style=\"background: #ADCCFFA6;\"\u003emais complexidade\u003c/mark\u003e tem o modelo, \u003cmark style=\"background: #ADCCFFA6;\"\u003emaior tende a ser sua vari√¢ncia e menor o vi√©s\u003c/mark\u003e, por outro lado \u003cmark style=\"background: #ADCCFFA6;\"\u003emodelos muito simples possuem vi√©s elevado e baixa vari√¢ncia\u003c/mark\u003e:\n\n![[Pasted image 20230717210840.png | center]]\nComo o erro do modelo √© a soma dos tr√™s termos e, **o erro irredut√≠vel √© constante**, √© preciso encontrar um equil√≠brio entre vi√©s e vari√¢ncia para garantirmos o melhor desempenho do nosso modelo, e \"filosofia\" de encontrar as quantidades √≥timas de vi√©s e vari√¢ncia √© chamada de **trade-off vi√©s-vari√¢ncia**.\n\n![[Pasted image 20230717211153.png | center]]\n#conceitos","lastmodified":"2023-08-06T23:13:33.13302269Z","tags":[]},"/Machine-Learning/Machine-Learning/XGBClassifier":{"title":"XGBClassifier","content":"√â um algoritmo derivado do XGBoost(Extreme Gradient Boosting) baseado em [[Ensemble]] de √°rvores de decis√£o que utiliza o [[Gradient Boost]] como estrutura de forma otimizada computacionalmente, aproveitando do paralelismo.\n![[Pasted image 20230716212019.png | center]]\n![[Pasted image 20230716212041.png | center]] \nConsegue melhorar o tempo de processamento construindo os modelo base de √°rvore de forma paralela, al√©m de ter sido projetado para utilizar os recursos do hardware de forma mais eficiente. Al√©m disso, **realiza a poda das √°rvores durante o processamento, que gera um ganho de performance**.\nUtiliza a regulariza√ß√£o [[Regulariza√ß√£o|L1 (Lasso)]] e [[Regulariza√ß√£o|L2 (Ridge)]] para prevenir *overfitting*, admite naturalmente features esparsas, sabendo lidar de forma eficiente com valores nulos. Al√©m disso realiza valida√ß√£o cruzada em cada itera√ß√£o.\n\n### Vantagens\n- Dispensa a necessidade de *feature engineering* (n√£o precisa de normaliza√ß√£o/padroniza√ß√£o, tamb√©m pode lidar com valores nulos)\n- Pode ser utilizado para determinar *feature importance*\n- Pouco sens√≠vel a outliers\n- Lida bem com datasets muito grandes\n- Custo computacional razo√°vel\n- Menos propenso a *overfitting*\n- Modelo possui boa performance, normalmente aparece nas melhores solu√ß√µes em sites de competi√ß√µes\n\n### Desvantagem\n- Pouca interpretabilidade (modelo black box)\n- Pode ocorrer *overfitting* se n√£o houver ajuste adequado dos hiperpar√¢metros\n- Quantidade extensa de hiperpar√¢metros para serem tunados (requer cuidado nessa etapa)\n\n\n#todo \nVer detalhadamente como funciona o gradient boosting\n\n\n#classifica√ß√£o #xgboost","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/Machine-Learning/Machine-Learning/XGBoost":{"title":"XGBoost","content":"","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/Machine-Learning/Private/Apresenta%C3%A7%C3%A3o-f%C3%B3rum-boas-pr%C3%A1ticas":{"title":"Apresenta√ß√£o f√≥rum boas pr√°ticas","content":"\n### Intro ~ 15s\nComo a marina comentou, a gente sabe que existe oportunidade para reconhecer melhor a renda para alguns p√∫blicos espec√≠ficos e n√≥s atacamos esses pontos dessas maneiras:\n\n#### Teto Select ~ 1m10s\nN√≥s vamos implementar um novo teto para o p√∫blico select que comprova renda com IR pois hoje os gerentes notam o impacto do cadastro na renda final por√©m pelos tetos atuais a renda riscos dificilmente se iguala ao valor do comprovante, principalmente para clientes NH21. \n\nComo no exemplo do cliente select Edson que levou um IR de 87mil na ag√™ncia para comprovar renda e teve a renda riscos calculada pela nossa pol√≠tica limitada no teto m√°ximo de 39mil.\n\nPara tentarmos tratar esses casos n√≥s vamos flexibilizar para 100mil o teto para esse perfil de p√∫blico, para garantirmos que caso haja a atualiza√ß√£o de renda com um comprovante forte, o cliente possa chegar a um patamar mais alto de renda riscos\n\n#### Santander On ~ 1m15s\nO nosso segundo ponto de aten√ß√£o s√£o os clientes que atualizam renda no santander on e acabam ficando com a renda estagnada at√© uma nova comprova√ß√£o de renda ou para os clientes folha 12 meses (ap√≥s esse periodo n√≥s priorizamos o cr√©dito sal√°rio)\n\nAqui a gente trouxe um exemplo dessa situa√ß√£o pra ilustrar, o Warley que atualizou sua renda pelo aplicativo para 39mil, 7 meses depois passou a receber um cr√©dito sal√°rio com valor maior do que o atualizado mas a renda riscos iria se manter no mesmo patamar mais 2 meses at√© n√≥s priorizarmos o fluxo \"normal\" da riscos\n\nO nosso ajuste aqui vai ser a partir de 6 meses que o cliente atualizou pelo aplicativo, a pol√≠tica vai olhar suas informa√ß√µes e decidir se existe a possibilidade de aumento de renda com as demais informa√ß√µes internas do cliente, caso exista, ele ter√° o acr√©scimo na renda riscos de maneira antecipada.\n\n#### Travas Sal√°rio ~ 1m30s\nAs travas que a gente cita aqui surgem a partir do momento que passamos a usar de forma mais forte o sal√°rio dentro da pol√≠tica, e a gente sabe que √© uma forma√ß√£o muito boa e de um fluxo seguro porque o sal√°rio √© uma informa√ß√£o sist√™mica sem input do cliente/gerente\n\nPor√©m notamos que existia uma pequena fragilidade na informa√ß√£o de sal√°rio quando notamos o exemplo da maria:\n\nMaria √© dona de uma empresa E1 (de pequeno porte) e tem uma conta PF no Santander, por√©m n√≥s notamos que ela recebia na conta PF, sal√°rios de 140mil reais que no ano representariam mais de 50% do faturamento total de uma empresa do porte que ela tem, e com todo esse fluxo duvidoso a gente acaba superestimando o sal√°rio na hora de calcular a renda riscos\n\nPara esse problema n√≥s adicionamos valores m√°ximos a serem considerados como cr√©dito sal√°rio dependendo do porte da cnpj que paga o cliente, exclusivamente das duas menores classes (E1 e E2), assim n√≥s n√£o prejudicamos o c√°lculo da renda riscos com o valor do sal√°rio inflado\n\n#### Demais pol√≠ticas ~ 1m\nEssas tr√™s s√£o as mudan√ßas com motivama√ß√£o mais especificas, mas n√£o s√£o todas que teremos, seguindo aqui:\n\nA nova **renda premium** √© uma informa√ß√£o que vamos o hist√≥rico de faturas internas e externas de clientes com perfil premium para garantir um piso de renda mais adequado para esse p√∫blico\n\n**Conselho profissional** √© outra informa√ß√£o que vamos adicionar para reconhecer melhor um perfil de p√∫blico alta renda que tem cadastro em conselhos profissionais como os de medicina, oab, etc. Definindo novos valores de piso e tetos de rendas.\n\nVamos substituir a informa√ß√£o do calculo do sal√°rio pela revis√£o que a Ana j√° apresentou e agora tamb√©m utilizamos a informa√ß√£o de **renda de servidor p√∫blico** que compramos da quod como um valor m√≠nimo de sal√°rio para os servidores que n√£o s√£o folha","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/Machine-Learning/Private/Resum%C3%A3o":{"title":"Resum√£o","content":"### Vi√©s e Vari√¢ncia\n- O que √© vies?\n- O que √© variancia\n- Relaciones vi√©s com vari√¢ncia\n- Quais s√£o as principais formas de se controlar vi√©s?\n- Quais s√£o as principais formas de se controlar vari√¢ncia?\n\nVi√©s e vari√¢ncia s√£o dois dos conceitos gerais de erros em modelagem, \u003cmark style=\"background: #ADCCFFA6;\"\u003evi√©s √© o tipo de erro que ocorre quando o modelo assume suposi√ß√µes incorreta dos dados a partir do conjunto de treino. Um modelo com alto vi√©s est√° relacionado ao underfit, quando um modelo aprende muito pouco com os dados de treino.\u003c/mark\u003e\n\nPor outro lado, \u003cmark style=\"background: #FF5582A6;\"\u003ea vari√¢ncia reflete o qu√£o sens√≠vel o modelo √© em rela√ß√£o √† varia√ß√µes dos dados de conjunto de treino. Dizemos que um modelo muito sens√≠vel possui alta vari√¢ncia e est√° relacionado ao problema de overfit, quando o modelo n√£o generaliza bem para novos dados (teste)\u003c/mark\u003e.\n\nA rela√ß√£o entre os dois √© o famoso trade-off vi√©s e vari√¢ncia, normalmente na modelagem existe uma balan√ßa entre reduzir o vi√©s e a vari√¢ncia. Ao passo que um modelo muito simples inicialmente come√ßam a ganhar complexidade e flexibilidade (ao comportamento dos dados), ele tem uma redu√ß√£o no vi√©s por√©m pode apresentar aumento na vari√¢ncia, indicando perda de performance para novos dados n√£o observados, \u003cmark style=\"background: #ADCCFFA6;\"\u003eo objetivo do trade-off √© encontrar o ponto de equil√≠brio entre a redu√ß√£o do vi√©s e da vari√¢ncia\u003c/mark\u003e\n\nVi√©s alto pode ser controlado usando modelos mais complexos e flex√≠veis, usando mais features (principalmente se elas apresentarem poder preditivo) e para alguns algoritmos, reduzir a penaliza√ß√£o aplicada. Para alta vari√¢ncia, podemos usar modelos mais simples/com menos par√¢metros, aumentar a quantidade de dados no treino, utilizar regularizadores (lasso e ridge) e tamb√©m √© poss√≠vel utilizar t√©cnicas de boosting\n\n### √Årvores\n- Qual o crit√©rio de quebra?\n- Como a sa√≠da √© calculada? \n- Quais s√£o os pontos fortes do algoritmo?\n- Quais s√£o os crit√©rios principais de parada?\n- Quais s√£o os principais problemas encontrados no algoritmo?\n- Qual a forma de regulariza√ß√£o de uma √°rvore?\n\n√Årvores de decis√£o podem ser utilizadas tanto para problemas de regress√£o quanto pra de classifica√ß√£o e funcionam de maneira minimamente diferentes para cada tipo. √â chamada de √°rvore pois as condi√ß√µes de decis√£o do modelo s√£o feitas por ramifica√ß√µes criando \"visualmente\" algo muito parecido com uma raiz de uma √°rvore.\n\nNo geral a ramifica√ß√£o da √°rvore √© feita de maneira que os dados que sobram em cada grupo ap√≥s a separa√ß√£o sejam mais homog√™neos do que antes da quebra, nas √°rvores de regress√£o verificamos a \"homogeneidade\" com m√©tricas como [[MSE]] e [[MAE]], e para as √°rvores de classifica√ß√£o utilizamos [[Gini]] ou [[Entropia]] para validar as quebras.\n\nAp√≥s serem feitas todas as quebras, n√≥s temos folhas no n√≠vel mais baixo de cada ramifica√ß√£o que representa a sa√≠da do modelo, para regress√£o utilizamos a m√©dia da target dos dados que pertencem a folha e para classifica√ß√£o n√≥s utilizamos a classe mais frequente dentro da folha (caso ela n√£o seja pura).\n\nPessoal gosta muito da interpretabilidade que as √°rvores de decis√£o oferecem e a capacidade de lidar com os dados sem a necessidade de padroniza√ß√£o ou tratamentos. Por√©m se n√£o tomar cuidado com os par√¢metros da √°rvore √© bem f√°cil de acontecer overfitting e o algoritmo tem a tend√™ncia de gerar √°rvores diferentes se os dados de treino forem alterados.\n\nUma maneira de evitar o overfitting √© definir bem os crit√©rios de parada da √°rvore, que s√£o a profundidade m√°xima da √°rvore, o tanto que voc√™ quer que ela se ramifique, n√∫mero m√≠nimo de observa√ß√µes dentro de um n√≥ para que seja poss√≠vel continuar dividindo e o n√∫mero m√≠nimo de observa√ß√µes dentro de uma folha do modelo.\n\nRegularizadores de √°rvore de decis√£o s√£o basicamente os crit√©rios de parada\n\n### Ensembles\n- Quais as principais formas de ensemble?\n- Cite um algoritmo de bagging e outro de boosting\n- Qual problema o bagging se prop√µe a resolver?\n- Qual problema o boosting se prop√µe a resolver?\n- Quais s√£o os principais par√¢metros de uma random forest e quais s√£o seus efeitos?\n- Quais s√£o os principais par√¢metros de um gradient boosting e quais s√£o seus efeitos?\n- Relacione bagging a vi√©s e vari√¢ncia\n- Relacione boosting a vi√©s e vari√¢ncia\n- Cite duas implementa√ß√µes de boosting e explique suas diferen√ßas\n\nEnsemble s√£o t√©cnicas que v√°rios modelos treinados para resolver um mesmo problema, combinados para ter um melhor poder preditivo. Os principais m√©todos de ensembles s√£o o bagging e o boosting.\n\nBagging utiliza v√°rias inst√¢ncias do \"mesmo modelo\" para diferentes subconjuntos dos dados originais (realizado por bootstrap) que no fim s√£o combinados por voto da maioria (classifica√ß√£o) e m√©dia/mediana das predi√ß√µes (regress√£o). No geral bagging tenta tratar o problema de modelos que tendem a ter alta vari√¢ncia com sua combina√ß√£o, e um exemplo de bagging √© a Random Forest (agrega√ß√£o de √°rvores de decis√µes)\n\nBoosting busca resolver o problema underfit de modelos fracos \"melhorando\" o modelo de forma sequencial, em cada itera√ß√£o o modelo √© treinado em um conjunto de dados \"ajustado\" dando mais import√¢ncia para os erros passado, ou predizendo o erro gerado pelo modelo anterior. Exemplos de boosting s√£o Gradient Boosting e XGBoost\n\nPrincipais par√¢metros da Random Forest:\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003enumero de √°rvores\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003etamanho do subconjunto de features pra ser utilizado em cada √°rvore\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003emetodo de reamostragem das observa√ß√µes para cada √°rvore\u003c/mark\u003e\n- profundidade m√°xima das √°rvores\n- n√∫mero minimo de amostras (folha/n√≥s)\n\nPrincipais par√¢metros do Gradient Boosting:\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003enumero de √°rvores\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003etamanho do subconjunto de features pra ser utilizado em cada √°rvore\u003c/mark\u003e\n- \u003cmark style=\"background: #ADCCFFA6;\"\u003elearning rate\u003c/mark\u003e\n- profundidade m√°xima das arvores\n- numero m√≠nimo de amostras (folha/n√≥s)\n\nTanto Gradient Boosting quanto XGBoost s√£o t√©cnicas de boosting que buscam melhorar um modelo weak learner predizendo os res√≠duos por√©m possuem algumas diferen√ßas: O XGBoost possui termos regularizadores, como o gamma e o lambda para diminuir o impacto que observa√ß√µes individuais possuem nas previs√µes e melhorar a generaliza√ß√£o do modelo, al√©m de tamb√©m possuir um sistema de poda dinamica que n√£o depende de completar a execu√ß√£o da arvore antes de realizar\n\n### Outros Modelos \nFalar de naive bayes\n\n### M√©tricas de avalia√ß√£o\n- Principais m√©tricas para avaliar um classificador\n- Funcionamento / caso de uso / restri√ß√µes\n- Diferenciar m√©tricas de poder e calibra√ß√£o\n- T√©cnicas multiclasse/multilabel\n- Principais m√©tricas para avaliar um regressor\n- Funcionamento/ caso de uso / restri√ß√µes\n\n#### As m√©tricas mais comuns pra avaliar classificadores s√£o:\n##### M√©tricas de poder:\n- Acuracia: Reflete o percentual de classes que seu modelo acerta, √∫til pra ter uma ideia inicial do modelo mas p√©ssima quando os dados s√£o muito desbalanceados\n- Precis√£o: Mede a propor√ß√£o de observa√ß√µes corretamente classificadas como positivas, bom quando queremos controlar os falsos positivos, \u003cmark style=\"background: #ADCCFFA6;\"\u003eimportante para problemas de recomenda√ß√£o\u003c/mark\u003e\n- Recall/Sensibilidade: Mede a propor√ß√£o de observa√ß√µes positivas classificadas corretamente, √∫til em problemas de sa√∫de/medicina \u003cmark style=\"background: #ADCCFFA6;\"\u003eonde n√£o queremos de maneira alguma deixar de classificar um cliente doente corretamente\u003c/mark\u003e\n- F1-Score: M√©dia harm√¥nica de precis√£o e recall, penaliza mais os valores extremos, √∫til quando ambas o custo dos dois erros s√£o semelhantes.\n- ROC-AUC: Gr√°fico entre TPR e FPR, mede qu√£o bem o classificador separa duas classes (quando o valor se aproxima de 1) para v√°rios pontos de corte, boa m√©trica para avaliar a classifica√ß√£o de um modelo no geral para problemas de classes desbalanceadas\n##### M√©tricas de calibra√ß√£o:\n- Log-Loss: Mede a discrep√¢ncia entre a probabilidade observada pelo modelo e as classes reais atrav√©s da log-verossimilhan√ßa\n\n#### Para avaliar problemas multiclass:\n- **Macro Average** das m√©tricas acima: M√©dia simples da soma das m√©tricas dividas pelo n√∫mero de classes, ex: precis√£o\n$$Macro Avg = \\frac{Precis√£o_{c1}+Precis√£o_{c2}+Precis√£o_{c3}}{3}$$\n- **Micro Average** das m√©tricas acima: M√©dia considerando toda a soma individual de TP, TN, FP e FN de todas as classes do conjunto de dados, ex: precisao\n$$Micro Avg = \\frac{\\sum_{1,2,3}TruePositive}{\\sum_{1,2,3}TruePositive+\\sum_{1,2,3}FalsePositive}$$\n- **Weighted Average** das m√©tricas acima: M√©dia com pesos atribu√≠dos pela frequ√™ncia de cada classe no conjunto de dados, ex: precis√£o\n$$Weighted Avg = \\frac{Precis√£o_{c1}*10+Precis√£o_{c2}*20+Precis√£o_{c3}*50}{10+20+50}$$\n\n#### Para problemas de m√∫ltiplos r√≥tulos pra mesma observa√ß√£o:\n- **Jaccard Score** mede a interse√ß√£o das classifica√ß√µes sobre a uni√£o de todas as classifica√ß√µes, \u003cmark style=\"background: #ADCCFFA6;\"\u003epara problemas bin√°rios √© id√™ntico √† acur√°cia, mas tamb√©m podemos entender o uso para problemas multiclasse e de multirotulo\u003c/mark\u003e\n\n\n#### As m√©tricas mais comuns pra avaliar regressores s√£o:\n- **MSE** representa a m√©dia do quadrado dos res√≠duos, penaliza de maneira mais forte erros maiores por√©m √© sens√≠vel a outliers, como √© uma fun√ß√£o deriv√°vel, √© muito √∫til como fun√ß√£o de custo\n- **RMSE** representa a raiz quadrada do MSE, tem as mesmas vantagens com o adicional de manter o erro na escala original dos dados, aumentando interpretabilidade.\n- **MAE** m√©dia dos erros absolutos, penaliza de acordo com a magnitude dos erros por√©m √© menos sens√≠vel a outliers, como n√£o √© deriv√°vel possui limita√ß√µes como fun√ß√£o de custo, o ponto positivo √© que facilita a interpretabilidade pois mantem a escala original dos dados.\n- **R¬≤** representa a porcentagem de ganho de predi√ß√£o ao usar o modelo em compara√ß√£o √† m√©dia da feature (diferen√ßa entre SSR da m√©dia e SSR do ajuste), desvantagem √© n√£o levar em conta a quantidade de features, que pode influenciar negativamente a m√©trica\n- **R¬≤ Ajustado** √© uma adapta√ß√£o do R¬≤ com uma penaliza√ß√£o pelo n√∫mero de features, ou seja, leva em conta a quantidade de explica√ß√£o fornecida pelas vari√°veis preditoras, √∫til para comparar modelos com diferentes n√∫mero de par√¢metros\n- \n### N√£o supervisionado\n- Quais s√£o as principais categorias de algoritmos de clusteriza√ß√£o\n- Cite um algoritmo de cada categoria?\n- Explique rapidamente os algoritmos citado\n\n\n#### Clusteriza√ß√£o Hier√°rquica\nConstroi dendogramas para representar os clusters em uma hierarquia, onde em certo ponto de corte todos os pontos podem fazer parte de um mesmo cluster, ou cada ponto ser seu pr√≥prio cluster\n\n##### Aglomera√ß√£o\nNa inicializa√ß√£o cada ponto √© seu pr√≥prio e a cada itera√ß√£o os  dois clusters mais pr√≥ximos se unem para formar um novo cluster, esse processo se repete at√© existir apenas 1 cluster s√≥, contendo todo o dataset\n\n##### Divis√£o\nO algoritmo come√ßa considerando todos os pontos em um √∫nico cluster e a cada passo as observa√ß√µes com maior dissimilaridade √© realocado em um cluster separado, processo se repete at√© existir um cluster para cada observa√ß√£o\n\nAs medidas utilizadas podem ser **vizinho mais proximo**, **vizinho mais distante** ou **media das distancias** \n\n#### Clusteriza√ß√£o Particionais\nT√©cnicas de agrupamento que divide os dados em um n√∫mero pre definido de clusters e assim como na hier√°rquica, no fim do processo cada ponto pertence a apenas um cluster, o objetivo √© encontrar a divis√£o do hiperplano que otimiza a m√©trica de dist√¢ncia intra-cluster e inter-cluster\n\n##### K-means\nestima o centroides do cluster com a media dos pontos - indicado usar distancia euclidiana\n##### K-Medoids\nestima centroide do cluster com a mediana - indicado usar com distancia de manhattan\n\n#### Clusteriza√ß√£o baseado em densidade - DBSCAN\nAlgoritmo de agrupamento que considera pontos muito pr√≥ximos em mesmo cluster por densidade, teoricamente consegue identificar qualquer formato na distribui√ß√£o dos dados olhando a proximidade entre pontos\n\nfunciona com os par√¢metros de **pontos minimos** e **tamanho do raio** para classificar os pontos do dataset e depois atribuir em algum cluster\n\n#### Clusteriza√ß√£o baseado em mistura de modelos\nCluster definido em uma abordagem probabil√≠stica, cada modelo representa um cluster e √© ajustado aos dados usando expectation-maximization, permitindo medir a incerteza dos agrupamentos gerados.\n\n##### GMM\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/notes/CJK-+-Latex-Support-%E6%B5%8B%E8%AF%95":{"title":"CJK + Latex Support (ÊµãËØï)","content":"\n## Chinese, Japanese, Korean Support\nÂá†‰πéÂú®Êàë‰ª¨ÊÑèËØÜÂà∞‰πãÂâçÔºåÊàë‰ª¨Â∑≤ÁªèÁ¶ªÂºÄ‰∫ÜÂú∞Èù¢„ÄÇ\n\nÏö∞Î¶¨Í∞Ä Í∑∏Í≤ÉÏùÑ ÏïåÍ∏∞ÎèÑ Ï†ÑÏóê Ïö∞Î¶¨Îäî ÎïÖÏùÑ Îñ†ÎÇ¨ÏäµÎãàÎã§.\n\nÁßÅ„Åü„Å°„Åå„Åù„Çå„ÇíÁü•„Çã„Åª„ÅºÂâç„Å´„ÄÅÁßÅ„Åü„Å°„ÅØÂú∞Èù¢„ÇíÈõ¢„Çå„Å¶„ÅÑ„Åæ„Åó„Åü„ÄÇ\n\n## Latex\n\nBlock math works with two dollar signs `$$...$$`\n\n$$f(x) = \\int_{-\\infty}^\\infty\n    f\\hat(\\xi),e^{2 \\pi i \\xi x}\n    \\,d\\xi$$\n\t\nInline math also works with single dollar signs `$...$`. For example, Euler's identity but inline: $e^{i\\pi} = -1$\n\nAligned equations work quite well:\n\n$$\n\\begin{aligned}\na \u0026= b + c \\\\ \u0026= e + f \\\\\n\\end{aligned}\n$$\n\nAnd matrices\n\n$$\n\\begin{bmatrix}\n1 \u0026 2 \u0026 3 \\\\\na \u0026 b \u0026 c\n\\end{bmatrix}\n$$\n\n## RTL\nMore information on configuring RTL languages like Arabic in the [config](notes/config.md) page.\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/notes/callouts":{"title":"Callouts","content":"\n## Callout support\n\nQuartz supports the same Admonition-callout syntax as Obsidian.\n\nThis includes\n- 12 Distinct callout types (each with several aliases)\n- Collapsable callouts\n\nSee [documentation on supported types and syntax here](https://help.obsidian.md/Editing+and+formatting/Callouts).\n\n## Showcase\n\n\u003e [!EXAMPLE] Examples\n\u003e\n\u003e Aliases: example\n\n\u003e [!note] Notes\n\u003e\n\u003e Aliases: note\n\n\u003e [!abstract] Summaries \n\u003e\n\u003e Aliases: abstract, summary, tldr\n\n\u003e [!info] Info \n\u003e\n\u003e Aliases: info, todo\n\n\u003e [!tip] Hint \n\u003e\n\u003e Aliases: tip, hint, important\n\n\u003e [!success] Success \n\u003e\n\u003e Aliases: success, check, done\n\n\u003e [!question] Question \n\u003e\n\u003e Aliases: question, help, faq\n\n\u003e [!warning] Warning \n\u003e\n\u003e Aliases: warning, caution, attention\n\n\u003e [!failure] Failure \n\u003e\n\u003e Aliases: failure, fail, missing\n\n\u003e [!danger] Error\n\u003e\n\u003e Aliases: danger, error\n\n\u003e [!bug] Bug\n\u003e\n\u003e Aliases: bug\n\n\u003e [!quote] Quote\n\u003e\n\u003e Aliases: quote, cite\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Jacky Zhao\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to render copy buttons for code blocks\nenableCodeBlockCopy: true \n\n# whether to render callouts\nenableCallouts: true\n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flashes of unstyled content and improves\n# smoothness of Quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# whether to display an 'edit' button next to the last edited field\n# that links to github\nenableGitHubEdit: true\nGitHubLink: https://github.com/jackyzha0/quartz/tree/hugo/content\n\n# whether to render mermaid diagrams\nenableMermaid: true\n\n# whether to use Operand to power semantic search\n# IMPORTANT: replace this API key with your own if you plan on using\n# Operand search!\nsearch:\n  enableSemanticSearch: false\n  operandApiKey: \"REPLACE-WITH-YOUR-OPERAND-API-KEY\"\n  operandIndexId: \"REPLACE-WITH-YOUR-OPERAND-INDEX-ID\"\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"ü™¥ Quartz 3.3\"\n\n# links to show in the footer\nlinks:\n  - link_name: Twitter\n    link: https://twitter.com/_jzhao\n  - link_name: Github\n    link: https://github.com/jackyzha0\n```\n\n### Code Block Titles\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur, and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your Quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. For example, here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to Quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current and past standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n    # whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `assets/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support (ÊµãËØï)](notes/CJK%20+%20Latex%20Support%20(ÊµãËØï).md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = 'ŸÖÿØŸàŸÜÿ™Ÿä'\n    weight = 1\n```\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":["setup"]},"/notes/custom-Domain":{"title":"Custom Domain","content":"\n### Registrar\nThis step is only applicable if you are using a **custom domain**! If you are using a `\u003cYOUR-USERNAME\u003e.github.io` domain, you can skip this step.\n\nFor this last bit to take effect, you also need to create a CNAME record with the DNS provider you register your domain with (i.e. NameCheap, Google Domains).\n\nGitHub has some [documentation on this](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site), but the tldr; is to\n\n1. Go to your forked repository (`github.com/\u003cYOUR-GITHUB-USERNAME\u003e/quartz`) settings page and go to the Pages tab. Under \"Custom domain\", type your custom domain, then click **Save**.\n2. Go to your DNS Provider and create a CNAME record that points from your domain to `\u003cYOUR-GITHUB-USERNAME.github.io.` (yes, with the trailing period).\n\n\t![Example Configuration for Quartz](/notes/images/google-domains.png)*Example Configuration for Quartz*\n3. Wait 30 minutes to an hour for the network changes to kick in.\n4. Done!","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/notes/docker":{"title":"Hosting with Docker","content":"\nIf you want to host Quartz on a machine without using a webpage hosting service, it may be easier to [install Docker Compose](https://docs.docker.com/compose/install/) and follow the instructions below than to [install Quartz's dependencies manually](notes/preview%20changes.md).\n## Hosting Quartz Locally\nYou can serve Quartz locally at `http://localhost:1313` with the following script, replacing `/path/to/quartz` with the \nactual path to your Quartz folder.\n\ndocker-compose.yml\n```\nservices:\n  quartz-hugo:\n    image: ghcr.io/jackyzha0/quartz:hugo\n    container_name: quartz-hugo\n    volumes:\n      - /path/to/quartz:/quartz\n    ports:\n      - 1313:1313\n\n    # optional\n    environment:\n      - HUGO_BIND=0.0.0.0\n      - HUGO_BASEURL=http://localhost\n      - HUGO_PORT=1313\n      - HUGO_APPENDPORT=true\n      - HUGO_LIVERELOADPORT=-1\n```\n\nThen run with: `docker-compose up -d` in the same directory as your `docker-compose.yml` file.\n\nWhile the container is running, you can update the `quartz` fork with: `docker exec -it quartz-hugo make update`.\n\n## Exposing Your Container to the Internet\n\n### To Your Public IP Address with Port Forwarding (insecure)\n\nAssuming you are already familiar with [port forwarding](https://en.wikipedia.org/wiki/Port_forwarding) and [setting it up with your router model](https://portforward.com):\n\n1. You should set the environment variable `HUGO_BASEURL=http://your-public-ip` and then start your container.\n2. Set up port forwarding on your router from port `p` to `your-local-ip:1313`.\n3. You should now be able to access Quartz from outside your local network at `http://your-public-ip:p`.\n\nHowever, your HTTP connection will be unencrypted and **this method is not secure**.\n\n### To a Domain using Cloudflare Proxy\n\n1. Port forward 443 (HTTPS) from your machine.\n2. Buy a custom domain (say, `your-domain.com`) from [Cloudflare](https://www.cloudflare.com/products/registrar/). Point a DNS A record from `your-domain.com` to your public IP address and enable the proxy.\n3. Set the environment variables `HUGO_BASEURL=https://your-domain.com`, `HUGO_PORT=443`, and `HUGO_APPENDPORT=false`. Change `1313:1313` to `443:443` for the `ports` in `docker-compose.yml`.\n4. Spin up your Quartz container and enjoy it at `https://your-domain.com`!\n\n### To a Domain using a Reverse Proxy\n\nIf you want to serve more than just Quartz to the internet on this machine (or don't want to use the Cloudflare registrar and proxy), you should follow the steps in the section above (as appropriate) and also set up a reverse proxy, like [Traefik](https://doc.traefik.io/traefik). Be sure to configure your TLS certificates too!\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":["setup"]},"/notes/editing":{"title":"Editing Content in Quartz","content":"\n## Editing \nQuartz runs on top of [Hugo](https://gohugo.io/) so all notes are written in [Markdown](https://www.markdownguide.org/getting-started/).\n\n### Folder Structure\nHere's a rough overview of what's what.\n\n**All content in your garden can found in the `/content` folder.** To make edits, you can open any of the files and make changes directly and save it. You can organize content into any folder you'd like.\n\n**To edit the main home page, open `/content/_index.md`.**\n\n### Front Matter\nHugo is picky when it comes to metadata for files. Make sure that your title is double-quoted and that you have a title defined at the top of your file like so, otherwise the generated page will not have a title!\n\nYou can also add tags here as well.\n\n```yaml\n---\ntitle: \"Example Title\"\ntags:\n- example-tag\n---\n\nRest of your content here...\n```\n\n### Obsidian\nI recommend using [Obsidian](http://obsidian.md/) as a way to edit and grow your digital garden. It comes with a really nice editor and graphical interface to preview all of your local files.\n\nThis step is **highly recommended**.\n\n\u003e üîó Step 3: [How to setup your Obsidian Vault to work with Quartz](notes/obsidian.md)\n\n## Previewing Changes\nThis step is purely optional and mostly for those who want to see the published version of their digital garden locally before opening it up to the internet. This is *highly recommended* but not required.\n\n\u003e üëÄ Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n\nFor those who like to live life more on the edge, viewing the garden through Obsidian gets you pretty close to the real thing.\n\n## Publishing Changes\nNow that you know the basics of managing your digital garden using Quartz, you can publish it to the internet!\n\n\u003e üåç Step 5: [Hosting Quartz online!](notes/hosting.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":["setup"]},"/notes/hosting":{"title":"Deploying Quartz to the Web","content":"\n## Hosting on GitHub Pages\nQuartz is designed to be effortless to deploy. If you forked and cloned Quartz directly from the repository, everything should already be good to go! Follow the steps below.\n\n### Enable GitHub Actions Permissions\nBy default, GitHub disables workflows from modifying your files (for good reason!). However, Quartz needs this to write the actual site files back to GitHub.\n\nHead to `Settings \u003e Action \u003e General \u003e Workflow Permissions` and choose `Read and Write Permissions`\n\n![[notes/images/github-actions.png]]\n*Enable GitHub Actions*\n\n### Enable GitHub Pages\n\nHead to the 'Settings' tab of your forked repository and go to the 'Pages' tab.\n\n1. (IMPORTANT) Set the source to deploy from `master` (and not `hugo`) using `/ (root)`\n2. Set a custom domain here if you have one!\n\n![Enable GitHub Pages](/notes/images/github-pages.png)*Enable GitHub Pages*\n\n### Pushing Changes\nTo see your changes on the internet, we need to push it them to GitHub. Quartz is a `git` repository so updating it is the same workflow as you would follow as if it were just a regular software project.\n\n```shell\n# Navigate to Quartz folder\ncd \u003cpath-to-quartz\u003e\n\n# Commit all changes\ngit add .\ngit commit -m \"message describing changes\"\n\n# Push to GitHub to update site\ngit push origin hugo\n```\n\nNote: we specifically push to the `hugo` branch here. Our GitHub action automatically runs everytime a push to is detected to that branch and then updates the `master` branch for redeployment.\n\n### Setting up the Site\nNow let's get this site up and running. Never hosted a site before? No problem. Have a fancy custom domain you already own or want to subdomain your Quartz? That's easy too.\n\nHere, we take advantage of GitHub's free page hosting to deploy our site. Change `baseURL` in `/config.toml`. \n\nMake sure that your `baseURL` has a trailing `/`!\n\n[Reference `config.toml` here](https://github.com/jackyzha0/quartz/blob/hugo/config.toml)\n\n```toml\nbaseURL = \"https://\u003cYOUR-DOMAIN\u003e/\"\n```\n\nIf you are using this under a subdomain (e.g. `\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz`), include the trailing `/`. **You need to do this especially if you are using GitHub!**\n\n```toml\nbaseURL = \"https://\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz/\"\n```\n\nChange `cname` in `/.github/workflows/deploy.yaml`. Again, if you don't have a custom domain to use, you can use `\u003cYOUR-USERNAME\u003e.github.io`.\n\nPlease note that the `cname` field should *not* have any path `e.g. end with /quartz` or have a trailing `/`.\n\n[Reference `deploy.yaml` here](https://github.com/jackyzha0/quartz/blob/hugo/.github/workflows/deploy.yaml)\n\n```yaml {title=\".github/workflows/deploy.yaml\"}\n- name: Deploy  \n  uses: peaceiris/actions-gh-pages@v3  \n  with:  \n\tgithub_token: ${{ secrets.GITHUB_TOKEN }} # this can stay as is, GitHub fills this in for us!\n\tpublish_dir: ./public  \n\tpublish_branch: master\n\tcname: \u003cYOUR-DOMAIN\u003e\n```\n\nHave a custom domain? [Learn how to set it up with Quartz ](notes/custom%20Domain.md).\n\n### Ignoring Files\nOnly want to publish a subset of all of your notes? Don't worry, Quartz makes this a simple two-step process.\n\n‚ùå [Excluding pages from being published](notes/ignore%20notes.md)\n\n## Docker Support\nIf you don't want to use a hosting service, you can host using [Docker](notes/docker.md) instead!\nI would *not use this method* unless you know what you are doing.\n\n---\n\nNow that your Quartz is live, let's figure out how to make Quartz really *yours*!\n\n\u003e Step 6: üé® [Customizing Quartz](notes/config.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":["setup"]},"/notes/ignore-notes":{"title":"Ignoring Notes","content":"\n### Quartz Ignore\nEdit `ignoreFiles` in `config.toml` to include paths you'd like to exclude from being rendered.\n\n```toml\n...\nignoreFiles = [  \n    \"/content/templates/*\",  \n    \"/content/private/*\", \n    \"\u003cyour path here\u003e\"\n]\n```\n\n`ignoreFiles` supports the use of Regular Expressions (RegEx) so you can ignore patterns as well (e.g. ignoring all `.png`s by doing `\\\\.png$`).\nTo ignore a specific file, you can also add the tag `draft: true` to the frontmatter of a note.\n\n```markdown\n---\ntitle: Some Private Note\ndraft: true\n---\n...\n```\n\nMore details in [Hugo's documentation](https://gohugo.io/getting-started/configuration/#ignore-content-and-data-files-when-rendering).\n\n### Global Ignore\nHowever, just adding to the `ignoreFiles` will only prevent the page from being access through Quartz. If you want to prevent the file from being pushed to GitHub (for example if you have a public repository), you need to also add the path to the `.gitignore` file at the root of the repository.","lastmodified":"2023-08-06T23:13:33.137022738Z","tags":[]},"/notes/obsidian":{"title":"Obsidian Vault Integration","content":"\n## Setup\nObsidian is the preferred way to use Quartz. You can either create a new Obsidian Vault or link one that your already have.\n\n### New Vault\nIf you don't have an existing Vault, [download Obsidian](https://obsidian.md/) and create a new Vault in the `/content` folder that you created and cloned during the [setup](notes/setup.md) step.\n\n### Linking an existing Vault\nThe easiest way to use an existing Vault is to copy all of your files (directory and hierarchies intact) into the `/content` folder.\n\n## Settings\nGreat, now that you have your Obsidian linked to your Quartz, let's fix some settings so that they play well.\n\nOpen Settings \u003e Files \u0026 Links and look for these two items:\n\n1. Set the **New link format** to **Absolute Path in vault**. If you have a completely flat vault (no folders), this step isn't necessary.\n2. Turn **on** the **Automatically update internal links** setting.\n\n\n![[notes/images/obsidian-settings.png]]*Obsidian Settings*\n\n## Templates\nInserting front matter everytime you want to create a new Note gets annoying really quickly. Luckily, Obsidian supports templates which makes inserting new content really easily.\n\n\u003e [!WARNING]\n\u003e \n\u003e **If you decide to overwrite the `/content` folder completely, don't remove the `/content/templates` folder!**\n\nHead over to Options \u003e Core Plugins and enable the Templates plugin. Then go to Options \u003e Hotkeys and set a hotkey for 'Insert Template' (I recommend `[cmd]+T`). That way, when you create a new note, you can just press the hotkey for a new template and be ready to go!\n\n\u003e üëÄ Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":["setup"]},"/notes/philosophy":{"title":"Quartz Philosophy","content":"\n\u003e ‚Äú[One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.‚Äù ‚Äî Richard Hamming\n\n## Why Quartz?\nHosting a public digital garden isn't easy. There are an overwhelming number of tutorials, resources, and guides for tools like [Notion](https://www.notion.so/), [Roam](https://roamresearch.com/), and [Obsidian](https://obsidian.md/), yet none of them have super easy to use *free* tools to publish that garden to the world.\n\nI've personally found that\n1. It's nice to access notes from anywhere\n2. Having a public digital garden invites open conversations\n3. It makes keeping personal notes and knowledge *playful and fun*\n\nI was really inspired by [Bianca](https://garden.bianca.digital/) and [Joel](https://joelhooks.com/digital-garden)'s digital gardens and wanted to try making my own.\n\n**The goal of Quartz is to make hosting your own public digital garden free and simple.** You don't even need your own website. Quartz does all of that for you and gives your own little corner of the internet.\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":[]},"/notes/preview-changes":{"title":"Preview Changes","content":"\nIf you'd like to preview what your Quartz site looks like before deploying it to the internet, the following\ninstructions guide you through installing the proper dependencies to run it locally.\n\n\n## Install `hugo-obsidian`\nThis step will generate the list of backlinks for Hugo to parse. Ensure you have [Go](https://golang.org/doc/install) (\u003e= 1.16) installed.\n\n```bash\n# Install and link `hugo-obsidian` locally\ngo install github.com/jackyzha0/hugo-obsidian@latest\n```\n\nIf you are running into an error saying that `command not found: hugo-obsidian`, make sure you set your `GOPATH` correctly (see [[notes/troubleshooting#`command not found: hugo-obsidian`|the troubleshooting page]])! This will allow your terminal to correctly recognize hugo-obsidian as an executable.\n\n##  Installing Hugo\nHugo is the static site generator that powers Quartz. [Install Hugo with \"extended\" Sass/SCSS version](https://gohugo.io/getting-started/installing/) first. Then,\n\n```bash\n# Navigate to your local Quartz folder\ncd \u003clocation-of-your-local-quartz\u003e\n\n# Start local server\nmake serve\n\n# View your site in a browser at http://localhost:1313/\n```\n\n\u003e [!INFO] Docker Support\n\u003e\n\u003e If you have the Docker CLI installed already, you can avoid installing `hugo-obsidian` and `hugo`. Instead, open your terminal, navigate to your folder with Quartz and run `make docker`\n\nAfterwards, start the Hugo server as shown above and your local backlinks and interactive graph should be populated! Now, let's get it hosted online.\n\n\u003e üåç Step 5: [Hosting Quartz online!](notes/hosting.md)\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":["setup"]},"/notes/search":{"title":"Search","content":"\nQuartz supports two modes of searching through content.\n\n## Full-text\nFull-text search is the default in Quartz. It produces results that *exactly* match the search query. This is easier to setup but usually produces lower quality matches.\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nenableSemanticSearch: false\n```\n\n## Natural Language\nNatural language search is powered by [Operand](https://beta.operand.ai/). It understands language like a person does and finds results that best match user intent. In this sense, it is closer to how Google Search works.\n\nNatural language search tends to produce higher quality results than full-text search.\n\nHere's how to set it up.\n\n1. Login or Register for a new Operand account. Click the verification link sent to your email, and you'll be redirected to the dashboard. (Note) You do not need to enter a credit card to create an account, or get started with the Operand API. The first $10 of usage each month is free. To learn more, see pricing. If you go over your free quota, we'll (politely) reach out and ask you to configure billing.\n2. Create your first index. On the dashboard, under \"Indexes\", enter the name and description of your index, and click \"Create Index\". Note down the ID of the index (obtained by clicking on the index name in the list of indexes), as you'll need it in the next step. IDs are unique to each index, and look something like `uqv1duxxbdxu`.\n3. Click into the index you've created. Under \"Index Something\", select \"SITEMAP\" from the dropdown and click \"Add Source\".\n4. For the \"Sitemap.xml URL\", put your deployed site's base URL followed by `sitemap.xml`. For example, for `quartz.jzhao.xyz`, put `https://quartz.jzhao.xyz/sitemap.xml`. Leave the URL Regex empty. \n5. Get your API key. On the dashboard, under \"API Keys\", you can manage your API keys. If you don't already have an API key, click \"Create API Key\". You'll need this for the next step.\n6. Open `data/config.yaml`. Set `enableSemanticSearch` to `true`, `operandApiKey` to your copied key, and `operandIndexId` to the ID of the index we created from earlier..\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nsearch:\n  enableSemanticSearch: true\n  operandApiKey: \"jp9k5hudse2a828z98kxd6z3payi8u90rnjf\"\n  operandIndexId: \"s0kf3bd6tldw\"\n```\n7. Push your changes to the site and wait for it to deploy.\n8. Check the Operand dashboard and wait for your site to index. Enjoy natural language search powered by Operand!\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":[]},"/notes/setup":{"title":"Setup","content":"\n## Making your own Quartz\nSetting up Quartz requires a basic understanding of `git`. If you are unfamiliar, [this resource](https://resources.nwplus.io/2-beginner/how-to-git-github.html) is a great place to start!\n\n### Forking\n\u003e A fork is a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.\n\nNavigate to the GitHub repository for the Quartz project:\n\nüìÅ [Quartz Repository](https://github.com/jackyzha0/quartz)\n\nThen, Fork the repository into your own GitHub account. **Make sure that when you fork, you _uncheck_ the 'Copy the `hugo` branch only' option**.\n\nIf you don't have an account, you can make on for free [here](https://github.com/join). More details about forking a repo can be found on [GitHub's documentation](https://docs.github.com/en/get-started/quickstart/fork-a-repo).\n\n![[notes/images/fork.png]]\n\n### Cloning\nAfter you've made a fork of the repository, you need to download the files locally onto your machine. Ensure you have `git`, then type the following command in your terminal replacing `YOUR-USERNAME` with your GitHub username.\n\n```shell\ngit clone https://github.com/YOUR-USERNAME/quartz\n```\n\n## Editing\nGreat! Now you have everything you need to start editing and growing your digital garden. If you're ready to start writing content already, check out the recommended flow for editing notes in Quartz.\n\n\u003e ‚úèÔ∏è Step 2: [Editing Notes in Quartz](notes/editing.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":["setup"]},"/notes/showcase":{"title":"Showcase","content":"\nWant to see what Quartz can do? Here are some cool community gardens :)\n\n- [Quartz Documentation (this site!)](https://quartz.jzhao.xyz/)\n- [Jacky Zhao's Garden](https://jzhao.xyz/)\n- [Scaling Synthesis - A hypertext research notebook](https://scalingsynthesis.com/)\n- [AWAGMI Intern Notes](https://notes.awagmi.xyz/)\n- [Shihyu's PKM](https://shihyuho.github.io/pkm/)\n- [SlRvb's Site](https://slrvb.github.io/Site/)\n- [Course notes for Information Technology Advanced Theory](https://a2itnotes.github.io/quartz/)\n- [Brandon Boswell's Garden](https://brandonkboswell.com)\n- [Siyang's Courtyard](https://siyangsun.github.io/courtyard/)\n- [Data Dictionary üß†](https://glossary.airbyte.com/)\n- [sspaeti.com's Second Brain](https://brain.sspaeti.com/)\n- [oldwinter„ÅÆÊï∞Â≠óËä±Âõ≠](https://garden.oldwinter.top/)\n- [SethMB Work](https://sethmb.xyz/)\n- [Abhijeet's Math Wiki](https://abhmul.github.io/quartz/Math-Wiki/)\n- [Mike's AI Garden ü§ñü™¥](https://mwalton.me/)\n\nIf you want to see your own on here, submit a [Pull Request adding yourself to this file](https://github.com/jackyzha0/quartz/blob/hugo/content/notes/showcase.md)!\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":[]},"/notes/troubleshooting":{"title":"Troubleshooting and FAQ","content":"\nStill having trouble? Here are a list of common questions and problems people encounter when installing Quartz.\n\nWhile you're here, join our [Discord](https://discord.gg/cRFFHYye7t) :)\n\n### Does Quartz have Latex support?\nYes! See [CJK + Latex Support (ÊµãËØï)](notes/CJK%20+%20Latex%20Support%20(ÊµãËØï).md) for a brief demo.\n\n### Can I use \\\u003cObsidian Plugin\\\u003e in Quartz?\nUnless it produces direct Markdown output in the file, no. There currently is no way to bundle plugin code with Quartz.\n\nThe easiest way would be to add your own HTML partial that supports the functionality you are looking for.\n\n### My GitHub pages is just showing the README and not Quartz\nMake sure you set the source to deploy from `master` (and not `hugo`) using `/ (root)`! See more in the [hosting](/notes/hosting) guide\n\n### Some of my pages have 'January 1, 0001' as the last modified date\nThis is a problem caused by `git` treating files as case-insensitive by default and some of your posts probably have capitalized file names. You can turn this off in your Quartz by running this command.\n\n```shell\n# in the root of your Quartz (same folder as config.toml)\ngit config core.ignorecase true\n\n# or globally (not recommended)\ngit config --global core.ignorecase true\n```\n\n### Can I publish only a subset of my pages?\nYes! Quartz makes selective publishing really easy. Heres a guide on [excluding pages from being published](notes/ignore%20notes.md).\n\n### Can I host this myself and not on GitHub Pages?\nYes! All built files can be found under `/public` in the `master` branch. More details under [hosting](notes/hosting.md).\n\n### `command not found: hugo-obsidian`\nMake sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize `hugo-obsidian` as an executable.\n\n```shell\n# Add the following 2 lines to your ~/.bash_profile (~/.zshrc if you are on Mac)\nexport GOPATH=/Users/$USER/go\nexport PATH=$GOPATH/bin:$PATH\n\n# In your current terminal, to reload the session\nsource ~/.bash_profile # again, (~/.zshrc if you are on Mac)\n```\n\n### How come my notes aren't being rendered?\nYou probably forgot to include front matter in your Markdown files. You can either setup [Obsidian](notes/obsidian.md) to do this for you or you need to manually define it. More details in [the 'how to edit' guide](notes/editing.md).\n\n### My custom domain isn't working!\nWalk through the steps in [the hosting guide](notes/hosting.md) again. Make sure you wait 30 min to 1 hour for changes to take effect.\n\n### How do I setup analytics?\nQuartz by default uses [Plausible](https://plausible.io/) for analytics. \n\nIf you would prefer to use Google Analytics, you can follow this [guide in the Hugo documentation](https://gohugo.io/templates/internal/#google-analytics). \n\nAlternatively, you can also import your Google Analytics data into Plausible by [following this guide](https://plausible.io/docs/google-analytics-import).\n\n\n### How do I change the content on the home page?\nTo edit the main home page, open `/content/_index.md`.\n\n### How do I change the colours?\nYou can change the theme by editing `assets/custom.scss`. More details on customization and themeing can be found in the [customization guide](notes/config.md).\n\n### How do I add images?\nYou can put images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\n### My Interactive Graph and Backlinks aren't up to date\nBy default, the `linkIndex.json` (which Quartz needs to generate the Interactive Graph and Backlinks) are not regenerated locally. To set that up, see the guide on [local editing](notes/editing.md)\n\n### Can I use React/Vue/some other framework?\nNot out of the box. You could probably make it work by editing `/layouts/_default/single.html` but that's not what Quartz is designed to work with. 99% of things you are trying to do with those frameworks you can accomplish perfectly fine using just vanilla HTML/CSS/JS.\n\n## Still Stuck?\nQuartz isn't perfect! If you're still having troubles, file an issue in the GitHub repo with as much information as you can reasonably provide. Alternatively, you can message me on [Twitter](https://twitter.com/_jzhao) and I'll try to get back to you as soon as I can.\n\nüêõ [Submit an Issue](https://github.com/jackyzha0/quartz/issues)\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":[]},"/notes/updating":{"title":"Updating","content":"\nHaven't updated Quartz in a while and want all the cool new optimizations? On Unix/Mac systems you can run the following command for a one-line update! This command will show you a log summary of all commits since you last updated, press `q` to acknowledge this. Then, it will show you each change in turn and press `y` to accept the patch or `n` to reject it. Usually you should press `y` for most of these unless it conflicts with existing changes you've made! \n\n```shell\nmake update\n```\n\nOr, if you don't want the interactive parts and just want to force update your local garden (this assumed that you are okay with some of your personalizations been overriden!)\n\n```shell\nmake update-force\n```\n\nOr, manually checkout the changes yourself.\n\n\u003e [!warning] Warning!\n\u003e\n\u003e If you customized the files in `data/`, or anything inside `layouts/`, your customization may be overwritten!\n\u003e Make sure you have a copy of these changes if you don't want to lose them.\n\n\n```shell\n# add Quartz as a remote host\ngit remote add upstream git@github.com:jackyzha0/quartz.git\n\n# index and fetch changes\ngit fetch upstream\ngit checkout -p upstream/hugo -- layouts .github Makefile assets/js assets/styles/base.scss assets/styles/darkmode.scss config.toml data \n```\n","lastmodified":"2023-08-06T23:13:33.141022785Z","tags":[]}}